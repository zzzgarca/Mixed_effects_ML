{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f278667b",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a1069b",
   "metadata": {},
   "source": [
    "## Root and data folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "068e5c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "root_dir = \"/Users/silviumatu/Desktop/Code/Python/Disertatie/Disertatie_Matu_Silviu_v1\"\n",
    "os.makedirs(root_dir, exist_ok=True)\n",
    "\n",
    "data_dir = os.path.join(root_dir, \"Data\")\n",
    "os.makedirs(data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a82a06",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e4c133",
   "metadata": {},
   "source": [
    "## Helper function to split columns with multiple values stored into one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "124fdc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_split_column(df, column_name, separator):\n",
    "    split_values = df[column_name].fillna(\"\").str.strip().str.replace(separator, \"\", regex=False).str.split()\n",
    "\n",
    "    unique_values = sorted(set(val for sublist in split_values for val in sublist))\n",
    "\n",
    "    for val in unique_values:\n",
    "        new_col = f\"{column_name}_{val}\"\n",
    "        df[new_col] = split_values.apply(lambda x: val in x).astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e7fcb1",
   "metadata": {},
   "source": [
    "## PED GHQ data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6e05500",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yh/t1ywk0b91j3gnfbjn2sct4300000gn/T/ipykernel_55794/3956664899.py:3: DtypeWarning: Columns (11,21,339,854,855,856,907,1041,1047,1049,1235,1242,1326,1331) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  PED_GHQ_df = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "# Loading the PED data\n",
    "PED_data_file = \"All_timeframes_merged_processed.csv\"\n",
    "PED_GHQ_df = pd.read_csv(\n",
    "    os.path.join(data_dir, PED_data_file))\n",
    "\n",
    "# Clening the data\n",
    "PED_GHQ_df = PED_GHQ_df[PED_GHQ_df[\"email_baseline\"] != \"test\"]\n",
    "PED_GHQ_df = PED_GHQ_df[PED_GHQ_df[\"to_exclude_baseline\"] != \"1\"]\n",
    "PED_GHQ_df = PED_GHQ_df[PED_GHQ_df[\"to_exclude_first_day\"] != \"1\"]\n",
    "PED_GHQ_df = PED_GHQ_df.drop_duplicates(subset=[\"email_baseline\", \"week_weekly\"], keep=\"first\")\n",
    "\n",
    "# Drop rows that have missing data on the basline and first day reports\n",
    "PED_GHQ_df = PED_GHQ_df.dropna(subset=[\"response_id_baseline\"])\n",
    "PED_GHQ_df = PED_GHQ_df.dropna(subset=[\"response_id_first_day\"])\n",
    "\n",
    "# Save the columns to filter them manually\n",
    "PED_GHQ_df.columns.to_series().to_csv(os.path.join(data_dir, \"PED_GHQ_baseline_day1_columns_to_filter.csv\"), index = False)\n",
    "\n",
    "# Reading the columns after they have been filtered\n",
    "PED_columns_to_keep = pd.read_csv(os.path.join(data_dir, \"PED_GHQ_baseline_day1_filtered_columns_forecast.csv\"))[\"columns\"].tolist()\n",
    "\n",
    "# Keeping only filtered columns\n",
    "PED_GHQ_df = PED_GHQ_df[PED_columns_to_keep]\n",
    "\n",
    "# Handle an error in the calculation of a score\n",
    "PED_GHQ_df[\"PDA_sadness_TOTAL_baseline\"] = (\n",
    "    PED_GHQ_df[\"PDA_sadness_TOTAL_baseline\"].fillna(0) +\n",
    "    PED_GHQ_df[\"PDA_saddness_TOTAL_baseline\"].fillna(0)\n",
    ")\n",
    "# Drop the misspelled column\n",
    "PED_GHQ_df = PED_GHQ_df.drop(columns=[\"PDA_saddness_TOTAL_baseline\"])\n",
    "\n",
    "# Drop text type columns\n",
    "PED_GHQ_df = PED_GHQ_df.drop(columns=[\"locations_today_first_day\",\n",
    "                              \"locations_now_first_day\",\n",
    "                              \"activity_now_first_day\",\n",
    "                              \"ER_ESM_1_first_day\",\n",
    "                              \"ER_ESM_14_first_day\",\n",
    "                              \"ER_ESM_15_first_day\",\n",
    "                              \"ER_ESM_16_first_day\",\n",
    "                              \"ER_ESM_17_first_day\",\n",
    "                              \"ER_ESM_18_first_day\"])\n",
    "\n",
    "# Drop incomplete cases\n",
    "PED_GHQ_df=PED_GHQ_df.dropna()\n",
    "\n",
    "# Using the helper function to split columns with multiple values to one-hot encoding\n",
    "PED_GHQ_df = one_hot_split_column(PED_GHQ_df, \"stress_factors_first_day\", \"_\")\n",
    "\n",
    "# Drop the column that was split\n",
    "PED_GHQ_df = PED_GHQ_df.drop(columns=[\"stress_factors_first_day\"])\n",
    "\n",
    "# Convert 1 to 0 and 2 to 1\n",
    "PED_GHQ_cols_to_convert_0_1 = [\n",
    "    \"gender_baseline\",\n",
    "    \"previous_psychiatric_diagnostic_baseline\",\n",
    "    \"previous_psychiatric_treatment_baseline\",\n",
    "    \"previous_psychologist_baseline\",\n",
    "    \"curent_psychiatric_treatment_baseline\",\n",
    "    \"current_psychologist_baseline\"\n",
    "]\n",
    "PED_GHQ_df[PED_GHQ_cols_to_convert_0_1] = PED_GHQ_df[PED_GHQ_cols_to_convert_0_1].replace({1: 0, 2: 1})\n",
    "\n",
    "\n",
    "# Columns for one hot encoding\n",
    "PED_GHQ_columns_to_one_hot_encode = [\n",
    "    \"nationality_recoded_baseline\",\n",
    "    \"live_same_city_baseline\",\n",
    "    \"work_status_baseline\",\n",
    "    \"siblings_baseline\",\n",
    "    \"familly_income_baseline\",\n",
    "    \"home_town_type_baseline\",\n",
    "    \"type_study_program_baseline\",\n",
    "    \"relationship_baseline\",\n",
    "    \"religion_baseline\",\n",
    "    \"parents_higher_education_baseline\",\n",
    "    \"health_last_month_baseline\",\n",
    "    \"mental_health_last_month_baseline\",\n",
    "    \"stress_management_first_day\"\n",
    "]\n",
    "PED_GHQ_df = pd.get_dummies(PED_GHQ_df, columns=PED_GHQ_columns_to_one_hot_encode, prefix_sep=\"_value_\", drop_first=False)\n",
    "PED_GHQ_df_dummy_cols = [col for col in PED_GHQ_df.columns if any(prefix in col for prefix in PED_GHQ_columns_to_one_hot_encode)]\n",
    "\n",
    "\n",
    "# Convert booledn dummy columns to int\n",
    "PED_GHQ_df[PED_GHQ_df_dummy_cols] = PED_GHQ_df[PED_GHQ_df_dummy_cols].astype(int)\n",
    "\n",
    "\n",
    "# Remove .0 from the names of the columns \n",
    "PED_GHQ_df.columns = PED_GHQ_df.columns.str.replace(r\"\\.0\\b\", \"\", regex=True)\n",
    "\n",
    "\n",
    "# Creat unique ids from emails\n",
    "PED_email_to_id = {email: idx for idx, email in enumerate(PED_GHQ_df[\"email_baseline\"].unique())}\n",
    "PED_GHQ_df[\"participant_id\"] = PED_GHQ_df[\"email_baseline\"].map(PED_email_to_id)\n",
    "PED_GHQ_mapping_df = pd.DataFrame(list(PED_email_to_id.items()), columns=[\"email_baseline\", \"participant_id\"])\n",
    "PED_GHQ_mapping_df.to_csv(os.path.join(data_dir,\"PED_GHQ_email_id_mapping_forecast.csv\"), index=False)\n",
    "\n",
    "\n",
    "# Drop the email column to keep the data anonymus\n",
    "PED_GHQ_df = PED_GHQ_df.drop(columns=[\"email_baseline\"])\n",
    "\n",
    "\n",
    "# Renaiming and processing time columns so that first completion for each participant is time 0\n",
    "PED_GHQ_df[\"week_weekly\"] = PED_GHQ_df[\"week_weekly\"] - PED_GHQ_df.groupby(\"participant_id\")[\"week_weekly\"].transform(\"min\")\n",
    "PED_GHQ_df = PED_GHQ_df.rename(columns={\"week_weekly\": \"time\"})\n",
    "\n",
    "\n",
    "# Categorical version of GHQ_Total_score\n",
    "PED_GHQ_df[\"GHQ_TOTAL_score_category_first_day\"] = np.where(PED_GHQ_df[\"GHQ_TOTAL_score_first_day\"] >= 12, 1, 0)\n",
    "\n",
    "\n",
    "# Rename columns to start with x\n",
    "PED_GHQ_df = PED_GHQ_df.rename(columns={\n",
    "    col: f\"x_{col}\" for col in PED_GHQ_df.columns\n",
    "})\n",
    "\n",
    "PED_GHQ_df[\"x_time_copy\"] = PED_GHQ_df[\"x_time\"]\n",
    "\n",
    "\n",
    "\n",
    "# Save the data to a CSV file\n",
    "PED_GHQ_df.to_csv(os.path.join(data_dir, \"PED_GHQ_filtered_data_forecast.csv\"), index = False)\n",
    "\n",
    "\n",
    "# Creating the time structure for the data\n",
    "PED_GHQ_df = PED_GHQ_df.sort_values(by=[\"x_participant_id\", \"x_time\"])\n",
    "PED_GHQ_df[\"x_time_difference_first_day\"] = PED_GHQ_df.groupby(\"x_participant_id\")[\"x_time\"].shift(-1) - PED_GHQ_df[\"x_time\"]\n",
    "PED_GHQ_df[\"y_GHQ_TOTAL_score_next\"] = PED_GHQ_df.groupby(\"x_participant_id\")[\"x_GHQ_TOTAL_score_first_day\"].shift(-1)\n",
    "PED_GHQ_df[\"y_GHQ_TOTAL_score_category_next\"] = PED_GHQ_df.groupby(\"x_participant_id\")[\"x_GHQ_TOTAL_score_category_first_day\"].shift(-1)\n",
    "\n",
    "#Making a copy of this\n",
    "PED_GHQ_df[\"x_time_difference_first_day_copy\"] = PED_GHQ_df[\"x_time_difference_first_day\"]\n",
    "\n",
    "# Dropping rows were there is nothing to predict\n",
    "PED_GHQ_df = PED_GHQ_df[PED_GHQ_df[\"y_GHQ_TOTAL_score_next\"].notna()]\n",
    "\n",
    "\n",
    "# Compute a count for each ID\n",
    "PED_GHQ_participant_counts = PED_GHQ_df[\"x_participant_id\"].value_counts().reset_index()\n",
    "PED_GHQ_participant_counts.columns = [\"participant_id\", \"count\"]\n",
    "PED_GHQ_participant_counts.to_csv(os.path.join(data_dir, \"PED_GHQ_participant_count_forecast.csv\"), index = False)\n",
    "\n",
    "\n",
    "# Saving files for regression and categorical analyses for the forecast scenario\n",
    "PED_GHQ_df_regression = PED_GHQ_df.drop(columns=[\"x_GHQ_TOTAL_score_category_first_day\" ,\"y_GHQ_TOTAL_score_category_next\"])\n",
    "PED_GHQ_df_regression.to_csv(os.path.join(data_dir, \"PED_GHQ_regression_data_forecast.csv\"), index = False)\n",
    "\n",
    "PED_GHQ_df_categorical = PED_GHQ_df.drop(columns=[\"x_GHQ_TOTAL_score_first_day\" ,\"y_GHQ_TOTAL_score_next\"])\n",
    "PED_GHQ_df_categorical.to_csv(os.path.join(data_dir, \"PED_GHQ_categorical_data_forecast.csv\"), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1166a5e",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0d6a9787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_age_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_gender_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_previous_psychiatric_diagnostic_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_previous_psychiatric_treatment_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_previous_psychologist_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_curent_psychiatric_treatment_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_current_psychologist_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_ABS_irrational_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_ABS_rational_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_ATS_Generalization_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_ATS_High_Standards_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_ATS_Self_Criticism_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_BAS_Drive_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_BAS_Fun_seeking_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_BAS_Reward_responsivenes_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_BCOPE_Acceptance_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_BCOPE_Active_coping_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_BCOPE_Behavioral_disengagement_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_BCOPE_Denial_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_BCOPE_Emotional_support_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_BCOPE_Humor_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_BCOPE_Informational_support_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_BCOPE_Planning_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_BCOPE_Positive_reframing_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_BCOPE_Religion_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_BCOPE_Self_blame_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_BCOPE_Self_distraction_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_BCOPE_Substance_use_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_BCOPE_Venting_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_BIG5_Agreeableness_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_BIG5_Conscientiousness_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_BIG5_Extraversion_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_BIG5_Neuroticism_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_BIG5_Openness_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_BIS_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_Childhood_Trauma_Screener_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_DASS_Stress_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_DASS21_Anxeity_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_DASS21_Depression_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_ERQ_reappraisal_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_ERQ_suppression_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_GHQ_12_Anxiety_Depression_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_GHQ_12_LossofConfidence_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_GHQ_12_Social_Dysfunction_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_Insomnia_Severity_Index_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_Loneliness_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_PDA_anger_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_PDA_anxiety_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_PDA_concern_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_PDA_depression_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_PDA_positive_emotions_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_PDA_sadness_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_Perceived_Stress_Scale_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_PERMA_Acomplishment_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_PERMA_Engagement_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_PERMA_Happyness_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_PERMA_Health_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_PERMA_Loneliness_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_PERMA_Meaning_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_PERMA_Negative_emotions_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_PERMA_Positive_emotions_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_PERMA_Relationships_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_POG_Lateral_generalization_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_POG_Social_generalization_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_POG_Upward_generalization_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_RIBS_Irratiobal_performance_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_SBQ_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_Self_Compassion_Scale_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_Somatic_Symptoms_Scale_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_Unsrealistic_standards_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_WHO5_well_being_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_BAS_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_BCOPE_avoidant_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_BCOPE_emotion_focused_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_BCOPE_problem_focused_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_GHQ_12_TOTAL_score_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_PDA_dysfcuntional_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_PDA_functional_TOTAL_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_time",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_number_interactions_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_sleep_last_night_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_talked_to_today_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_phone_today_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_CERQ_1_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_CERQ_2_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_CERQ_3_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_CERQ_4_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_CERQ_5_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_CERQ_6_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_CERQ_7_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_CERQ_8_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_CERQ_9_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_CERQ_10_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_CERQ_11_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_CERQ_12_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_CERQ_13_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_CERQ_14_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_CERQ_15_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_CERQ_16_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_CERQ_17_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_CERQ_18_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_GHQ_1_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_GHQ_2_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_GHQ_3_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_GHQ_4_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_GHQ_5_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_GHQ_6_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_GHQ_7_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_GHQ_8_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_GHQ_9_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_GHQ_10_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_GHQ_11_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_GHQ_12_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_ER_ESM_2_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_ER_ESM_3_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_ER_ESM_4_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_ER_ESM_5_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_ER_ESM_6_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_ER_ESM_7_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_ER_ESM_8_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_ER_ESM_9_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_ER_ESM_10_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_ER_ESM_11_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_ER_ESM_12_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_ER_ESM_13_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_GHQ_Anxiety_and_Depression_TOTAL_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_GHQ_Loss_of_Confidence_TOTAL_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_GHQ_Social_Dysfunction_TOTAL_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_stress_factors_first_day_1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_stress_factors_first_day_10",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_stress_factors_first_day_11",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_stress_factors_first_day_12",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_stress_factors_first_day_13",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_stress_factors_first_day_2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_stress_factors_first_day_3",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_stress_factors_first_day_4",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_stress_factors_first_day_5",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_stress_factors_first_day_6",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_stress_factors_first_day_7",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_stress_factors_first_day_8",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_stress_factors_first_day_9",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_nationality_recoded_baseline_value_1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_nationality_recoded_baseline_value_2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_nationality_recoded_baseline_value_3",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_live_same_city_baseline_value_1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_live_same_city_baseline_value_2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_live_same_city_baseline_value_3",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_live_same_city_baseline_value_4",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_live_same_city_baseline_value_5",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_work_status_baseline_value_1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_work_status_baseline_value_2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_work_status_baseline_value_3",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_siblings_baseline_value_0",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_siblings_baseline_value_1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_siblings_baseline_value_2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_siblings_baseline_value_3",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_siblings_baseline_value_4",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_siblings_baseline_value_6",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_siblings_baseline_value_7",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_familly_income_baseline_value_1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_familly_income_baseline_value_2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_familly_income_baseline_value_3",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_home_town_type_baseline_value_1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_home_town_type_baseline_value_4",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_type_study_program_baseline_value_1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_type_study_program_baseline_value_2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_type_study_program_baseline_value_3",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_relationship_baseline_value_1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_relationship_baseline_value_4",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_relationship_baseline_value_5",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_religion_baseline_value_4",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_religion_baseline_value_5",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_religion_baseline_value_6",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_religion_baseline_value_7",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_religion_baseline_value_8",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_religion_baseline_value_10",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_religion_baseline_value_11",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_religion_baseline_value_12",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_religion_baseline_value_13",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_parents_higher_education_baseline_value_1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_parents_higher_education_baseline_value_2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_parents_higher_education_baseline_value_3",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_parents_higher_education_baseline_value_4",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_health_last_month_baseline_value_1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_health_last_month_baseline_value_2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_health_last_month_baseline_value_3",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_health_last_month_baseline_value_4",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_health_last_month_baseline_value_5",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_mental_health_last_month_baseline_value_1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_mental_health_last_month_baseline_value_2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_mental_health_last_month_baseline_value_3",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_mental_health_last_month_baseline_value_4",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_mental_health_last_month_baseline_value_5",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_stress_management_first_day_value_0",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_stress_management_first_day_value_1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_stress_management_first_day_value_2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_participant_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_GHQ_TOTAL_score_category_first_day",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_time_copy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_time_difference_first_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y_GHQ_TOTAL_score_category_next",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_time_difference_first_day_copy",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "b1394f7c-b182-45e8-9579-b656ce88d044",
       "rows": [
        [
         "0",
         "19.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "45.0",
         "26.0",
         "8.0",
         "3.0",
         "6.0",
         "5.0",
         "9.0",
         "6.0",
         "2.0",
         "8.0",
         "4.0",
         "6.0",
         "6.0",
         "5.0",
         "6.0",
         "5.0",
         "6.0",
         "6.0",
         "8.0",
         "7.0",
         "5.0",
         "7.0",
         "8.0",
         "10.0",
         "10.0",
         "10.0",
         "6.0",
         "13.0",
         "17.0",
         "52.0",
         "30.0",
         "44.0",
         "28.0",
         "7.0",
         "11.0",
         "2.0",
         "14.0",
         "19.0",
         "9.0",
         "22.0",
         "14.0",
         "20.0",
         "31.0",
         "21.0",
         "24.0",
         "15.0",
         "23.0",
         "18.0",
         "5.0",
         "10.0",
         "9.0",
         "14.0",
         "23.0",
         "12.0",
         "26.0",
         "7.0",
         "9.0",
         "9.0",
         "16.0",
         "6.0",
         "47.0",
         "28.0",
         "34.0",
         "68.0",
         "20.0",
         "22.0",
         "34.0",
         "25.0",
         "27.0",
         "38.0",
         "40.0",
         "0.0",
         "4.0",
         "9.0",
         "4.0",
         "10.0",
         "5.0",
         "3.0",
         "4.0",
         "2.0",
         "5.0",
         "3.0",
         "5.0",
         "5.0",
         "3.0",
         "5.0",
         "1.0",
         "2.0",
         "5.0",
         "1.0",
         "1.0",
         "5.0",
         "3.0",
         "5.0",
         "0.0",
         "0.0",
         "1.0",
         "1.0",
         "2.0",
         "3.0",
         "0.0",
         "1.0",
         "2.0",
         "2.0",
         "2.0",
         "0.0",
         "4.0",
         "0.0",
         "2.0",
         "2.0",
         "5.0",
         "2.0",
         "3.0",
         "5.0",
         "5.0",
         "3.0",
         "2.0",
         "5.0",
         "7.0",
         "4.0",
         "3.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "1",
         "0.0",
         "1.0",
         "0.0",
         "1.0"
        ],
        [
         "1",
         "19.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "45.0",
         "26.0",
         "8.0",
         "3.0",
         "6.0",
         "5.0",
         "9.0",
         "6.0",
         "2.0",
         "8.0",
         "4.0",
         "6.0",
         "6.0",
         "5.0",
         "6.0",
         "5.0",
         "6.0",
         "6.0",
         "8.0",
         "7.0",
         "5.0",
         "7.0",
         "8.0",
         "10.0",
         "10.0",
         "10.0",
         "6.0",
         "13.0",
         "17.0",
         "52.0",
         "30.0",
         "44.0",
         "28.0",
         "7.0",
         "11.0",
         "2.0",
         "14.0",
         "19.0",
         "9.0",
         "22.0",
         "14.0",
         "20.0",
         "31.0",
         "21.0",
         "24.0",
         "15.0",
         "23.0",
         "18.0",
         "5.0",
         "10.0",
         "9.0",
         "14.0",
         "23.0",
         "12.0",
         "26.0",
         "7.0",
         "9.0",
         "9.0",
         "16.0",
         "6.0",
         "47.0",
         "28.0",
         "34.0",
         "68.0",
         "20.0",
         "22.0",
         "34.0",
         "25.0",
         "27.0",
         "38.0",
         "40.0",
         "1.0",
         "4.0",
         "8.0",
         "4.0",
         "214.0",
         "4.0",
         "4.0",
         "5.0",
         "1.0",
         "5.0",
         "4.0",
         "4.0",
         "5.0",
         "2.0",
         "4.0",
         "5.0",
         "1.0",
         "5.0",
         "1.0",
         "5.0",
         "5.0",
         "4.0",
         "5.0",
         "2.0",
         "1.0",
         "0.0",
         "1.0",
         "2.0",
         "2.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "4.0",
         "1.0",
         "5.0",
         "5.0",
         "5.0",
         "0.0",
         "5.0",
         "5.0",
         "5.0",
         "5.0",
         "5.0",
         "4.0",
         "6.0",
         "0.0",
         "5.0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "1.0",
         "3.0",
         "1.0",
         "3.0"
        ],
        [
         "2",
         "19.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "45.0",
         "26.0",
         "8.0",
         "3.0",
         "6.0",
         "5.0",
         "9.0",
         "6.0",
         "2.0",
         "8.0",
         "4.0",
         "6.0",
         "6.0",
         "5.0",
         "6.0",
         "5.0",
         "6.0",
         "6.0",
         "8.0",
         "7.0",
         "5.0",
         "7.0",
         "8.0",
         "10.0",
         "10.0",
         "10.0",
         "6.0",
         "13.0",
         "17.0",
         "52.0",
         "30.0",
         "44.0",
         "28.0",
         "7.0",
         "11.0",
         "2.0",
         "14.0",
         "19.0",
         "9.0",
         "22.0",
         "14.0",
         "20.0",
         "31.0",
         "21.0",
         "24.0",
         "15.0",
         "23.0",
         "18.0",
         "5.0",
         "10.0",
         "9.0",
         "14.0",
         "23.0",
         "12.0",
         "26.0",
         "7.0",
         "9.0",
         "9.0",
         "16.0",
         "6.0",
         "47.0",
         "28.0",
         "34.0",
         "68.0",
         "20.0",
         "22.0",
         "34.0",
         "25.0",
         "27.0",
         "38.0",
         "40.0",
         "4.0",
         "11.0",
         "7.0",
         "9.0",
         "30.0",
         "2.0",
         "4.0",
         "1.0",
         "1.0",
         "5.0",
         "2.0",
         "4.0",
         "5.0",
         "2.0",
         "1.0",
         "5.0",
         "1.0",
         "5.0",
         "1.0",
         "5.0",
         "5.0",
         "3.0",
         "5.0",
         "3.0",
         "1.0",
         "0.0",
         "1.0",
         "3.0",
         "3.0",
         "1.0",
         "2.0",
         "3.0",
         "1.0",
         "1.0",
         "1.0",
         "5.0",
         "2.0",
         "5.0",
         "5.0",
         "5.0",
         "0.0",
         "5.0",
         "5.0",
         "5.0",
         "5.0",
         "3.0",
         "5.0",
         "10.0",
         "2.0",
         "8.0",
         "0",
         "1",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "4.0",
         "1.0",
         "0.0",
         "1.0"
        ],
        [
         "3",
         "19.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "45.0",
         "26.0",
         "8.0",
         "3.0",
         "6.0",
         "5.0",
         "9.0",
         "6.0",
         "2.0",
         "8.0",
         "4.0",
         "6.0",
         "6.0",
         "5.0",
         "6.0",
         "5.0",
         "6.0",
         "6.0",
         "8.0",
         "7.0",
         "5.0",
         "7.0",
         "8.0",
         "10.0",
         "10.0",
         "10.0",
         "6.0",
         "13.0",
         "17.0",
         "52.0",
         "30.0",
         "44.0",
         "28.0",
         "7.0",
         "11.0",
         "2.0",
         "14.0",
         "19.0",
         "9.0",
         "22.0",
         "14.0",
         "20.0",
         "31.0",
         "21.0",
         "24.0",
         "15.0",
         "23.0",
         "18.0",
         "5.0",
         "10.0",
         "9.0",
         "14.0",
         "23.0",
         "12.0",
         "26.0",
         "7.0",
         "9.0",
         "9.0",
         "16.0",
         "6.0",
         "47.0",
         "28.0",
         "34.0",
         "68.0",
         "20.0",
         "22.0",
         "34.0",
         "25.0",
         "27.0",
         "38.0",
         "40.0",
         "5.0",
         "11.0",
         "7.0",
         "11.0",
         "330.0",
         "4.0",
         "4.0",
         "3.0",
         "4.0",
         "2.0",
         "5.0",
         "4.0",
         "5.0",
         "5.0",
         "3.0",
         "4.0",
         "5.0",
         "1.0",
         "1.0",
         "5.0",
         "2.0",
         "5.0",
         "5.0",
         "2.0",
         "2.0",
         "0.0",
         "0.0",
         "2.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "3.0",
         "0.0",
         "0.0",
         "3.0",
         "0.0",
         "2.0",
         "4.0",
         "2.0",
         "4.0",
         "5.0",
         "4.0",
         "5.0",
         "5.0",
         "1.0",
         "4.0",
         "4.0",
         "3.0",
         "2.0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "5.0",
         "3.0",
         "0.0",
         "3.0"
        ],
        [
         "4",
         "18.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "44.0",
         "48.0",
         "10.0",
         "6.0",
         "6.0",
         "8.0",
         "8.0",
         "10.0",
         "5.0",
         "4.0",
         "5.0",
         "6.0",
         "7.0",
         "4.0",
         "6.0",
         "6.0",
         "6.0",
         "5.0",
         "5.0",
         "7.0",
         "7.0",
         "5.0",
         "8.0",
         "7.0",
         "10.0",
         "8.0",
         "8.0",
         "15.0",
         "13.0",
         "44.0",
         "28.0",
         "20.0",
         "34.0",
         "20.0",
         "9.0",
         "3.0",
         "13.0",
         "26.0",
         "7.0",
         "18.0",
         "15.0",
         "19.0",
         "19.0",
         "35.0",
         "12.0",
         "15.0",
         "23.0",
         "22.0",
         "6.0",
         "17.0",
         "4.0",
         "21.0",
         "23.0",
         "22.0",
         "17.0",
         "13.0",
         "12.0",
         "10.0",
         "12.0",
         "9.0",
         "44.0",
         "26.0",
         "42.0",
         "60.0",
         "26.0",
         "25.0",
         "31.0",
         "22.0",
         "25.0",
         "29.0",
         "28.0",
         "0.0",
         "5.0",
         "9.0",
         "5.0",
         "0.0",
         "2.0",
         "3.0",
         "4.0",
         "3.0",
         "4.0",
         "3.0",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "4.0",
         "3.0",
         "4.0",
         "1.0",
         "2.0",
         "3.0",
         "2.0",
         "4.0",
         "0.0",
         "0.0",
         "1.0",
         "1.0",
         "2.0",
         "2.0",
         "2.0",
         "2.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "4.0",
         "4.0",
         "3.0",
         "1.0",
         "4.0",
         "1.0",
         "3.0",
         "4.0",
         "2.0",
         "3.0",
         "4.0",
         "2.0",
         "5.0",
         "0.0",
         "7.0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "1",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "1",
         "2",
         "1",
         "0.0",
         "2.0",
         "1.0",
         "2.0"
        ]
       ],
       "shape": {
        "columns": 202,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_age_baseline</th>\n",
       "      <th>x_gender_baseline</th>\n",
       "      <th>x_previous_psychiatric_diagnostic_baseline</th>\n",
       "      <th>x_previous_psychiatric_treatment_baseline</th>\n",
       "      <th>x_previous_psychologist_baseline</th>\n",
       "      <th>x_curent_psychiatric_treatment_baseline</th>\n",
       "      <th>x_current_psychologist_baseline</th>\n",
       "      <th>x_ABS_irrational_TOTAL_baseline</th>\n",
       "      <th>x_ABS_rational_TOTAL_baseline</th>\n",
       "      <th>x_ATS_Generalization_TOTAL_baseline</th>\n",
       "      <th>...</th>\n",
       "      <th>x_mental_health_last_month_baseline_value_5</th>\n",
       "      <th>x_stress_management_first_day_value_0</th>\n",
       "      <th>x_stress_management_first_day_value_1</th>\n",
       "      <th>x_stress_management_first_day_value_2</th>\n",
       "      <th>x_participant_id</th>\n",
       "      <th>x_GHQ_TOTAL_score_category_first_day</th>\n",
       "      <th>x_time_copy</th>\n",
       "      <th>x_time_difference_first_day</th>\n",
       "      <th>y_GHQ_TOTAL_score_category_next</th>\n",
       "      <th>x_time_difference_first_day_copy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   x_age_baseline  x_gender_baseline  \\\n",
       "0            19.0                0.0   \n",
       "1            19.0                0.0   \n",
       "2            19.0                0.0   \n",
       "3            19.0                0.0   \n",
       "4            18.0                0.0   \n",
       "\n",
       "   x_previous_psychiatric_diagnostic_baseline  \\\n",
       "0                                         0.0   \n",
       "1                                         0.0   \n",
       "2                                         0.0   \n",
       "3                                         0.0   \n",
       "4                                         0.0   \n",
       "\n",
       "   x_previous_psychiatric_treatment_baseline  \\\n",
       "0                                        0.0   \n",
       "1                                        0.0   \n",
       "2                                        0.0   \n",
       "3                                        0.0   \n",
       "4                                        0.0   \n",
       "\n",
       "   x_previous_psychologist_baseline  x_curent_psychiatric_treatment_baseline  \\\n",
       "0                               1.0                                      0.0   \n",
       "1                               1.0                                      0.0   \n",
       "2                               1.0                                      0.0   \n",
       "3                               1.0                                      0.0   \n",
       "4                               0.0                                      0.0   \n",
       "\n",
       "   x_current_psychologist_baseline  x_ABS_irrational_TOTAL_baseline  \\\n",
       "0                              0.0                             45.0   \n",
       "1                              0.0                             45.0   \n",
       "2                              0.0                             45.0   \n",
       "3                              0.0                             45.0   \n",
       "4                              0.0                             44.0   \n",
       "\n",
       "   x_ABS_rational_TOTAL_baseline  x_ATS_Generalization_TOTAL_baseline  ...  \\\n",
       "0                           26.0                                  8.0  ...   \n",
       "1                           26.0                                  8.0  ...   \n",
       "2                           26.0                                  8.0  ...   \n",
       "3                           26.0                                  8.0  ...   \n",
       "4                           48.0                                 10.0  ...   \n",
       "\n",
       "   x_mental_health_last_month_baseline_value_5  \\\n",
       "0                                            0   \n",
       "1                                            0   \n",
       "2                                            0   \n",
       "3                                            0   \n",
       "4                                            0   \n",
       "\n",
       "   x_stress_management_first_day_value_0  \\\n",
       "0                                      0   \n",
       "1                                      0   \n",
       "2                                      0   \n",
       "3                                      0   \n",
       "4                                      0   \n",
       "\n",
       "   x_stress_management_first_day_value_1  \\\n",
       "0                                      0   \n",
       "1                                      1   \n",
       "2                                      1   \n",
       "3                                      1   \n",
       "4                                      0   \n",
       "\n",
       "   x_stress_management_first_day_value_2  x_participant_id  \\\n",
       "0                                      1                 0   \n",
       "1                                      0                 0   \n",
       "2                                      0                 0   \n",
       "3                                      0                 0   \n",
       "4                                      1                 2   \n",
       "\n",
       "   x_GHQ_TOTAL_score_category_first_day  x_time_copy  \\\n",
       "0                                     1          0.0   \n",
       "1                                     0          1.0   \n",
       "2                                     1          4.0   \n",
       "3                                     0          5.0   \n",
       "4                                     1          0.0   \n",
       "\n",
       "   x_time_difference_first_day  y_GHQ_TOTAL_score_category_next  \\\n",
       "0                          1.0                              0.0   \n",
       "1                          3.0                              1.0   \n",
       "2                          1.0                              0.0   \n",
       "3                          3.0                              0.0   \n",
       "4                          2.0                              1.0   \n",
       "\n",
       "   x_time_difference_first_day_copy  \n",
       "0                               1.0  \n",
       "1                               3.0  \n",
       "2                               1.0  \n",
       "3                               3.0  \n",
       "4                               2.0  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GHQ_cat_df = pd.read_csv(os.path.join(data_dir, \"PED_GHQ_categorical_data_forecast.csv\"))\n",
    "columns_GHQ_cat_df = pd.read_csv(os.path.join(data_dir, \"columns_PED_GHQ_categorical_data_forecast.csv\"))\n",
    "\n",
    "GHQ_cat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c174fcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the outcome column(s) marked with 1 in the \"outcomes\" column of columns_GHQ_cat_df\n",
    "GHQ_cat_outcome_cols = columns_GHQ_cat_df.loc[columns_GHQ_cat_df['outcomes'] == 1, 'column_name'].tolist()\n",
    "GHQ_cat_y = GHQ_cat_df[GHQ_cat_outcome_cols]\n",
    "GHQ_cat_y.head()\n",
    "\n",
    "# Same for outcomes lags column(s)\n",
    "GHQ_cat_outcomes_lags_cols = columns_GHQ_cat_df.loc[columns_GHQ_cat_df['outcomes_lags'] == 1, 'column_name'].tolist()\n",
    "GHQ_cat_outcomes_lags = GHQ_cat_df[GHQ_cat_outcomes_lags_cols]\n",
    "\n",
    "# Same for participant column(s)\n",
    "GHQ_cat_participant_cols = columns_GHQ_cat_df.loc[columns_GHQ_cat_df['participant_id'] == 1, 'column_name'].tolist()\n",
    "GHQ_cat_participant_id = GHQ_cat_df[GHQ_cat_participant_cols]\n",
    "\n",
    "# Same for time column(s)\n",
    "GHQ_cat_time_cols = columns_GHQ_cat_df.loc[columns_GHQ_cat_df['time'] == 1, 'column_name'].tolist()\n",
    "GHQ_cat_time = GHQ_cat_df[GHQ_cat_time_cols]\n",
    "\n",
    "# Same for forecast horizons column(s)\n",
    "GHQ_cat_forecast_horizons_cols = columns_GHQ_cat_df.loc[columns_GHQ_cat_df['forecast_horizons'] == 1, 'column_name'].tolist()\n",
    "GHQ_cat_forecast_horizons = GHQ_cat_df[GHQ_cat_forecast_horizons_cols]\n",
    "\n",
    "# Same for fixed effects column(s)\n",
    "GHQ_cat_only_fixed_cols = columns_GHQ_cat_df.loc[columns_GHQ_cat_df['only_fixed'] == 1, 'column_name'].tolist()\n",
    "GHQ_cat_only_fixed = GHQ_cat_df[GHQ_cat_only_fixed_cols]\n",
    "\n",
    "# Same for random effects column(s)\n",
    "GHQ_cat_fixed_and_random_cols = columns_GHQ_cat_df.loc[columns_GHQ_cat_df['fixed_and_random'] == 1, 'column_name'].tolist()\n",
    "GHQ_cat_fixed_and_random = GHQ_cat_df[GHQ_cat_fixed_and_random_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de618133",
   "metadata": {},
   "source": [
    "# ARMED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916c36bf",
   "metadata": {},
   "source": [
    "## Architecutre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ce60db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple, Dict, Any, Iterable\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GradientReversalFn(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, lambd: float):\n",
    "        ctx.lambd = float(lambd)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return -ctx.lambd * grad_output, None\n",
    "\n",
    "\n",
    "class GradientReversal(nn.Module):\n",
    "    def __init__(self, lambd: float = 1.0):\n",
    "        super().__init__()\n",
    "        self.lambd = float(lambd)\n",
    "\n",
    "    def set_lambda(self, lambd: float):\n",
    "        self.lambd = float(lambd)\n",
    "    def forward(self, x):\n",
    "        return GradientReversalFn.apply(x, self.lambd)\n",
    "\n",
    "\n",
    "def mlp(in_dim: int, hidden: Iterable[int], out_dim: int, dropout: float = 0.0, last_activation: Optional[nn.Module] = None):\n",
    "    layers: list[nn.Module] = []\n",
    "    dims = [in_dim] + list(hidden)\n",
    "    for d0, d1 in zip(dims[:-1], dims[1:]):\n",
    "        layers.append(nn.Linear(d0, d1))\n",
    "        layers.append(nn.ReLU())\n",
    "        if dropout > 0:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "    layers.append(nn.Linear(dims[-1], out_dim))\n",
    "    if last_activation is not None:\n",
    "        layers.append(last_activation)\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class FixedAE(nn.Module):\n",
    "    def __init__(self, in_dim: int, enc_hidden=(128, 64), rep_dim=32, dropout=0.0,\n",
    "                 use_decoder: bool = False, dec_hidden: Optional[Iterable[int]] = None):\n",
    "        super().__init__()\n",
    "        self.encoder = mlp(in_dim, enc_hidden, rep_dim, dropout)\n",
    "        self.use_decoder = bool(use_decoder)\n",
    "        if self.use_decoder:\n",
    "            dec_hidden = list(dec_hidden) if dec_hidden is not None else list(enc_hidden)[::-1]\n",
    "            self.decoder = mlp(rep_dim, dec_hidden, in_dim, dropout)\n",
    "        else:\n",
    "            self.decoder = None\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n",
    "        z = self.encoder(x)\n",
    "        xhat = self.decoder(z) if self.decoder is not None else None\n",
    "        return z, xhat\n",
    "\n",
    "\n",
    "class RandomEnc(nn.Module):\n",
    "    def __init__(self, in_dim: int, hidden=(128, 64), rep_dim=32, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.net = mlp(in_dim, hidden, rep_dim, dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class ParticipantEmbedding(nn.Module):\n",
    "    def __init__(self, n_participants: int, rep_dim: int):\n",
    "        super().__init__()\n",
    "        self.n_seen = int(n_participants)\n",
    "        self.unk_index = self.n_seen\n",
    "        self.emb = nn.Embedding(self.n_seen + 1, rep_dim, padding_idx=None)\n",
    "\n",
    "    def forward(self, pid_idx: torch.Tensor) -> torch.Tensor:\n",
    "        # Map unseen (-1) → UNK\n",
    "        idx = pid_idx.clone()\n",
    "        idx = torch.where(idx >= 0, idx, torch.full_like(idx, self.unk_index))\n",
    "        return self.emb(idx)\n",
    "\n",
    "\n",
    "class FiLM(nn.Module):\n",
    "    def __init__(self, rep_dim: int, hidden=(64,), dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.gamma = mlp(rep_dim, hidden, rep_dim, dropout)\n",
    "        self.beta  = mlp(rep_dim, hidden, rep_dim, dropout)\n",
    "\n",
    "    def forward(self, z_id: torch.Tensor, z_obs: torch.Tensor) -> torch.Tensor:\n",
    "        # Stabilized residual scaling: gamma centered near 1, beta near 0\n",
    "        g = 1.0 + 0.1 * torch.tanh(self.gamma(z_id))\n",
    "        b = 0.1 * self.beta(z_id)\n",
    "        return g * z_obs + b\n",
    "\n",
    "\n",
    "class Adversary(nn.Module):\n",
    "    def __init__(self, in_dim: int, hidden=(64,), n_participants: int = 1,\n",
    "                 dropout: float = 0.0, grl_lambda: float = 1.0):\n",
    "        super().__init__()\n",
    "        self.grl = GradientReversal(grl_lambda)\n",
    "        self.net = mlp(in_dim, hidden, n_participants, dropout)\n",
    "\n",
    "    def set_lambda(self, lambd: float):\n",
    "        self.grl.set_lambda(lambd)\n",
    "\n",
    "    def forward(self, z_fixed: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(self.grl(z_fixed))\n",
    "\n",
    "class ARMEDTabular(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_fixed: int,\n",
    "        d_random: int = 0,\n",
    "        y_dim: int = 1,\n",
    "        n_participants: int = 1,\n",
    "        include_random_data: bool = True,\n",
    "        \n",
    "        fixed_enc_hidden=(128, 64),\n",
    "        fixed_rep_dim: int = 32,\n",
    "        fixed_dropout: float = 0.0,\n",
    "        use_fixed_decoder: bool = False,\n",
    "        fixed_dec_hidden: Optional[Iterable[int]] = None,\n",
    "\n",
    "        random_hidden=(128, 64),\n",
    "        random_rep_dim: int = 32,\n",
    "        random_dropout: float = 0.0,\n",
    "        combine_mode: str = \"add\",   # \"add\" or \"film\"\n",
    "        film_hidden=(64,),\n",
    "        film_dropout: float = 0.0,\n",
    "\n",
    "\n",
    "        adv_hidden=(64,),\n",
    "        adv_dropout: float = 0.0,\n",
    "        grl_lambda: float = 1.0,\n",
    "        head_hidden=(64,),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.include_random_data = bool(include_random_data and d_random > 0)\n",
    "\n",
    "        self.fixed = FixedAE(\n",
    "            in_dim=d_fixed,\n",
    "            enc_hidden=fixed_enc_hidden,\n",
    "            rep_dim=fixed_rep_dim,\n",
    "            dropout=fixed_dropout,\n",
    "            use_decoder=use_fixed_decoder,\n",
    "            dec_hidden=fixed_dec_hidden,\n",
    "        )\n",
    "\n",
    "        self.id_emb = ParticipantEmbedding(n_participants, rep_dim=random_rep_dim)\n",
    "\n",
    "        self.random = RandomEnc(\n",
    "            in_dim=d_random,\n",
    "            hidden=random_hidden,\n",
    "            rep_dim=random_rep_dim,\n",
    "            dropout=random_dropout,\n",
    "        ) if self.include_random_data else None\n",
    "\n",
    "        self.combine_mode = combine_mode\n",
    "        if combine_mode not in {\"add\", \"film\"}:\n",
    "            raise ValueError(\"combine_mode must be 'add' or 'film'\")\n",
    "        self.film = FiLM(rep_dim=random_rep_dim, hidden=film_hidden, dropout=film_dropout) if combine_mode == \"film\" else None\n",
    "\n",
    "        self.head = mlp(fixed_rep_dim + random_rep_dim, head_hidden, y_dim, dropout=0.0)\n",
    "        self.adv  = Adversary(fixed_rep_dim, adv_hidden, n_participants, adv_dropout, grl_lambda)\n",
    "\n",
    "        self.norm_f = nn.LayerNorm(fixed_rep_dim)\n",
    "        self.norm_r = nn.LayerNorm(random_rep_dim)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x_fixed: torch.Tensor,\n",
    "        pid_idx: torch.Tensor,\n",
    "        x_random: Optional[torch.Tensor] = None\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, Optional[torch.Tensor], torch.Tensor, torch.Tensor]:\n",
    "\n",
    "        z_f, xhat = self.fixed(x_fixed)\n",
    "        z_f = self.norm_f(z_f)\n",
    "\n",
    "        z_id = self.id_emb(pid_idx)  \n",
    "        if self.include_random_data and (x_random is not None):\n",
    "            z_r_obs = self.random(x_random)\n",
    "            if self.combine_mode == \"add\":\n",
    "                z_r = z_r_obs + z_id\n",
    "            else:\n",
    "                z_r = self.film(z_id, z_r_obs)\n",
    "        else:\n",
    "            z_r = z_id\n",
    "        z_r = self.norm_r(z_r)\n",
    "\n",
    "        y_logits  = self.head(torch.cat([z_f, z_r], dim=1))\n",
    "        adv_logits = self.adv(z_f)\n",
    "\n",
    "        return y_logits, adv_logits, xhat, z_f, z_r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e898a0",
   "metadata": {},
   "source": [
    "## Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "788fdf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple, Dict, Any, Iterable, Sequence\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ARMEDLossWeights:\n",
    "    lambda_adv: float = 1.0\n",
    "    lambda_recon: float = 0.0\n",
    "\n",
    "\n",
    "class ARMEDWrapper:\n",
    "    \"\"\"\n",
    "    Wrapper around ARMEDTabular adding:\n",
    "      - device management\n",
    "      - loss computation (unchanged)\n",
    "      - validation/prediction helpers (unchanged)\n",
    "      - NEW: per-task F1-optimal threshold selection utilities\n",
    "             * find_best_thresholds_f1_from_arrays(y_true, y_prob)\n",
    "             * find_best_thresholds_f1_from_loader(loader)\n",
    "             * set_thresholds(thresholds)\n",
    "             * predict_with_thresholds(..., thresholds=...) / predict_using_stored_thresholds(...)\n",
    "    \"\"\"\n",
    "    def __init__(self, model: nn.Module, loss_weights: Optional[ARMEDLossWeights] = None, device: Optional[torch.device] = None):\n",
    "        self.model = model\n",
    "        self.loss_w = loss_weights or ARMEDLossWeights()\n",
    "        self.device = (device\n",
    "                       or (torch.device(\"mps\") if torch.backends.mps.is_available() else None)\n",
    "                       or (torch.device(\"cuda\") if torch.cuda.is_available() else None)\n",
    "                       or torch.device(\"cpu\"))\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # Holds per-task thresholds after selection (numpy array shape [y_dim])\n",
    "        self.thresholds_: Optional[np.ndarray] = None\n",
    "\n",
    "    def forward(self, x_fixed: torch.Tensor, pid_idx: torch.Tensor, x_random: Optional[torch.Tensor] = None):\n",
    "        return self.model(x_fixed, pid_idx, x_random)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Loss components (unchanged)\n",
    "    # -----------------------------\n",
    "    def _pred_loss(self, logits: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "        return F.binary_cross_entropy_with_logits(logits, y_true.float())\n",
    "\n",
    "    def _adv_loss(self, adv_logits: torch.Tensor, pid_idx: torch.Tensor) -> torch.Tensor:\n",
    "        seen_mask = (pid_idx >= 0)\n",
    "        if seen_mask.any():\n",
    "            return F.cross_entropy(adv_logits[seen_mask], pid_idx[seen_mask])\n",
    "        else:\n",
    "            return torch.tensor(0.0, device=adv_logits.device)\n",
    "\n",
    "    def _recon_loss(self, xhat: Optional[torch.Tensor], x: torch.Tensor) -> torch.Tensor:\n",
    "        if (xhat is None) or (self.loss_w.lambda_recon <= 0.0):\n",
    "            return torch.tensor(0.0, device=x.device)\n",
    "        return F.mse_loss(xhat, x)\n",
    "\n",
    "    def compute_losses(\n",
    "        self,\n",
    "        y_true: torch.Tensor,\n",
    "        y_logits: torch.Tensor,\n",
    "        adv_logits: torch.Tensor,\n",
    "        xhat: Optional[torch.Tensor],\n",
    "        x_fixed: torch.Tensor,\n",
    "        pid_idx: torch.Tensor,\n",
    "    ) -> Tuple[torch.Tensor, Dict[str, float]]:\n",
    "        lp = self._pred_loss(y_logits, y_true)\n",
    "        la = self._adv_loss(adv_logits, pid_idx)\n",
    "        lr = self._recon_loss(xhat, x_fixed)\n",
    "\n",
    "        total = lp + self.loss_w.lambda_adv * la + self.loss_w.lambda_recon * lr\n",
    "\n",
    "        parts = {\n",
    "            \"loss_total\": float(total.detach().cpu()),\n",
    "            \"loss_pred\":  float(lp.detach().cpu()),\n",
    "            \"loss_adv\":   float(la.detach().cpu()),\n",
    "            \"loss_recon\": float(lr.detach().cpu()),\n",
    "        }\n",
    "        return total, parts\n",
    "\n",
    "    # -----------------------------\n",
    "    # Eval / predict helpers\n",
    "    # -----------------------------\n",
    "    @torch.no_grad()\n",
    "    def validation_step(\n",
    "        self,\n",
    "        x_fixed: torch.Tensor,\n",
    "        pid_idx: torch.Tensor,\n",
    "        y_true: torch.Tensor,\n",
    "        x_random: Optional[torch.Tensor] = None,\n",
    "        prefix: str = \"val\"\n",
    "    ) -> Tuple[torch.Tensor, Dict[str, float]]:\n",
    "        self.model.eval()\n",
    "        x_fixed = x_fixed.to(self.device)\n",
    "        pid_idx = pid_idx.to(self.device)\n",
    "        y_true  = y_true.to(self.device)\n",
    "        x_random = x_random.to(self.device) if x_random is not None else None\n",
    "\n",
    "        y_logits, adv_logits, xhat, _, _ = self.forward(x_fixed, pid_idx, x_random)\n",
    "        loss, parts = self.compute_losses(y_true, y_logits, adv_logits, xhat, x_fixed, pid_idx)\n",
    "\n",
    "        print(\n",
    "            f\"{prefix}_loss: {parts['loss_total']:.6f} | \"\n",
    "            f\"pred: {parts['loss_pred']:.6f} | \"\n",
    "            f\"adv: {parts['loss_adv']:.6f} | \"\n",
    "            f\"recon: {parts['loss_recon']:.6f}\"\n",
    "        )\n",
    "        return loss, parts\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict_logits(\n",
    "        self,\n",
    "        x_fixed: torch.Tensor,\n",
    "        pid_idx: torch.Tensor,\n",
    "        x_random: Optional[torch.Tensor] = None\n",
    "    ) -> torch.Tensor:\n",
    "        self.model.eval()\n",
    "        x_fixed = x_fixed.to(self.device)\n",
    "        pid_idx = pid_idx.to(self.device)\n",
    "        x_random = x_random.to(self.device) if x_random is not None else None\n",
    "        y_logits, _, _, _, _ = self.forward(x_fixed, pid_idx, x_random)\n",
    "        return y_logits\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict_proba(self, *args, **kwargs) -> torch.Tensor:\n",
    "        logits = self.predict_logits(*args, **kwargs)\n",
    "        return torch.sigmoid(logits)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict(self, *args, threshold: float = 0.5, **kwargs) -> torch.Tensor:\n",
    "        proba = self.predict_proba(*args, **kwargs)\n",
    "        return (proba >= threshold).to(torch.int32)\n",
    "\n",
    "    # -----------------------------\n",
    "    # NEW: F1-optimal thresholds\n",
    "    # -----------------------------\n",
    "    @staticmethod\n",
    "    def _best_threshold_f1_1d(y_true: np.ndarray, y_prob: np.ndarray) -> Tuple[float, float]:\n",
    "        \"\"\"\n",
    "        Exact F1 maximizing threshold for a single task by scanning the midpoints\n",
    "        between unique scores (plus endpoints). Returns (best_thr, best_f1).\n",
    "        \"\"\"\n",
    "        y_true = y_true.astype(int).ravel()\n",
    "        y_prob = y_prob.astype(float).ravel()\n",
    "        if y_prob.size == 0:\n",
    "            return 0.5, 0.0\n",
    "\n",
    "        # Sort unique scores and consider midpoints between them\n",
    "        scores = np.unique(y_prob)\n",
    "        # Edge case: constant probabilities\n",
    "        if scores.size == 1:\n",
    "            thr = scores[0]\n",
    "            y_pred = (y_prob >= thr).astype(int)\n",
    "            tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "            fp = np.sum((y_pred == 1) & (y_true == 0))\n",
    "            fn = np.sum((y_pred == 0) & (y_true == 1))\n",
    "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "            recall    = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "            return float(thr), float(f1)\n",
    "\n",
    "        mids = (scores[:-1] + scores[1:]) / 2.0\n",
    "        # include slightly outside endpoints to catch all regimes\n",
    "        candidates = np.concatenate(([scores[0] - 1e-12], mids, [scores[-1] + 1e-12]))\n",
    "\n",
    "        best_f1, best_thr = -1.0, 0.5\n",
    "        for thr in candidates:\n",
    "            y_pred = (y_prob >= thr).astype(int)\n",
    "            tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "            fp = np.sum((y_pred == 1) & (y_true == 0))\n",
    "            fn = np.sum((y_pred == 0) & (y_true == 1))\n",
    "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "            recall    = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "            if f1 > best_f1 or (f1 == best_f1 and thr < best_thr):\n",
    "                best_f1, best_thr = f1, thr\n",
    "\n",
    "        return float(best_thr), float(best_f1)\n",
    "\n",
    "    @classmethod\n",
    "    def find_best_thresholds_f1_from_arrays(\n",
    "        cls,\n",
    "        y_true: np.ndarray,\n",
    "        y_prob: np.ndarray\n",
    "    ) -> Tuple[np.ndarray, Dict[str, float]]:\n",
    "        \"\"\"\n",
    "        y_true, y_prob: arrays of shape [N, y_dim] (or [N] for single task).\n",
    "        Returns:\n",
    "          - thresholds: np.ndarray of shape [y_dim]\n",
    "          - summary: dict with per-task F1 and macro_F1\n",
    "        \"\"\"\n",
    "        y_true = np.asarray(y_true)\n",
    "        y_prob = np.asarray(y_prob)\n",
    "        if y_true.ndim == 1:\n",
    "            y_true = y_true[:, None]\n",
    "        if y_prob.ndim == 1:\n",
    "            y_prob = y_prob[:, None]\n",
    "        assert y_true.shape == y_prob.shape, \"y_true and y_prob must have same shape\"\n",
    "\n",
    "        y_dim = y_true.shape[1]\n",
    "        thresholds = np.zeros(y_dim, dtype=float)\n",
    "        f1s = np.zeros(y_dim, dtype=float)\n",
    "\n",
    "        for j in range(y_dim):\n",
    "            thr, f1 = cls._best_threshold_f1_1d(y_true[:, j], y_prob[:, j])\n",
    "            thresholds[j] = thr\n",
    "            f1s[j] = f1\n",
    "\n",
    "        summary = {f\"task_{j+1}_F1_opt\": float(f1s[j]) for j in range(y_dim)}\n",
    "        summary[\"macro_F1_opt\"] = float(np.nanmean(f1s))\n",
    "        return thresholds, summary\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def find_best_thresholds_f1_from_loader(self, loader) -> Tuple[np.ndarray, Dict[str, float]]:\n",
    "        \"\"\"\n",
    "        Computes per-task F1-optimal thresholds using predictions on the given loader.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        probs_all, y_all = [], []\n",
    "        for Xf_b, pid_b, Xr_b, y_b in loader:\n",
    "            logits = self.predict_logits(Xf_b, pid_b, Xr_b if Xr_b.size(1) > 0 else None)\n",
    "            probs_all.append(torch.sigmoid(logits).cpu().numpy())\n",
    "            y_all.append(y_b.cpu().numpy())\n",
    "\n",
    "        y_prob = np.vstack(probs_all)\n",
    "        y_true = np.vstack(y_all)\n",
    "        thresholds, summary = self.find_best_thresholds_f1_from_arrays(y_true, y_prob)\n",
    "        return thresholds, summary\n",
    "\n",
    "    def set_thresholds(self, thresholds: Sequence[float]) -> None:\n",
    "        th = np.asarray(thresholds, dtype=float).ravel()\n",
    "        self.thresholds_ = th\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict_with_thresholds(\n",
    "        self,\n",
    "        x_fixed: torch.Tensor,\n",
    "        pid_idx: torch.Tensor,\n",
    "        x_random: Optional[torch.Tensor] = None,\n",
    "        thresholds: Optional[Sequence[float]] = None\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Predict labels using provided per-task thresholds (or stored thresholds_ if None).\n",
    "        Returns an int32 tensor of shape [N, y_dim].\n",
    "        \"\"\"\n",
    "        probs = self.predict_proba(x_fixed, pid_idx, x_random)\n",
    "        if thresholds is None:\n",
    "            if self.thresholds_ is None:\n",
    "                raise ValueError(\"No thresholds provided and self.thresholds_ is not set.\")\n",
    "            thr = torch.as_tensor(self.thresholds_, device=probs.device, dtype=probs.dtype).view(1, -1)\n",
    "        else:\n",
    "            thr = torch.as_tensor(np.asarray(thresholds, dtype=float), device=probs.device, dtype=probs.dtype).view(1, -1)\n",
    "        return (probs >= thr).to(torch.int32)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict_using_stored_thresholds(\n",
    "        self,\n",
    "        x_fixed: torch.Tensor,\n",
    "        pid_idx: torch.Tensor,\n",
    "        x_random: Optional[torch.Tensor] = None\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Convenience wrapper that uses self.thresholds_ (must be set).\n",
    "        \"\"\"\n",
    "        return self.predict_with_thresholds(x_fixed, pid_idx, x_random, thresholds=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea48953",
   "metadata": {},
   "source": [
    "## Evaluation procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b982099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, Optional, Tuple, Iterable, List\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, TimeSeriesSplit, ParameterGrid\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import t as student_t\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Dataset / loaders\n",
    "# -------------------------------------------------------------------\n",
    "class _ARMEDDataset(Dataset):\n",
    "    def __init__(self, Xf, pid_idx, y, Xr=None, device=None):\n",
    "        device = device or torch.device(\"cpu\")\n",
    "        Xf  = np.asarray(Xf, dtype=np.float32)\n",
    "        y   = np.asarray(y,  dtype=np.float32)\n",
    "        pid = np.asarray(pid_idx)\n",
    "\n",
    "        if y.ndim == 1:\n",
    "            y = y[:, None]\n",
    "\n",
    "        self.Xf  = torch.as_tensor(Xf, dtype=torch.float32, device=device)\n",
    "        self.pid = torch.as_tensor(pid, dtype=torch.long,    device=device)\n",
    "        self.y   = torch.as_tensor(y,  dtype=torch.float32,  device=device)\n",
    "\n",
    "        if Xr is None:\n",
    "            self.Xr = torch.zeros((len(self.Xf), 0), dtype=torch.float32, device=device)\n",
    "        else:\n",
    "            Xr = np.asarray(Xr, dtype=np.float32)\n",
    "            self.Xr = torch.as_tensor(Xr, dtype=torch.float32, device=device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.Xf.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.Xf[idx], self.pid[idx], self.Xr[idx], self.y[idx]\n",
    "\n",
    "def _make_loader(Xf, pid_idx, y, Xr=None, batch_size=256, shuffle=False, device=None):\n",
    "    ds = _ARMEDDataset(Xf, pid_idx, y, Xr=Xr, device=device)\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=shuffle, num_workers=0, drop_last=False)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Metrics\n",
    "# -------------------------------------------------------------------\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score,\n",
    "    precision_recall_fscore_support, confusion_matrix\n",
    ")\n",
    "\n",
    "def _metrics_binary_full(y_true, y_prob, thr=0.5) -> Dict[str, float]:\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_prob = np.asarray(y_prob).astype(float)\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "\n",
    "    # Threshold-independent metrics\n",
    "    try:\n",
    "        auc = float(roc_auc_score(y_true, y_prob))\n",
    "    except Exception:\n",
    "        auc = float(\"nan\")\n",
    "    try:\n",
    "        auprc = float(average_precision_score(y_true, y_prob))\n",
    "    except Exception:\n",
    "        auprc = float(\"nan\")\n",
    "\n",
    "    # NEW: Brier score (lower is better)\n",
    "    brier = float(np.mean((y_prob - y_true) ** 2))\n",
    "    # (If you prefer sklearn: from sklearn.metrics import brier_score_loss; brier = float(brier_score_loss(y_true, y_prob)))\n",
    "\n",
    "    # Thresholded metrics\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='binary', zero_division=0\n",
    "    )\n",
    "    acc = float((y_pred == y_true).mean())\n",
    "    try:\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "        sens = float(tp / (tp + fn)) if (tp + fn) > 0 else float(\"nan\")\n",
    "        spec = float(tn / (tn + fp)) if (tn + fp) > 0 else float(\"nan\")\n",
    "    except Exception:\n",
    "        sens, spec = float(\"nan\"), float(\"nan\")\n",
    "\n",
    "    return {\n",
    "        \"AUC\": auc,\n",
    "        \"AUPRC\": auprc,\n",
    "        \"Brier\": brier,          # <— added\n",
    "        \"ACC\": acc,\n",
    "        \"F1\": float(f1),\n",
    "        \"Precision\": float(prec),\n",
    "        \"Recall\": float(rec),\n",
    "        \"Sensitivity\": sens,\n",
    "        \"Specificity\": spec,\n",
    "    }\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from typing import Dict, Any\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "def compute_calibration_curves(\n",
    "    y_true: np.ndarray,\n",
    "    y_prob: np.ndarray,\n",
    "    n_bins: int = 10,\n",
    "    strategy: str = \"quantile\",   # \"uniform\" or \"quantile\"\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      {\n",
    "        \"per_task\": {\n",
    "          0: {\"mean_pred\": [...], \"frac_pos\": [...], \"counts\": [...], \"ece\": float, \"mce\": float, \"brier\": float},\n",
    "          1: {...}, ...\n",
    "        },\n",
    "        \"macro_ECE\": float,\n",
    "        \"macro_MCE\": float,\n",
    "      }\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_prob = np.asarray(y_prob)\n",
    "    assert y_true.shape == y_prob.shape\n",
    "    y_dim = y_true.shape[1] if y_true.ndim == 2 else 1\n",
    "    if y_true.ndim == 1:\n",
    "        y_true = y_true[:, None]\n",
    "        y_prob = y_prob[:, None]\n",
    "\n",
    "    per_task = {}\n",
    "    eces, mces = [], []\n",
    "\n",
    "    for j in range(y_dim):\n",
    "        t = y_true[:, j].astype(int)\n",
    "        p = np.clip(y_prob[:, j].astype(float), 1e-6, 1.0 - 1e-6)\n",
    "\n",
    "        # Try to build bins; if only one class present, fall back to NaNs\n",
    "        try:\n",
    "            frac_pos, mean_pred = calibration_curve(t, p, n_bins=n_bins, strategy=strategy)\n",
    "        except Exception:\n",
    "            frac_pos = np.array([])\n",
    "            mean_pred = np.array([])\n",
    "\n",
    "        # Reconstruct bin edges and counts to weight ECE properly\n",
    "        if strategy == \"uniform\":\n",
    "            edges = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "        else:\n",
    "            # quantile bins over predictions\n",
    "            qs = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "            edges = np.quantile(p, qs)\n",
    "            edges[0], edges[-1] = 0.0, 1.0\n",
    "\n",
    "        bin_ids = np.digitize(p, edges[1:-1], right=True)  # 0..n_bins-1\n",
    "        counts = np.bincount(bin_ids, minlength=n_bins).astype(float)\n",
    "        N = max(1, len(p))\n",
    "\n",
    "        # Align counts to the returned bins (calibration_curve may drop empty bins)\n",
    "        # Map each returned mean_pred to its bin to pull the right weight\n",
    "        # If shapes match, we can compute directly; otherwise do a safe join.\n",
    "        if len(mean_pred) == n_bins:\n",
    "            weights = counts / N\n",
    "        else:\n",
    "            # Safe mapping by nearest edge (rare when calibration_curve prunes empties)\n",
    "            weights = np.zeros_like(mean_pred, dtype=float)\n",
    "            if len(mean_pred) > 0:\n",
    "                # find each mean_pred's bin index\n",
    "                idxs = np.digitize(mean_pred, edges[1:-1], right=True)\n",
    "                weights = counts[idxs] / N\n",
    "\n",
    "        # ECE / MCE\n",
    "        gaps = np.abs(frac_pos - mean_pred) if len(mean_pred) else np.array([np.nan])\n",
    "        ece = float(np.nansum(weights * gaps)) if len(mean_pred) else float(\"nan\")\n",
    "        mce = float(np.nanmax(gaps)) if len(mean_pred) else float(\"nan\")\n",
    "\n",
    "        # Brier (already in your metrics, but handy here too)\n",
    "        brier = float(np.mean((p - t) ** 2)) if N > 0 else float(\"nan\")\n",
    "\n",
    "        per_task[j] = {\n",
    "            \"mean_pred\": mean_pred.tolist(),\n",
    "            \"frac_pos\": frac_pos.tolist(),\n",
    "            \"counts\": counts.tolist(),\n",
    "            \"ece\": ece,\n",
    "            \"mce\": mce,\n",
    "            \"brier\": brier,\n",
    "        }\n",
    "        eces.append(ece); mces.append(mce)\n",
    "\n",
    "    return {\n",
    "        \"per_task\": per_task,\n",
    "        \"macro_ECE\": float(np.nanmean(eces)),\n",
    "        \"macro_MCE\": float(np.nanmean(mces)),\n",
    "    }\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_calibration_curves(calib: Dict[str, Any], task_names=None, suptitle=None):\n",
    "    per_task = calib[\"per_task\"]\n",
    "    for j, d in per_task.items():\n",
    "        mp = np.array(d[\"mean_pred\"], dtype=float)\n",
    "        fp = np.array(d[\"frac_pos\"], dtype=float)\n",
    "        ece = d.get(\"ece\", np.nan)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot([0, 1], [0, 1], linestyle=\"--\", linewidth=1)\n",
    "        if mp.size and fp.size:\n",
    "            plt.plot(mp, fp, marker=\"o\")\n",
    "        name = f\"Task {j+1}\" if not task_names else task_names[j]\n",
    "        plt.title(f\"{name} — Reliability (ECE={ece:.3f})\")\n",
    "        plt.xlabel(\"Mean predicted probability\")\n",
    "        plt.ylabel(\"Observed positive rate\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        if suptitle:\n",
    "            plt.suptitle(suptitle)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_multitask(y_true: np.ndarray, y_prob: np.ndarray, thr=0.5) -> dict:\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_prob = np.asarray(y_prob)\n",
    "    assert y_true.shape == y_prob.shape\n",
    "    y_dim = y_true.shape[1]\n",
    "\n",
    "    out, macro = {}, {}\n",
    "    for j in range(y_dim):\n",
    "        m = _metrics_binary_full(y_true[:, j], y_prob[:, j], thr)\n",
    "        for k, v in m.items():\n",
    "            out[f\"task_{j+1}_{k}\"] = float(v)\n",
    "            macro.setdefault(k, []).append(float(v))\n",
    "\n",
    "    for k, vals in macro.items():\n",
    "        out[f\"macro_{k}\"] = float(np.nanmean(np.array(vals, dtype=float)))\n",
    "    return out\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import t as student_t\n",
    "\n",
    "def _summarize_cv_folds(results_folds: list[dict]) -> dict:\n",
    "    \"\"\"\n",
    "    results_folds: list of per-fold metrics dicts (same keys each fold; missing -> NaN OK)\n",
    "    Returns { \"<metric>_mean\": ..., \"<metric>_95ci_low\": ..., \"<metric>_95ci_high\": ... }\n",
    "    \"\"\"\n",
    "    if not results_folds:\n",
    "        return {}\n",
    "\n",
    "    # Union of all metric keys across folds\n",
    "    all_keys = set().union(*results_folds)\n",
    "    summary = {}\n",
    "\n",
    "    for k in sorted(all_keys):\n",
    "        vals = np.array([fold.get(k, np.nan) for fold in results_folds], dtype=float)\n",
    "        mask = np.isfinite(vals)\n",
    "        n = int(mask.sum())\n",
    "\n",
    "        if n == 0:\n",
    "            m = np.nan; low = np.nan; high = np.nan\n",
    "        elif n == 1:\n",
    "            m = float(vals[mask][0]); low = np.nan; high = np.nan\n",
    "        else:\n",
    "            m = float(np.nanmean(vals))\n",
    "            s = float(np.nanstd(vals, ddof=1))\n",
    "            se = s / np.sqrt(n)\n",
    "            tcrit = float(student_t.ppf(0.975, df=n - 1))\n",
    "            low = m - tcrit * se\n",
    "            high = m + tcrit * se\n",
    "\n",
    "        summary[f\"{k}_mean\"] = m\n",
    "        summary[f\"{k}_95ci_low\"] = low\n",
    "        summary[f\"{k}_95ci_high\"] = high\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# PCA pipelines and helpers\n",
    "# -------------------------------------------------------------------\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "\n",
    "# Safe defaults (tighten if needed)\n",
    "_VAR_EPS = 1e-8   # drop columns with train variance <= this (use 1e-6 if still unstable)\n",
    "_STD_EPS = 1e-6   # minimum std used in scaling\n",
    "_CLIP_Z  = 8.0   # clip z-scores to [-CLIP_Z, CLIP_Z] before PCA\n",
    "\n",
    "@dataclass\n",
    "class PCAPipeline:\n",
    "    keep_mask: np.ndarray         # True = keep column (decided on TRAIN variance)\n",
    "    mean_: np.ndarray             # scaler mean (after masking)\n",
    "    scale_: np.ndarray            # scaler std with epsilon floor (after masking)\n",
    "    pca: PCA\n",
    "\n",
    "def _fit_pca_pipeline(X_train: np.ndarray, var_ratio: float = 0.95, random_state: int | None = None) -> PCAPipeline:\n",
    "    # 1) sanitize + float64 for numerical stability\n",
    "    X = np.asarray(X_train, dtype=np.float64)\n",
    "    X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    # 2) drop near-constant columns on TRAIN ONLY\n",
    "    var = X.var(axis=0)\n",
    "    keep = var > _VAR_EPS\n",
    "    if not np.any(keep):\n",
    "        # degenerate: no usable features\n",
    "        pca = PCA(n_components=0, svd_solver='full', random_state=random_state)\n",
    "        return PCAPipeline(keep_mask=keep, mean_=np.array([], dtype=np.float64),\n",
    "                           scale_=np.array([], dtype=np.float64), pca=pca)\n",
    "\n",
    "    Xk = X[:, keep]\n",
    "\n",
    "    # 3) robust scaling params with epsilon floor\n",
    "    mean = Xk.mean(axis=0)\n",
    "    std  = Xk.std(axis=0)\n",
    "    std  = np.maximum(std, _STD_EPS)\n",
    "\n",
    "    # 4) scale -> sanitize -> clip\n",
    "    Z = (Xk - mean) / std\n",
    "    Z = np.nan_to_num(Z, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    np.clip(Z, -_CLIP_Z, _CLIP_Z, out=Z)\n",
    "\n",
    "    # 5) PCA fit\n",
    "    pca = PCA(n_components=var_ratio, svd_solver='full', random_state=random_state)\n",
    "    pca.fit(Z)\n",
    "    if not np.isfinite(pca.components_).all():\n",
    "        raise RuntimeError(\"PCA components contain non-finite values after fit.\")\n",
    "\n",
    "    return PCAPipeline(keep_mask=keep, mean_=mean, scale_=std, pca=pca)\n",
    "\n",
    "def _transform_pca_pipeline(pipe: PCAPipeline | None, X: np.ndarray | None) -> np.ndarray | None:\n",
    "    \n",
    "    if pipe is None or X is None:\n",
    "        return None\n",
    "\n",
    "    # 1) sanitize + float64\n",
    "    X = np.asarray(X, dtype=np.float64)\n",
    "    X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    # 2) apply TRAIN mask\n",
    "    if pipe.keep_mask.size == 0 or not np.any(pipe.keep_mask):\n",
    "        return np.zeros((X.shape[0], 0), dtype=np.float32)\n",
    "    Xk = X[:, pipe.keep_mask]\n",
    "\n",
    "    # 3) scale with epsilon-protected std; then sanitize & clip\n",
    "    Z = (Xk - pipe.mean_) / pipe.scale_\n",
    "    Z = np.nan_to_num(Z, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    np.clip(Z, -_CLIP_Z, _CLIP_Z, out=Z)\n",
    "\n",
    "\n",
    "    if not np.isfinite(Z).all():\n",
    "        bad = np.argwhere(~np.isfinite(Z))[0]\n",
    "        raise RuntimeError(f\"[our PCA] Z non-finite at {tuple(bad)}: {Z[tuple(bad)]}\")\n",
    "    if np.abs(Z).max() > 1e6:\n",
    "        raise RuntimeError(f\"[our PCA] Z max |z| too large: {np.abs(Z).max()}\")\n",
    "    if not np.isfinite(pipe.pca.components_).all():\n",
    "        raise RuntimeError(\"[our PCA] components_ non-finite\")\n",
    "    if hasattr(pipe.pca, \"mean_\") and not np.isfinite(pipe.pca.mean_).all():\n",
    "        raise RuntimeError(\"[our PCA] mean_ non-finite\")\n",
    "\n",
    "    # 4) PCA transform (manual projection in float64, then cast)\n",
    "    Z64 = np.ascontiguousarray(Z, dtype=np.float64)\n",
    "    CT  = np.ascontiguousarray(pipe.pca.components_.T, dtype=np.float64)\n",
    "\n",
    "    \n",
    "    with np.errstate(over='ignore', invalid='ignore', divide='ignore'):\n",
    "        Xt = Z64 @ CT\n",
    "\n",
    "    # ensure strictly finite output (belt & suspenders)\n",
    "    Xt = np.nan_to_num(Xt, nan=0.0, posinf=0.0, neginf=0.0).astype(np.float32)\n",
    "    return Xt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _concat_safe(*arrays: Optional[np.ndarray]) -> np.ndarray:\n",
    "    parts = [a for a in arrays if a is not None and a.size > 0]\n",
    "    if not parts:\n",
    "        return np.zeros((0, 0), dtype=np.float32)\n",
    "    return np.concatenate(parts, axis=1).astype(np.float32)\n",
    "\n",
    "def _filter_time_test_min_measurements(pid_idx: np.ndarray, test_idx: np.ndarray, min_meas: int = 3):\n",
    "    \"\"\"Keep only rows in test_idx belonging to pids with >= min_meas measurements overall.\"\"\"\n",
    "    pid = np.asarray(pid_idx)\n",
    "    counts = {pid_val: np.sum(pid == pid_val) for pid_val in np.unique(pid)}\n",
    "    keep = [i for i in test_idx if counts.get(pid[i], 0) >= min_meas]\n",
    "    return np.array(keep, dtype=int)\n",
    "\n",
    "def _evaluate_with_thresholds(y_true: np.ndarray, y_prob: np.ndarray, thresholds: np.ndarray) -> Dict[str, float]:\n",
    "    y_true = np.asarray(y_true); y_prob = np.asarray(y_prob)\n",
    "    if y_true.ndim == 1: y_true = y_true[:, None]\n",
    "    if y_prob.ndim == 1: y_prob = y_prob[:, None]\n",
    "    y_dim = y_true.shape[1]\n",
    "    out, macro = {}, {}\n",
    "    for j in range(y_dim):\n",
    "        thr = thresholds[j]\n",
    "        m = _metrics_binary_full(y_true[:, j], y_prob[:, j], thr)\n",
    "        for k, v in m.items():\n",
    "            out[f\"task_{j+1}_{k}_optthr\"] = float(v)\n",
    "            macro.setdefault(k, []).append(float(v))\n",
    "    for k, vals in macro.items():\n",
    "        out[f\"macro_{k}_optthr\"] = float(np.nanmean(np.array(vals, dtype=float)))\n",
    "    return out\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Splitting\n",
    "# -------------------------------------------------------------------\n",
    "def _split_cases(pid_array, test_fraction=0.2, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    unique_ids = np.unique(pid_array)\n",
    "    te_ids = rng.choice(unique_ids, size=max(1, int(len(unique_ids) * test_fraction)), replace=False)\n",
    "    te_mask = np.isin(pid_array, te_ids)\n",
    "    return np.where(~te_mask)[0], np.where(te_mask)[0]\n",
    "\n",
    "def _split_time_basic(time_index, test_fraction=0.2):\n",
    "    order = np.argsort(time_index)\n",
    "    n = len(order)\n",
    "    split = int(np.floor(n * (1.0 - test_fraction)))\n",
    "    return order[:split], order[split:]\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Train loop (prints train & monitor; early stop on val loss by default)\n",
    "# -------------------------------------------------------------------\n",
    "def _eval_macro_auc_on_loader(wrapper, loader: DataLoader) -> float:\n",
    "    wrapper.model.eval()\n",
    "    probs_all, y_all = [], []\n",
    "    with torch.no_grad():\n",
    "        for Xf_b, pid_b, Xr_b, y_b in loader:\n",
    "            logits = wrapper.predict_logits(Xf_b, pid_b, Xr_b if Xr_b.size(1) > 0 else None)\n",
    "            probs_all.append(torch.sigmoid(logits).cpu().numpy())\n",
    "            y_all.append(y_b.cpu().numpy())\n",
    "    y_prob = np.vstack(probs_all); y_true = np.vstack(y_all)\n",
    "    m = evaluate_multitask(y_true, y_prob, thr=0.5)\n",
    "    return float(m.get(\"macro_AUC\", np.nan))\n",
    "\n",
    "def _fit_once(\n",
    "    wrapper, optimizer,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: Optional[DataLoader],          # used for early stopping (default)\n",
    "    monitor_loader: Optional[DataLoader],      # printed each epoch; often the test set\n",
    "    max_epochs: int = 100,\n",
    "    patience: int = 10,\n",
    "    early_stop_metric: str = \"loss\",           # \"loss\" | \"macro_AUC\"\n",
    "    early_stop_on: str = \"val\",                # \"val\" | \"train\" | \"monitor\"\n",
    "    verbose: bool = True,\n",
    "):\n",
    "    # If early_stop_on='val' but val_loader is None, fall back to 'train'\n",
    "    if early_stop_on == \"val\" and val_loader is None:\n",
    "        early_stop_on = \"train\"\n",
    "\n",
    "    best_val = np.inf if early_stop_metric == \"loss\" else -np.inf\n",
    "    best_state, no_improve = None, 0\n",
    "\n",
    "    def _avg_loss(loader) -> Optional[float]:\n",
    "        if loader is None:\n",
    "            return None\n",
    "        wrapper.model.eval()\n",
    "        total, n = 0.0, 0\n",
    "        with torch.no_grad():\n",
    "            for Xf_b, pid_b, Xr_b, y_b in loader:\n",
    "                y_logits, adv_logits, xhat, _, _ = wrapper.forward(Xf_b, pid_b, Xr_b if Xr_b.size(1) > 0 else None)\n",
    "                l, _ = wrapper.compute_losses(y_b, y_logits, adv_logits, xhat, Xf_b, pid_b)\n",
    "                bs = Xf_b.size(0)\n",
    "                total += float(l.detach().cpu()) * bs\n",
    "                n += bs\n",
    "        return total / max(1, n)\n",
    "\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        # --- Train pass ---\n",
    "        wrapper.model.train()\n",
    "        total_tr, n_tr = 0.0, 0\n",
    "        for Xf_b, pid_b, Xr_b, y_b in train_loader:\n",
    "            y_logits, adv_logits, xhat, _, _ = wrapper.forward(\n",
    "                Xf_b, pid_b, Xr_b if Xr_b.size(1) > 0 else None\n",
    "            )\n",
    "            loss, _ = wrapper.compute_losses(y_b, y_logits, adv_logits, xhat, Xf_b, pid_b)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            bs = Xf_b.size(0)\n",
    "            total_tr += float(loss.detach().cpu()) * bs\n",
    "            n_tr += bs\n",
    "        train_loss = total_tr / max(1, n_tr)\n",
    "\n",
    "        # --- Monitor print ---\n",
    "        monitor_loss = _avg_loss(monitor_loader)\n",
    "        if verbose:\n",
    "            if monitor_loss is not None:\n",
    "                print(f\"Epoch {epoch:03d} | train {train_loss:.6f} | val_loss(monitor) {monitor_loss:.6f}\")\n",
    "            else:\n",
    "                print(f\"Epoch {epoch:03d} | train {train_loss:.6f}\")\n",
    "\n",
    "        # --- Early stopping ---\n",
    "        if early_stop_metric == \"loss\":\n",
    "            if early_stop_on == \"val\":\n",
    "                current = _avg_loss(val_loader)\n",
    "                is_better = (current is not None) and (current < best_val - 1e-6)\n",
    "                metric_for_best = current\n",
    "            elif early_stop_on == \"train\":\n",
    "                current = train_loss\n",
    "                is_better = current < best_val - 1e-6\n",
    "                metric_for_best = current\n",
    "            else:  # \"monitor\"\n",
    "                current = monitor_loss\n",
    "                is_better = (current is not None) and (current < best_val - 1e-6)\n",
    "                metric_for_best = current\n",
    "        else:  # early_stop_metric == \"macro_AUC\"\n",
    "            if early_stop_on == \"val\":\n",
    "                current = _eval_macro_auc_on_loader(wrapper, val_loader) if val_loader is not None else np.nan\n",
    "            elif early_stop_on == \"train\":\n",
    "                current = _eval_macro_auc_on_loader(wrapper, train_loader)\n",
    "            else:\n",
    "                current = _eval_macro_auc_on_loader(wrapper, monitor_loader) if monitor_loader is not None else np.nan\n",
    "            is_better = (not np.isnan(current)) and (current > best_val + 1e-6)\n",
    "            metric_for_best = current\n",
    "\n",
    "        if is_better:\n",
    "            best_val = metric_for_best\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in wrapper.model.state_dict().items()}\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience:\n",
    "                if verbose:\n",
    "                    tag = f\"{early_stop_metric}@{early_stop_on}\"\n",
    "                    print(f\"Early stopping at epoch {epoch:03d} (best {tag} {best_val:.6f})\")\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        wrapper.model.load_state_dict(best_state)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# PCA + loaders + per-split PID remap\n",
    "# -------------------------------------------------------------------\n",
    "def _prepare_split_and_loaders(\n",
    "    X_only_fixed: np.ndarray,\n",
    "    X_fixed_and_random: Optional[np.ndarray],\n",
    "    y: np.ndarray,\n",
    "    pid_idx_full: np.ndarray,\n",
    "    indices_train: np.ndarray,\n",
    "    indices_val: Optional[np.ndarray],\n",
    "    indices_test: np.ndarray,\n",
    "    batch_size: int,\n",
    "    device: torch.device,\n",
    "    random_state: int = 42,\n",
    "    pca_var_ratio: float = 0.95,\n",
    "):\n",
    "    # Fit PCA pipelines on TRAIN only\n",
    "    of_pipe = _fit_pca_pipeline(X_only_fixed[indices_train], var_ratio=pca_var_ratio, random_state=random_state)\n",
    "    fr_pipe = None\n",
    "    if X_fixed_and_random is not None and X_fixed_and_random.shape[1] > 0:\n",
    "        fr_pipe = _fit_pca_pipeline(X_fixed_and_random[indices_train], var_ratio=pca_var_ratio, random_state=random_state)\n",
    "\n",
    "    # Transform helper\n",
    "    def transform_block(idxs):\n",
    "        of = _transform_pca_pipeline(of_pipe, X_only_fixed[idxs])\n",
    "        fr = _transform_pca_pipeline(fr_pipe, None if X_fixed_and_random is None else X_fixed_and_random[idxs])\n",
    "        Xf = _concat_safe(of, fr)  # fixed = OF ⊕ FR\n",
    "        Xr = fr                    # random = FR\n",
    "        return Xf, Xr\n",
    "\n",
    "    Xf_tr, Xr_tr = transform_block(indices_train)\n",
    "    Xf_te, Xr_te = transform_block(indices_test)\n",
    "    if indices_val is not None:\n",
    "        Xf_va, Xr_va = transform_block(indices_val)\n",
    "    else:\n",
    "        Xf_va, Xr_va = None, None\n",
    "\n",
    "    # Per-split PID remap: train-seen -> 0..n_seen-1, unseen -> -1\n",
    "    seen = np.unique(pid_idx_full[indices_train])\n",
    "    pid_to_seen = {p: i for i, p in enumerate(seen)}\n",
    "\n",
    "    def map_pids(idxs):\n",
    "        vals = pid_idx_full[idxs]\n",
    "        mapped = np.array([pid_to_seen.get(p, -1) for p in vals], dtype=np.int64)\n",
    "        return mapped\n",
    "\n",
    "    pid_tr = map_pids(indices_train)\n",
    "    pid_te = map_pids(indices_test)\n",
    "    pid_va = map_pids(indices_val) if indices_val is not None else None\n",
    "\n",
    "    # Build loaders\n",
    "    tr_loader = _make_loader(Xf_tr, pid_tr, y[indices_train], Xr=Xr_tr, batch_size=batch_size, shuffle=True,  device=device)\n",
    "    va_loader = _make_loader(Xf_va, pid_va, y[indices_val], Xr=Xr_va, batch_size=batch_size, shuffle=False, device=device) if Xf_va is not None else None\n",
    "    te_loader = _make_loader(Xf_te, pid_te, y[indices_test],  Xr=Xr_te, batch_size=batch_size, shuffle=False, device=device)\n",
    "\n",
    "    # Post-PCA dims\n",
    "    d_fixed  = Xf_tr.shape[1]\n",
    "    d_random = 0 if Xr_tr is None else Xr_tr.shape[1]\n",
    "\n",
    "    preprocessors = {\n",
    "        \"only_fixed\": of_pipe,\n",
    "        \"fixed_and_random\": fr_pipe,\n",
    "        \"d_fixed\": d_fixed,\n",
    "        \"d_random\": d_random,\n",
    "        \"n_seen\": int(len(seen)),\n",
    "    }\n",
    "    loaders = {\"train\": tr_loader, \"val\": va_loader, \"test\": te_loader}\n",
    "    return preprocessors, loaders\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# One split fit/eval (used by all modes)\n",
    "# -------------------------------------------------------------------\n",
    "def _fit_eval_once(\n",
    "    build_model_fn, wrapper_cls,\n",
    "    arch_params: Dict[str, Any],\n",
    "    train_params: Dict[str, Any],\n",
    "    X_of: np.ndarray,\n",
    "    X_fr: Optional[np.ndarray],\n",
    "    y: np.ndarray,\n",
    "    pid_idx_full: np.ndarray,\n",
    "    tr_idx: np.ndarray,\n",
    "    va_idx: Optional[np.ndarray],\n",
    "    te_idx: np.ndarray,\n",
    "    device: torch.device,\n",
    "    monitor_source: str = \"test\",               # \"test\" (default) or \"val\"\n",
    "    threshold_selection_source: str = \"train\",  # \"train\" (default) | \"val\" | \"test\"\n",
    "    verbose: bool = True,\n",
    "):\n",
    "    preprocessors, loaders = _prepare_split_and_loaders(\n",
    "        X_of, X_fr, y, pid_idx_full,\n",
    "        tr_idx, va_idx, te_idx,\n",
    "        batch_size=train_params.get(\"batch_size\", 256),\n",
    "        device=device,\n",
    "        random_state=train_params.get(\"random_state\", 42),\n",
    "        pca_var_ratio=train_params.get(\"pca_var_ratio\", 0.95),\n",
    "    )\n",
    "\n",
    "    d_fixed  = preprocessors[\"d_fixed\"]\n",
    "    d_random = preprocessors[\"d_random\"]\n",
    "    n_seen   = preprocessors[\"n_seen\"]\n",
    "\n",
    "    # Build model with post-PCA dims and train-seen participant count\n",
    "    y_dim = y.shape[1] if y.ndim == 2 else 1\n",
    "    model = build_model_fn(\n",
    "        d_fixed=d_fixed,\n",
    "        d_random=d_random,\n",
    "        y_dim=y_dim,\n",
    "        n_participants=n_seen,\n",
    "        **arch_params\n",
    "    ).to(device)\n",
    "\n",
    "    wrapper = wrapper_cls(model, loss_weights=train_params.get(\"loss_weights\", None), device=device)\n",
    "    opt = torch.optim.Adam(wrapper.model.parameters(),\n",
    "                           lr=train_params.get(\"lr\", 1e-3),\n",
    "                           weight_decay=train_params.get(\"weight_decay\", 0.0))\n",
    "\n",
    "    monitor_loader = loaders[\"test\"] if monitor_source == \"test\" else loaders[\"val\"]\n",
    "\n",
    "    _fit_once(\n",
    "        wrapper, opt,\n",
    "        loaders[\"train\"], loaders[\"val\"], monitor_loader,\n",
    "        max_epochs=train_params.get(\"max_epochs\", 100),\n",
    "        patience=train_params.get(\"patience\", 10),\n",
    "        early_stop_metric=train_params.get(\"early_stop_metric\", \"loss\"),\n",
    "        early_stop_on=train_params.get(\"early_stop_on\", \"val\"),\n",
    "        verbose=verbose\n",
    "    )\n",
    "\n",
    "    # Predict on TEST loader\n",
    "    wrapper.model.eval()\n",
    "    probs_all, y_all = [], []\n",
    "    with torch.no_grad():\n",
    "        for Xf_b, pid_b, Xr_b, y_b in loaders[\"test\"]:\n",
    "            logits = wrapper.predict_logits(Xf_b, pid_b, Xr_b if Xr_b.size(1) > 0 else None)\n",
    "            probs_all.append(torch.sigmoid(logits).cpu().numpy())\n",
    "            y_all.append(y_b.cpu().numpy())\n",
    "    y_prob_te = np.vstack(probs_all); y_true_te = np.vstack(y_all)\n",
    "\n",
    "    # Metrics @ 0.5\n",
    "    metrics_050 = evaluate_multitask(y_true_te, y_prob_te, thr=0.5)\n",
    "\n",
    "    # Threshold selection (per-task exact F1-opt)\n",
    "    if threshold_selection_source == \"train\":\n",
    "        thr_vec, thr_summary = wrapper.find_best_thresholds_f1_from_loader(loaders[\"train\"])\n",
    "    elif threshold_selection_source == \"val\" and loaders[\"val\"] is not None:\n",
    "        thr_vec, thr_summary = wrapper.find_best_thresholds_f1_from_loader(loaders[\"val\"])\n",
    "    else:  # \"test\" or no val available fallback\n",
    "        thr_vec, thr_summary = wrapper.find_best_thresholds_f1_from_loader(loaders[\"test\"])\n",
    "\n",
    "    metrics_opt = _evaluate_with_thresholds(y_true_te, y_prob_te, thr_vec)\n",
    "\n",
    "    calib = compute_calibration_curves(y_true_te, y_prob_te,\n",
    "    n_bins=train_params.get(\"calibration_bins\", 10),\n",
    "    strategy=train_params.get(\"calibration_strategy\", \"quantile\"),)\n",
    "\n",
    "    # add scalar summaries into metrics\n",
    "    macro_ECE = calib[\"macro_ECE\"]\n",
    "    macro_MCE = calib[\"macro_MCE\"]\n",
    "\n",
    "    return {\n",
    "        \"metrics@0.5\": metrics_050,\n",
    "        \"metrics@optthr\": metrics_opt,\n",
    "        \"opt_thresholds\": thr_vec,\n",
    "        \"opt_thresholds_summary\": thr_summary,\n",
    "        \"preprocessors\": preprocessors,\n",
    "        \"wrapper\": wrapper,\n",
    "        \"model\": wrapper.model,\n",
    "        \"macro_ECE\": macro_ECE,\n",
    "        \"macro_MCE\": macro_MCE\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Main entry: single / cv_only / nested_cv, scenarios cases/time/both\n",
    "# -------------------------------------------------------------------\n",
    "def run_training_and_eval_armed(\n",
    "    X_only_fixed: np.ndarray,\n",
    "    X_fixed_and_random: Optional[np.ndarray],\n",
    "    y: np.ndarray,\n",
    "    pid_idx: np.ndarray,\n",
    "    time_index: np.ndarray,\n",
    "    build_model_fn,               # callable(d_fixed, d_random, y_dim, n_participants, **arch)\n",
    "    wrapper_cls,                  # ARMEDWrapper\n",
    "    *,\n",
    "    mode: str = \"single\",         # \"single\" | \"cv_only\" | \"nested_cv\"\n",
    "    scenario: str = \"cases\",      # \"cases\" | \"time\" | \"both\"\n",
    "    outer_folds: int = 5,\n",
    "    inner_folds: int = 3,\n",
    "    param_grid: Optional[Dict[str, List]] = None,\n",
    "    arch_defaults: Optional[Dict[str, Any]] = None,\n",
    "    train_defaults: Optional[Dict[str, Any]] = None,\n",
    "    device: Optional[torch.device] = None,\n",
    "    verbose: bool = True,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Unified runner:\n",
    "      - scaling + PCA(0.95) per block fit on TRAIN inside each split\n",
    "      - time scenario: test uses participants with >=3 measurements\n",
    "      - inner model selection by macro-F1 at per-task F1-opt thresholds (chosen on TRAIN)\n",
    "      - prints train + monitor (default monitor=test) losses per epoch\n",
    "    \"\"\"\n",
    "    device = device or (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "    X_of = np.asarray(X_only_fixed, dtype=np.float32)\n",
    "    X_fr = None if X_fixed_and_random is None else np.asarray(X_fixed_and_random, dtype=np.float32)\n",
    "    y    = np.asarray(y, dtype=np.float32)\n",
    "    pid_idx = np.asarray(pid_idx, dtype=np.int64)\n",
    "    time_ix = np.asarray(time_index)\n",
    "\n",
    "    arch_defaults = arch_defaults or {}\n",
    "    train_defaults = train_defaults or {}\n",
    "\n",
    "    rnd = int(train_defaults.get(\"random_state\", 42))\n",
    "    val_frac = float(train_defaults.get(\"val_fraction\", 0.10))\n",
    "    monitor_source = train_defaults.get(\"monitor_source\", \"test\")                     # printed each epoch\n",
    "    thr_source = train_defaults.get(\"threshold_selection_source\", \"train\")            # choose thresholds on TRAIN by default\n",
    "\n",
    "    def _make_train_val_split(idx_array: np.ndarray, seed: int) -> Tuple[np.ndarray, Optional[np.ndarray]]:\n",
    "        \"\"\"Return (train_indices, val_indices). If too small, no val.\"\"\"\n",
    "        idx_array = np.asarray(idx_array)\n",
    "        if len(idx_array) <= 10 or val_frac <= 0.0:\n",
    "            return idx_array, None\n",
    "        rng = np.random.default_rng(seed)\n",
    "        perm = rng.permutation(len(idx_array))\n",
    "        cut = max(1, int(val_frac * len(idx_array)))\n",
    "        va_sel, tr_sel = perm[:cut], perm[cut:]\n",
    "        return idx_array[tr_sel], idx_array[va_sel]\n",
    "\n",
    "    # Run both scenarios if requested\n",
    "    if scenario == \"both\":\n",
    "        out_cases = run_training_and_eval_armed(\n",
    "            X_of, X_fr, y, pid_idx, time_ix,\n",
    "            build_model_fn, wrapper_cls,\n",
    "            mode=mode, scenario=\"cases\",\n",
    "            outer_folds=outer_folds, inner_folds=inner_folds,\n",
    "            param_grid=param_grid, arch_defaults=arch_defaults, train_defaults=train_defaults,\n",
    "            device=device, verbose=verbose\n",
    "        )\n",
    "        out_time = run_training_and_eval_armed(\n",
    "            X_of, X_fr, y, pid_idx, time_ix,\n",
    "            build_model_fn, wrapper_cls,\n",
    "            mode=mode, scenario=\"time\",\n",
    "            outer_folds=outer_folds, inner_folds=inner_folds,\n",
    "            param_grid=param_grid, arch_defaults=arch_defaults, train_defaults=train_defaults,\n",
    "            device=device, verbose=verbose\n",
    "        )\n",
    "        return {\"cases\": out_cases, \"time\": out_time}\n",
    "\n",
    "    # -------------------- MODE: SINGLE --------------------\n",
    "    if mode == \"single\":\n",
    "        if scenario == \"cases\":\n",
    "            tr_idx_all, te_idx = _split_cases(pid_idx, test_fraction=0.2, seed=rnd)\n",
    "        elif scenario == \"time\":\n",
    "            tr_idx_all, te_idx_raw = _split_time_basic(time_ix, test_fraction=0.2)\n",
    "            te_idx = _filter_time_test_min_measurements(pid_idx, te_idx_raw, min_meas=3)\n",
    "            if len(te_idx) == 0:\n",
    "                raise RuntimeError(\"Time split produced empty test after >=3 measurements filter.\")\n",
    "            te_idx = te_idx\n",
    "        else:\n",
    "            raise ValueError(\"scenario must be 'cases' or 'time'\")\n",
    "\n",
    "        if scenario == \"cases\":\n",
    "            te_idx_use = te_idx\n",
    "        else:\n",
    "            te_idx_use = te_idx\n",
    "\n",
    "        tr_idx, va_idx = _make_train_val_split(np.asarray(tr_idx_all), seed=rnd)\n",
    "\n",
    "        res = _fit_eval_once(\n",
    "            build_model_fn, wrapper_cls,\n",
    "            arch_defaults, train_defaults,\n",
    "            X_of, X_fr, y,\n",
    "            pid_idx,     # ALWAYS pass full pid array\n",
    "            tr_idx, va_idx, te_idx_use,\n",
    "            device=device,\n",
    "            monitor_source=monitor_source,\n",
    "            threshold_selection_source=thr_source,\n",
    "            verbose=verbose\n",
    "        )\n",
    "\n",
    "        if verbose:\n",
    "            print(\"\\nSingle-fit test metrics @0.5:\")\n",
    "            for k, v in res[\"metrics@0.5\"].items():\n",
    "                print(f\"{k:>18}: {v:.4f}\")\n",
    "            print(\"\\nSingle-fit test metrics @F1-opt per task:\")\n",
    "            for k, v in res[\"metrics@optthr\"].items():\n",
    "                print(f\"{k:>18}: {v:.4f}\")\n",
    "\n",
    "        return res\n",
    "\n",
    "    # -------------------- MODE: CV-ONLY --------------------\n",
    "    if mode == \"cv_only\":\n",
    "        fold_metrics_050, fold_metrics_opt = [], []\n",
    "\n",
    "        if scenario == \"cases\":\n",
    "            outer = GroupKFold(n_splits=outer_folds)\n",
    "            outer_iter = outer.split(X_of, y[:, 0] if y.ndim > 1 else y, groups=pid_idx)\n",
    "        elif scenario == \"time\":\n",
    "            tss = TimeSeriesSplit(n_splits=outer_folds)\n",
    "            order = np.argsort(time_ix)\n",
    "            X_order = X_of[order]; y_order = y[order]\n",
    "            outer_iter = ((order[tr], order[te]) for tr, te in tss.split(X_order, y_order[:, 0] if y.ndim > 1 else y_order))\n",
    "        else:\n",
    "            raise ValueError(\"scenario must be 'cases' or 'time'\")\n",
    "\n",
    "        for fold_id, (tr_idx_all, te_idx_raw) in enumerate(outer_iter, start=1):\n",
    "            if scenario == \"time\":\n",
    "                te_idx = _filter_time_test_min_measurements(pid_idx, te_idx_raw, min_meas=3)\n",
    "                if len(te_idx) == 0:\n",
    "                    if verbose: print(f\"Skipping time fold {fold_id} (empty test after filter).\")\n",
    "                    continue\n",
    "                te_idx_use = te_idx\n",
    "            else:\n",
    "                te_idx_use = te_idx_raw\n",
    "\n",
    "            tr_idx, va_idx = _make_train_val_split(np.asarray(tr_idx_all), seed=rnd + fold_id)\n",
    "\n",
    "            res = _fit_eval_once(\n",
    "                build_model_fn, wrapper_cls,\n",
    "                arch_defaults, train_defaults,\n",
    "                X_of, X_fr, y,\n",
    "                pid_idx,\n",
    "                tr_idx, va_idx, te_idx_use,\n",
    "                device=device,\n",
    "                monitor_source=monitor_source,\n",
    "                threshold_selection_source=thr_source,   # TRAIN by default\n",
    "                verbose=False\n",
    "            )\n",
    "            fold_metrics_050.append(res[\"metrics@0.5\"])\n",
    "            fold_metrics_opt.append(res[\"metrics@optthr\"])\n",
    "\n",
    "            if verbose:\n",
    "                macro_keys = [k for k in res[\"metrics@optthr\"].keys() if k.startswith(\"macro_\")]\n",
    "                print(f\"Fold {fold_id}: \" + \", \".join(f\"{k}={res['metrics@optthr'][k]:.4f}\" for k in macro_keys))\n",
    "        \n",
    "        cv_summary_050 = _summarize_cv_folds(fold_metrics_050)\n",
    "        cv_summary_opt = _summarize_cv_folds(fold_metrics_opt)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"\\nCV averages (±95% CI) for 0.50 treshold:\")\n",
    "            for key in sorted(cv_summary_050.keys()):\n",
    "                if key.endswith(\"_mean\"):\n",
    "                    base = key[:-5]\n",
    "                    mean = cv_summary_050[key]\n",
    "                    low  = cv_summary_050.get(f\"{base}_95ci_low\", np.nan)\n",
    "                    high = cv_summary_050.get(f\"{base}_95ci_high\", np.nan)\n",
    "                    print(f\"{base:>20}: {mean:.4f}  (95% CI {low:.4f}, {high:.4f})\")\n",
    "\n",
    "            print(\"\\nCV averages (±95% CI) for optimal threshold:\")\n",
    "            for key in sorted(cv_summary_opt.keys()):\n",
    "                if key.endswith(\"_mean\"):\n",
    "                    base = key[:-5]\n",
    "                    mean = cv_summary_opt[key]\n",
    "                    low  = cv_summary_opt.get(f\"{base}_95ci_low\", np.nan)\n",
    "                    high = cv_summary_opt.get(f\"{base}_95ci_high\", np.nan)\n",
    "                    print(f\"{base:>20}: {mean:.4f}  (95% CI {low:.4f}, {high:.4f})\")\n",
    "\n",
    "\n",
    "        return {\n",
    "            \"cv_folds_metrics@0.5\": fold_metrics_050,\n",
    "            \"cv_folds_metrics@optthr\": fold_metrics_opt,\n",
    "            \"cv_summary@0.5\": cv_summary_050,\n",
    "            \"cv_summary@optthr\": cv_summary_opt,\n",
    "        }\n",
    "\n",
    "\n",
    "    # -------------------- MODE: NESTED CV --------------------\n",
    "    if mode == \"nested_cv\":\n",
    "        if not param_grid:\n",
    "            param_grid = {\n",
    "                \"fixed_rep_dim\": [32, 64, 128],\n",
    "                \"random_rep_dim\": [32],\n",
    "                \"combine_mode\": [\"add\"],\n",
    "                \"grl_lambda\": [1.0],\n",
    "                \"lr\": [1e-3, 3e-4],\n",
    "                \"weight_decay\": [0.0, 1e-4],\n",
    "                \"batch_size\": [256],\n",
    "                \"max_epochs\": [100],\n",
    "                \"patience\": [10],\n",
    "            }\n",
    "\n",
    "        results_folds = []\n",
    "        best_score_global, best_params_global = -np.inf, None\n",
    "\n",
    "        # Outer iterator\n",
    "        if scenario == \"cases\":\n",
    "            outer = GroupKFold(n_splits=outer_folds)\n",
    "            outer_iter = outer.split(X_of, y[:, 0] if y.ndim > 1 else y, groups=pid_idx)\n",
    "        elif scenario == \"time\":\n",
    "            tss = TimeSeriesSplit(n_splits=outer_folds)\n",
    "            order = np.argsort(time_ix)\n",
    "            X_order = X_of[order]; y_order = y[order]\n",
    "            outer_iter = ((order[tr], order[te]) for tr, te in tss.split(X_order, y_order[:, 0] if y.ndim > 1 else y_order))\n",
    "        else:\n",
    "            raise ValueError(\"scenario must be 'cases' or 'time'\")\n",
    "\n",
    "        for fold_id, (tr_idx_all, te_idx_raw) in enumerate(outer_iter, start=1):\n",
    "            if verbose:\n",
    "                print(f\"\\nOuter fold {fold_id}/{outer_folds}\")\n",
    "\n",
    "            if scenario == \"time\":\n",
    "                te_idx = _filter_time_test_min_measurements(pid_idx, te_idx_raw, min_meas=3)\n",
    "                if len(te_idx) == 0:\n",
    "                    if verbose: print(f\"Skipping outer time fold {fold_id} (empty test after filter).\")\n",
    "                    continue\n",
    "                te_idx_use = te_idx\n",
    "            else:\n",
    "                te_idx_use = te_idx_raw\n",
    "\n",
    "            # ----- INNER CV: model selection by macro F1 at per-task F1-opt thresholds (chosen on TRAIN) -----\n",
    "            def inner_iter():\n",
    "                if scenario == \"cases\":\n",
    "                    inner = GroupKFold(n_splits=inner_folds)\n",
    "                    return inner.split(X_of[tr_idx_all], (y[tr_idx_all, 0] if y.ndim > 1 else y[tr_idx_all]), groups=pid_idx[tr_idx_all])\n",
    "                else:\n",
    "                    tr_order = np.argsort(time_ix[tr_idx_all])\n",
    "                    X_tr_order = X_of[tr_idx_all][tr_order]\n",
    "                    y_tr_order = y[tr_idx_all][tr_order]\n",
    "                    inner_tss = TimeSeriesSplit(n_splits=inner_folds)\n",
    "                    return ((tr_idx_all[tr_order][itr], tr_idx_all[tr_order][iva])\n",
    "                            for itr, iva in inner_tss.split(X_tr_order, y_tr_order[:, 0] if y.ndim > 1 else y_tr_order))\n",
    "\n",
    "            best_inner_score, best_inner_params = -np.inf, None\n",
    "\n",
    "            for params in ParameterGrid(param_grid):\n",
    "                arch_params = dict(arch_defaults)\n",
    "                train_params = dict(train_defaults)\n",
    "                for k, v in params.items():\n",
    "                    if k in (\"fixed_rep_dim\", \"random_rep_dim\", \"combine_mode\", \"grl_lambda\"):\n",
    "                        arch_params[k] = v\n",
    "                    else:\n",
    "                        train_params[k] = v\n",
    "\n",
    "                inner_scores = []\n",
    "                for in_tr, in_va in inner_iter():\n",
    "                    # For time scenario, apply ≥3 rule on inner held-out set\n",
    "                    if scenario == \"time\":\n",
    "                        in_va_f = _filter_time_test_min_measurements(pid_idx, in_va, min_meas=3)\n",
    "                        if len(in_va_f) == 0:\n",
    "                            continue\n",
    "                        in_va = in_va_f\n",
    "\n",
    "                    # carve small early-stop val from in_tr\n",
    "                    tr_idx_inner, va_idx_inner = _make_train_val_split(np.asarray(in_tr), seed=rnd + fold_id)\n",
    "\n",
    "                    # Fit once: thresholds from TRAIN; evaluate on inner \"test\" (=in_va)\n",
    "                    res_inner = _fit_eval_once(\n",
    "                        build_model_fn, wrapper_cls,\n",
    "                        arch_params, train_params,\n",
    "                        X_of, X_fr, y,\n",
    "                        pid_idx,\n",
    "                        tr_idx_inner, va_idx_inner, in_va,\n",
    "                        device=device,\n",
    "                        monitor_source=\"val\",\n",
    "                        threshold_selection_source=\"train\",   # << thresholds from TRAIN\n",
    "                        verbose=False\n",
    "                    )\n",
    "                    score = res_inner[\"metrics@optthr\"].get(\"macro_F1_optthr\", np.nan)\n",
    "                    inner_scores.append(score)\n",
    "\n",
    "                if len(inner_scores) == 0:\n",
    "                    avg_score = -np.inf\n",
    "                else:\n",
    "                    avg_score = float(np.nanmean(inner_scores))\n",
    "\n",
    "                if avg_score > best_inner_score:\n",
    "                    best_inner_score = avg_score\n",
    "                    best_inner_params = (arch_params, train_params)\n",
    "\n",
    "            # ----- Outer evaluation with best inner params -----\n",
    "            if best_inner_params is None:\n",
    "                if verbose: print(\"No viable inner config; skipping outer fold.\")\n",
    "                continue\n",
    "\n",
    "            arch_params, train_params = best_inner_params\n",
    "            tr_idx_outer, va_idx_outer = _make_train_val_split(np.asarray(tr_idx_all), seed=rnd + fold_id * 17)\n",
    "\n",
    "            res_outer = _fit_eval_once(\n",
    "                build_model_fn, wrapper_cls,\n",
    "                arch_params, train_params,\n",
    "                X_of, X_fr, y,\n",
    "                pid_idx,\n",
    "                tr_idx_outer, va_idx_outer, te_idx_use,\n",
    "                device=device,\n",
    "                monitor_source=monitor_source,\n",
    "                threshold_selection_source=\"train\",   # << thresholds from TRAIN\n",
    "                verbose=False\n",
    "            )\n",
    "            results_folds.append(res_outer)\n",
    "\n",
    "            score_outer = res_outer[\"metrics@optthr\"].get(\"macro_F1_optthr\", -np.inf)\n",
    "            if score_outer > best_score_global:\n",
    "                best_score_global = score_outer\n",
    "                best_params_global = (arch_params, train_params)\n",
    "\n",
    "            if verbose:\n",
    "                macro_keys = [k for k in res_outer[\"metrics@optthr\"].keys() if k.startswith(\"macro_\")]\n",
    "                print(\"Outer fold macro (optthr): \" + \", \".join(f\"{k}={res_outer['metrics@optthr'][k]:.4f}\" for k in macro_keys))\n",
    "\n",
    "        # summarize folds\n",
    "        def summarize(results_list: List[Dict[str, Any]], which: str) -> Dict[str, float]:\n",
    "            keys = list(results_list[0][which].keys())\n",
    "            out = {}\n",
    "            for k in keys:\n",
    "                arr = np.array([res[which][k] for res in results_list], dtype=float)\n",
    "                m = float(np.nanmean(arr)); s = float(np.nanstd(arr, ddof=1)); n = len(arr)\n",
    "                se = s / np.sqrt(n) if n > 1 else np.nan\n",
    "                if n > 1:\n",
    "                    tcrit = float(student_t.ppf(0.975, df=n-1))\n",
    "                    ci = (m - tcrit * se, m + tcrit * se)\n",
    "                else:\n",
    "                    ci = (np.nan, np.nan)\n",
    "                out[k + \"_mean\"] = m\n",
    "                out[k + \"_95ci_low\"] = ci[0]\n",
    "                out[k + \"_95ci_high\"] = ci[1]\n",
    "            return out\n",
    "\n",
    "        cv_summary_050    = summarize(results_folds, \"metrics@0.5\")\n",
    "        cv_summary_optthr = summarize(results_folds, \"metrics@optthr\")\n",
    "\n",
    "        # Optional final refit on a fresh 80/20 with best params\n",
    "        if verbose:\n",
    "            print(\"\\nBest params (by outer macro_F1 at opt thresholds):\")\n",
    "            arch_p, train_p = best_params_global\n",
    "            print(\"[ARCH]:\");   [print(f\"  {k}: {v}\") for k, v in arch_p.items()]\n",
    "            print(\"[TRAIN]:\");  [print(f\"  {k}: {v}\") for k, v in train_p.items()]\n",
    "\n",
    "        # Final refit (fresh 80/20) for reporting\n",
    "        if scenario == \"cases\":\n",
    "            tr_idx_all, te_idx = _split_cases(pid_idx, test_fraction=0.2, seed=rnd)\n",
    "            te_idx_use = te_idx\n",
    "        else:\n",
    "            tr_idx_all, te_idx_raw = _split_time_basic(time_ix, test_fraction=0.2)\n",
    "            te_idx = _filter_time_test_min_measurements(pid_idx, te_idx_raw, min_meas=2)\n",
    "            if len(te_idx) == 0:\n",
    "                raise RuntimeError(\"Final refit: time split produced empty test after filter.\")\n",
    "            te_idx_use = te_idx\n",
    "\n",
    "        tr_idx_final, va_idx_final = _make_train_val_split(np.asarray(tr_idx_all), seed=rnd + 999)\n",
    "\n",
    "        final_res = _fit_eval_once(\n",
    "            build_model_fn, wrapper_cls,\n",
    "            best_params_global[0], best_params_global[1],\n",
    "            X_of, X_fr, y,\n",
    "            pid_idx,\n",
    "            tr_idx_final, va_idx_final, te_idx_use,\n",
    "            device=device,\n",
    "            monitor_source=monitor_source,\n",
    "            threshold_selection_source=\"train\",\n",
    "            verbose=verbose\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"outer_folds\": results_folds,\n",
    "            \"cv_summary@0.5\": cv_summary_050,\n",
    "            \"cv_summary@optthr\": cv_summary_optthr,\n",
    "            \"best_params\": {\"arch\": best_params_global[0], \"train\": best_params_global[1]},\n",
    "            \"final_refit\": final_res,\n",
    "        }\n",
    "\n",
    "    raise ValueError(\"mode must be one of {'single','cv_only','nested_cv'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e421e889",
   "metadata": {},
   "source": [
    "## Model test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8fdc27",
   "metadata": {},
   "source": [
    "### Define variables and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ade285cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_raw      = GHQ_cat_y.to_numpy(np.float32)\n",
    "y_np       = y_raw if y_raw.ndim == 2 else y_raw.reshape(-1, 1)\n",
    "\n",
    "pid_raw    = GHQ_cat_participant_id.to_numpy().ravel()\n",
    "pid_uniqs, pid_encoded = np.unique(pid_raw, return_inverse=True)\n",
    "pid_np     = pid_encoded.astype(np.int64)       \n",
    "n_ids      = int(len(pid_uniqs))                \n",
    "\n",
    "time_ix_np = GHQ_cat_time.to_numpy().ravel()\n",
    "\n",
    "\n",
    "\n",
    "def build_model_fn(d_fixed, d_random, y_dim, n_participants, **arch):\n",
    "    return ARMEDTabular(\n",
    "        d_fixed=d_fixed,\n",
    "        d_random=d_random,\n",
    "        y_dim=y_dim,\n",
    "        n_participants=n_participants,\n",
    "        **arch\n",
    "    )\n",
    "\n",
    "wrapper_cls = ARMEDWrapper\n",
    "\n",
    "arch_defaults = dict(\n",
    "    fixed_rep_dim=256,\n",
    "    random_rep_dim=256,\n",
    "    combine_mode=\"add\",\n",
    "    grl_lambda=1.0,\n",
    ")\n",
    "\n",
    "train_defaults = dict(\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-4,\n",
    "    batch_size=256,\n",
    "    max_epochs=100,\n",
    "    patience=20,\n",
    "    loss_weights=ARMEDLossWeights(lambda_adv=1.0, lambda_recon=0.0),\n",
    "\n",
    "    # NEW knobs:\n",
    "    pca_var_ratio=0.95,                   # 95% variance PCA\n",
    "    threshold_selection_source=\"train\",   # pick per-task F1 thresholds on TRAIN\n",
    "    monitor_source=\"test\",                # print “val_loss” on the test loader\n",
    "    early_stop_metric=\"loss\",             # default (BCE + λ_adv CE + λ_recon MSE)\n",
    "    early_stop_on=\"val\",                  # stop on validation loss\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312c501e",
   "metadata": {},
   "source": [
    "### Simple split test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58fff929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | train 6.030224 | val_loss(monitor) 0.692274\n",
      "Epoch 002 | train 6.012431 | val_loss(monitor) 0.688858\n",
      "Epoch 003 | train 5.997552 | val_loss(monitor) 0.686105\n",
      "Epoch 004 | train 5.984345 | val_loss(monitor) 0.683502\n",
      "Epoch 005 | train 5.972251 | val_loss(monitor) 0.680849\n",
      "Epoch 006 | train 5.960769 | val_loss(monitor) 0.678124\n",
      "Epoch 007 | train 5.950499 | val_loss(monitor) 0.675621\n",
      "Epoch 008 | train 5.938741 | val_loss(monitor) 0.673116\n",
      "Epoch 009 | train 5.928022 | val_loss(monitor) 0.670584\n",
      "Epoch 010 | train 5.917136 | val_loss(monitor) 0.667917\n",
      "Epoch 011 | train 5.905789 | val_loss(monitor) 0.665497\n",
      "Epoch 012 | train 5.894815 | val_loss(monitor) 0.663129\n",
      "Epoch 013 | train 5.884111 | val_loss(monitor) 0.660909\n",
      "Epoch 014 | train 5.872952 | val_loss(monitor) 0.659218\n",
      "Epoch 015 | train 5.862207 | val_loss(monitor) 0.657941\n",
      "Epoch 016 | train 5.851113 | val_loss(monitor) 0.657120\n",
      "Epoch 017 | train 5.839987 | val_loss(monitor) 0.656684\n",
      "Epoch 018 | train 5.829613 | val_loss(monitor) 0.656465\n",
      "Epoch 019 | train 5.819189 | val_loss(monitor) 0.656117\n",
      "Epoch 020 | train 5.808350 | val_loss(monitor) 0.656429\n",
      "Epoch 021 | train 5.798476 | val_loss(monitor) 0.657037\n",
      "Epoch 022 | train 5.788508 | val_loss(monitor) 0.658112\n",
      "Epoch 023 | train 5.779543 | val_loss(monitor) 0.659596\n",
      "Epoch 024 | train 5.770508 | val_loss(monitor) 0.660965\n",
      "Epoch 025 | train 5.762104 | val_loss(monitor) 0.662305\n",
      "Epoch 026 | train 5.753505 | val_loss(monitor) 0.664316\n",
      "Epoch 027 | train 5.745660 | val_loss(monitor) 0.666939\n",
      "Epoch 028 | train 5.737737 | val_loss(monitor) 0.668835\n",
      "Epoch 029 | train 5.730218 | val_loss(monitor) 0.670640\n",
      "Epoch 030 | train 5.723010 | val_loss(monitor) 0.672512\n",
      "Epoch 031 | train 5.715759 | val_loss(monitor) 0.674457\n",
      "Epoch 032 | train 5.709080 | val_loss(monitor) 0.676346\n",
      "Epoch 033 | train 5.702696 | val_loss(monitor) 0.678445\n",
      "Epoch 034 | train 5.695744 | val_loss(monitor) 0.680422\n",
      "Epoch 035 | train 5.689318 | val_loss(monitor) 0.681347\n",
      "Epoch 036 | train 5.683074 | val_loss(monitor) 0.682995\n",
      "Epoch 037 | train 5.676778 | val_loss(monitor) 0.685008\n",
      "Epoch 038 | train 5.670599 | val_loss(monitor) 0.686876\n",
      "Epoch 039 | train 5.664887 | val_loss(monitor) 0.689299\n",
      "Epoch 040 | train 5.658396 | val_loss(monitor) 0.690703\n",
      "Epoch 041 | train 5.652191 | val_loss(monitor) 0.692307\n",
      "Epoch 042 | train 5.646089 | val_loss(monitor) 0.694030\n",
      "Epoch 043 | train 5.640535 | val_loss(monitor) 0.695648\n",
      "Epoch 044 | train 5.634496 | val_loss(monitor) 0.697548\n",
      "Epoch 045 | train 5.628756 | val_loss(monitor) 0.700063\n",
      "Epoch 046 | train 5.622941 | val_loss(monitor) 0.702393\n",
      "Epoch 047 | train 5.616819 | val_loss(monitor) 0.705103\n",
      "Epoch 048 | train 5.611151 | val_loss(monitor) 0.707355\n",
      "Epoch 049 | train 5.605227 | val_loss(monitor) 0.709374\n",
      "Epoch 050 | train 5.599539 | val_loss(monitor) 0.712112\n",
      "Epoch 051 | train 5.593542 | val_loss(monitor) 0.714445\n",
      "Epoch 052 | train 5.587920 | val_loss(monitor) 0.717359\n",
      "Epoch 053 | train 5.582108 | val_loss(monitor) 0.720578\n",
      "Epoch 054 | train 5.576190 | val_loss(monitor) 0.723545\n",
      "Epoch 055 | train 5.570468 | val_loss(monitor) 0.726503\n",
      "Epoch 056 | train 5.564404 | val_loss(monitor) 0.729439\n",
      "Epoch 057 | train 5.558819 | val_loss(monitor) 0.732348\n",
      "Epoch 058 | train 5.552960 | val_loss(monitor) 0.735441\n",
      "Epoch 059 | train 5.547247 | val_loss(monitor) 0.738327\n",
      "Epoch 060 | train 5.541289 | val_loss(monitor) 0.741814\n",
      "Epoch 061 | train 5.535747 | val_loss(monitor) 0.745543\n",
      "Epoch 062 | train 5.530037 | val_loss(monitor) 0.749333\n",
      "Epoch 063 | train 5.524608 | val_loss(monitor) 0.752924\n",
      "Epoch 064 | train 5.519474 | val_loss(monitor) 0.756788\n",
      "Epoch 065 | train 5.514056 | val_loss(monitor) 0.761224\n",
      "Epoch 066 | train 5.508344 | val_loss(monitor) 0.765174\n",
      "Epoch 067 | train 5.503065 | val_loss(monitor) 0.770235\n",
      "Epoch 068 | train 5.497730 | val_loss(monitor) 0.774964\n",
      "Epoch 069 | train 5.493059 | val_loss(monitor) 0.779610\n",
      "Epoch 070 | train 5.487879 | val_loss(monitor) 0.784650\n",
      "Epoch 071 | train 5.483070 | val_loss(monitor) 0.790420\n",
      "Early stopping at epoch 071 (best loss@val 5.767788)\n",
      "\n",
      "Single-fit test metrics @0.5:\n",
      "        task_1_AUC: 0.6716\n",
      "      task_1_AUPRC: 0.6651\n",
      "      task_1_Brier: 0.2454\n",
      "        task_1_ACC: 0.6244\n",
      "         task_1_F1: 0.6373\n",
      "  task_1_Precision: 0.6311\n",
      "     task_1_Recall: 0.6436\n",
      "task_1_Sensitivity: 0.6436\n",
      "task_1_Specificity: 0.6042\n",
      "         macro_AUC: 0.6716\n",
      "       macro_AUPRC: 0.6651\n",
      "       macro_Brier: 0.2454\n",
      "         macro_ACC: 0.6244\n",
      "          macro_F1: 0.6373\n",
      "   macro_Precision: 0.6311\n",
      "      macro_Recall: 0.6436\n",
      " macro_Sensitivity: 0.6436\n",
      " macro_Specificity: 0.6042\n",
      "\n",
      "Single-fit test metrics @F1-opt per task:\n",
      " task_1_AUC_optthr: 0.6716\n",
      "task_1_AUPRC_optthr: 0.6651\n",
      "task_1_Brier_optthr: 0.2454\n",
      " task_1_ACC_optthr: 0.6193\n",
      "  task_1_F1_optthr: 0.6512\n",
      "task_1_Precision_optthr: 0.6140\n",
      "task_1_Recall_optthr: 0.6931\n",
      "task_1_Sensitivity_optthr: 0.6931\n",
      "task_1_Specificity_optthr: 0.5417\n",
      "  macro_AUC_optthr: 0.6716\n",
      "macro_AUPRC_optthr: 0.6651\n",
      "macro_Brier_optthr: 0.2454\n",
      "  macro_ACC_optthr: 0.6193\n",
      "   macro_F1_optthr: 0.6512\n",
      "macro_Precision_optthr: 0.6140\n",
      "macro_Recall_optthr: 0.6931\n",
      "macro_Sensitivity_optthr: 0.6931\n",
      "macro_Specificity_optthr: 0.5417\n",
      "Epoch 001 | train 6.218629 | val_loss(monitor) 6.184038\n",
      "Epoch 002 | train 6.204885 | val_loss(monitor) 6.171026\n",
      "Epoch 003 | train 6.192590 | val_loss(monitor) 6.159928\n",
      "Epoch 004 | train 6.180669 | val_loss(monitor) 6.148799\n",
      "Epoch 005 | train 6.170032 | val_loss(monitor) 6.138138\n",
      "Epoch 006 | train 6.158507 | val_loss(monitor) 6.128424\n",
      "Epoch 007 | train 6.147283 | val_loss(monitor) 6.119303\n",
      "Epoch 008 | train 6.135874 | val_loss(monitor) 6.109667\n",
      "Epoch 009 | train 6.125198 | val_loss(monitor) 6.099411\n",
      "Epoch 010 | train 6.113879 | val_loss(monitor) 6.088477\n",
      "Epoch 011 | train 6.102456 | val_loss(monitor) 6.077707\n",
      "Epoch 012 | train 6.091571 | val_loss(monitor) 6.066533\n",
      "Epoch 013 | train 6.080349 | val_loss(monitor) 6.055299\n",
      "Epoch 014 | train 6.069404 | val_loss(monitor) 6.043235\n",
      "Epoch 015 | train 6.058256 | val_loss(monitor) 6.032162\n",
      "Epoch 016 | train 6.048321 | val_loss(monitor) 6.021426\n",
      "Epoch 017 | train 6.037445 | val_loss(monitor) 6.011959\n",
      "Epoch 018 | train 6.027627 | val_loss(monitor) 6.003131\n",
      "Epoch 019 | train 6.017693 | val_loss(monitor) 5.995692\n",
      "Epoch 020 | train 6.008852 | val_loss(monitor) 5.989281\n",
      "Epoch 021 | train 5.999872 | val_loss(monitor) 5.982650\n",
      "Epoch 022 | train 5.992029 | val_loss(monitor) 5.977236\n",
      "Epoch 023 | train 5.984031 | val_loss(monitor) 5.970784\n",
      "Epoch 024 | train 5.976231 | val_loss(monitor) 5.965198\n",
      "Epoch 025 | train 5.969011 | val_loss(monitor) 5.960998\n",
      "Epoch 026 | train 5.961715 | val_loss(monitor) 5.957211\n",
      "Epoch 027 | train 5.954762 | val_loss(monitor) 5.953265\n",
      "Epoch 028 | train 5.947985 | val_loss(monitor) 5.949821\n",
      "Epoch 029 | train 5.941379 | val_loss(monitor) 5.947547\n",
      "Epoch 030 | train 5.935432 | val_loss(monitor) 5.946993\n",
      "Epoch 031 | train 5.928693 | val_loss(monitor) 5.945112\n",
      "Epoch 032 | train 5.922687 | val_loss(monitor) 5.942703\n",
      "Epoch 033 | train 5.916678 | val_loss(monitor) 5.940405\n",
      "Epoch 034 | train 5.910661 | val_loss(monitor) 5.939719\n",
      "Epoch 035 | train 5.904641 | val_loss(monitor) 5.938634\n",
      "Epoch 036 | train 5.898837 | val_loss(monitor) 5.938243\n",
      "Epoch 037 | train 5.892969 | val_loss(monitor) 5.937135\n",
      "Epoch 038 | train 5.887154 | val_loss(monitor) 5.935462\n",
      "Epoch 039 | train 5.881471 | val_loss(monitor) 5.934062\n",
      "Epoch 040 | train 5.875879 | val_loss(monitor) 5.933250\n",
      "Epoch 041 | train 5.869491 | val_loss(monitor) 5.933815\n",
      "Epoch 042 | train 5.863676 | val_loss(monitor) 5.934877\n",
      "Epoch 043 | train 5.857786 | val_loss(monitor) 5.936399\n",
      "Epoch 044 | train 5.851595 | val_loss(monitor) 5.936061\n",
      "Epoch 045 | train 5.845243 | val_loss(monitor) 5.935183\n",
      "Epoch 046 | train 5.838834 | val_loss(monitor) 5.933597\n",
      "Epoch 047 | train 5.832120 | val_loss(monitor) 5.933025\n",
      "Epoch 048 | train 5.825411 | val_loss(monitor) 5.932271\n",
      "Early stopping at epoch 048 (best loss@val 6.090393)\n",
      "\n",
      "Single-fit test metrics @0.5:\n",
      "        task_1_AUC: 0.8718\n",
      "      task_1_AUPRC: 0.9172\n",
      "      task_1_Brier: 0.1478\n",
      "        task_1_ACC: 0.7843\n",
      "         task_1_F1: 0.8182\n",
      "  task_1_Precision: 0.8534\n",
      "     task_1_Recall: 0.7857\n",
      "task_1_Sensitivity: 0.7857\n",
      "task_1_Specificity: 0.7821\n",
      "         macro_AUC: 0.8718\n",
      "       macro_AUPRC: 0.9172\n",
      "       macro_Brier: 0.1478\n",
      "         macro_ACC: 0.7843\n",
      "          macro_F1: 0.8182\n",
      "   macro_Precision: 0.8534\n",
      "      macro_Recall: 0.7857\n",
      " macro_Sensitivity: 0.7857\n",
      " macro_Specificity: 0.7821\n",
      "\n",
      "Single-fit test metrics @F1-opt per task:\n",
      " task_1_AUC_optthr: 0.8718\n",
      "task_1_AUPRC_optthr: 0.9172\n",
      "task_1_Brier_optthr: 0.1478\n",
      " task_1_ACC_optthr: 0.7843\n",
      "  task_1_F1_optthr: 0.8240\n",
      "task_1_Precision_optthr: 0.8306\n",
      "task_1_Recall_optthr: 0.8175\n",
      "task_1_Sensitivity_optthr: 0.8175\n",
      "task_1_Specificity_optthr: 0.7308\n",
      "  macro_AUC_optthr: 0.8718\n",
      "macro_AUPRC_optthr: 0.9172\n",
      "macro_Brier_optthr: 0.1478\n",
      "  macro_ACC_optthr: 0.7843\n",
      "   macro_F1_optthr: 0.8240\n",
      "macro_Precision_optthr: 0.8306\n",
      "macro_Recall_optthr: 0.8175\n",
      "macro_Sensitivity_optthr: 0.8175\n",
      "macro_Specificity_optthr: 0.7308\n"
     ]
    }
   ],
   "source": [
    "res_simple = run_training_and_eval_armed(\n",
    "    X_only_fixed=GHQ_cat_only_fixed.values,\n",
    "    X_fixed_and_random=GHQ_cat_fixed_and_random.values,\n",
    "    y=y_np,\n",
    "    pid_idx=pid_np,\n",
    "    time_index=time_ix_np,\n",
    "    build_model_fn=build_model_fn,\n",
    "    wrapper_cls=wrapper_cls,\n",
    "    mode=\"single\",\n",
    "    scenario=\"both\",          # <- runs cases and time in one go\n",
    "    arch_defaults=arch_defaults,\n",
    "    train_defaults=train_defaults,\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c2fc41",
   "metadata": {},
   "source": [
    "### Nested CV with parameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09927b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outer fold 1/5\n",
      "Outer fold macro (optthr): macro_AUC_optthr=0.7566, macro_AUPRC_optthr=0.7738, macro_Brier_optthr=0.2010, macro_ACC_optthr=0.7246, macro_F1_optthr=0.7532, macro_Precision_optthr=0.7909, macro_Recall_optthr=0.7190, macro_Sensitivity_optthr=0.7190, macro_Specificity_optthr=0.7326\n",
      "\n",
      "Outer fold 2/5\n",
      "Outer fold macro (optthr): macro_AUC_optthr=0.7379, macro_AUPRC_optthr=0.7717, macro_Brier_optthr=0.2088, macro_ACC_optthr=0.6748, macro_F1_optthr=0.6884, macro_Precision_optthr=0.7115, macro_Recall_optthr=0.6667, macro_Sensitivity_optthr=0.6667, macro_Specificity_optthr=0.6842\n",
      "\n",
      "Outer fold 3/5\n",
      "Outer fold macro (optthr): macro_AUC_optthr=0.8183, macro_AUPRC_optthr=0.8112, macro_Brier_optthr=0.1830, macro_ACC_optthr=0.7184, macro_F1_optthr=0.7500, macro_Precision_optthr=0.6797, macro_Recall_optthr=0.8365, macro_Sensitivity_optthr=0.8365, macro_Specificity_optthr=0.5980\n",
      "\n",
      "Outer fold 4/5\n",
      "Outer fold macro (optthr): macro_AUC_optthr=0.8578, macro_AUPRC_optthr=0.8803, macro_Brier_optthr=0.1592, macro_ACC_optthr=0.7913, macro_F1_optthr=0.8245, macro_Precision_optthr=0.7953, macro_Recall_optthr=0.8559, macro_Sensitivity_optthr=0.8559, macro_Specificity_optthr=0.7045\n",
      "\n",
      "Outer fold 5/5\n",
      "Outer fold macro (optthr): macro_AUC_optthr=0.7872, macro_AUPRC_optthr=0.7769, macro_Brier_optthr=0.1951, macro_ACC_optthr=0.6990, macro_F1_optthr=0.7048, macro_Precision_optthr=0.6852, macro_Recall_optthr=0.7255, macro_Sensitivity_optthr=0.7255, macro_Specificity_optthr=0.6731\n",
      "\n",
      "Best params (by outer macro_F1 at opt thresholds):\n",
      "[ARCH]:\n",
      "  fixed_rep_dim: 64\n",
      "  random_rep_dim: 128\n",
      "  combine_mode: film\n",
      "  grl_lambda: 1.0\n",
      "[TRAIN]:\n",
      "  lr: 0.0001\n",
      "  weight_decay: 0.0001\n",
      "  batch_size: 256\n",
      "  max_epochs: 100\n",
      "  patience: 20\n",
      "  loss_weights: ARMEDLossWeights(lambda_adv=1.0, lambda_recon=0.0)\n",
      "  pca_var_ratio: 0.95\n",
      "  threshold_selection_source: train\n",
      "  monitor_source: test\n",
      "  early_stop_metric: loss\n",
      "  early_stop_on: val\n",
      "Epoch 001 | train 6.062648 | val_loss(monitor) 0.688713\n",
      "Epoch 002 | train 6.055544 | val_loss(monitor) 0.684572\n",
      "Epoch 003 | train 6.049009 | val_loss(monitor) 0.680529\n",
      "Epoch 004 | train 6.042998 | val_loss(monitor) 0.676965\n",
      "Epoch 005 | train 6.037065 | val_loss(monitor) 0.673503\n",
      "Epoch 006 | train 6.031703 | val_loss(monitor) 0.670052\n",
      "Epoch 007 | train 6.025951 | val_loss(monitor) 0.666776\n",
      "Epoch 008 | train 6.019927 | val_loss(monitor) 0.663617\n",
      "Epoch 009 | train 6.014097 | val_loss(monitor) 0.660478\n",
      "Epoch 010 | train 6.007860 | val_loss(monitor) 0.657924\n",
      "Epoch 011 | train 6.001203 | val_loss(monitor) 0.655714\n",
      "Epoch 012 | train 5.994283 | val_loss(monitor) 0.654195\n",
      "Epoch 013 | train 5.987503 | val_loss(monitor) 0.653250\n",
      "Epoch 014 | train 5.980353 | val_loss(monitor) 0.652748\n",
      "Epoch 015 | train 5.973450 | val_loss(monitor) 0.653085\n",
      "Epoch 016 | train 5.966378 | val_loss(monitor) 0.653783\n",
      "Epoch 017 | train 5.959698 | val_loss(monitor) 0.654642\n",
      "Epoch 018 | train 5.953598 | val_loss(monitor) 0.656396\n",
      "Epoch 019 | train 5.947776 | val_loss(monitor) 0.658638\n",
      "Epoch 020 | train 5.942299 | val_loss(monitor) 0.662041\n",
      "Epoch 021 | train 5.937295 | val_loss(monitor) 0.666024\n",
      "Epoch 022 | train 5.932806 | val_loss(monitor) 0.669969\n",
      "Epoch 023 | train 5.929056 | val_loss(monitor) 0.673791\n",
      "Epoch 024 | train 5.925634 | val_loss(monitor) 0.678055\n",
      "Epoch 025 | train 5.922427 | val_loss(monitor) 0.682164\n",
      "Epoch 026 | train 5.920156 | val_loss(monitor) 0.686877\n",
      "Epoch 027 | train 5.917878 | val_loss(monitor) 0.691211\n",
      "Epoch 028 | train 5.915734 | val_loss(monitor) 0.694857\n",
      "Epoch 029 | train 5.913822 | val_loss(monitor) 0.698475\n",
      "Epoch 030 | train 5.911665 | val_loss(monitor) 0.701992\n",
      "Epoch 031 | train 5.910137 | val_loss(monitor) 0.704781\n",
      "Epoch 032 | train 5.908583 | val_loss(monitor) 0.707901\n",
      "Epoch 033 | train 5.906569 | val_loss(monitor) 0.711475\n",
      "Epoch 034 | train 5.904675 | val_loss(monitor) 0.714418\n",
      "Epoch 035 | train 5.902841 | val_loss(monitor) 0.717283\n",
      "Epoch 036 | train 5.900838 | val_loss(monitor) 0.719851\n",
      "Epoch 037 | train 5.898813 | val_loss(monitor) 0.722763\n",
      "Epoch 038 | train 5.896558 | val_loss(monitor) 0.725271\n",
      "Epoch 039 | train 5.894122 | val_loss(monitor) 0.727374\n",
      "Epoch 040 | train 5.891556 | val_loss(monitor) 0.729117\n",
      "Epoch 041 | train 5.888856 | val_loss(monitor) 0.731722\n",
      "Epoch 042 | train 5.886008 | val_loss(monitor) 0.734457\n",
      "Early stopping at epoch 042 (best loss@val 5.972049)\n",
      "\n",
      "Outer fold 1/5\n",
      "Outer fold macro (optthr): macro_AUC_optthr=0.7816, macro_AUPRC_optthr=0.7438, macro_Brier_optthr=0.1799, macro_ACC_optthr=0.7615, macro_F1_optthr=0.8000, macro_Precision_optthr=0.7470, macro_Recall_optthr=0.8611, macro_Sensitivity_optthr=0.8611, macro_Specificity_optthr=0.6379\n",
      "\n",
      "Outer fold 2/5\n",
      "Outer fold macro (optthr): macro_AUC_optthr=0.7542, macro_AUPRC_optthr=0.7050, macro_Brier_optthr=0.2084, macro_ACC_optthr=0.6709, macro_F1_optthr=0.6977, macro_Precision_optthr=0.6122, macro_Recall_optthr=0.8108, macro_Sensitivity_optthr=0.8108, macro_Specificity_optthr=0.5476\n",
      "\n",
      "Outer fold 3/5\n",
      "Outer fold macro (optthr): macro_AUC_optthr=0.8010, macro_AUPRC_optthr=0.8012, macro_Brier_optthr=0.1904, macro_ACC_optthr=0.7421, macro_F1_optthr=0.7211, macro_Precision_optthr=0.7681, macro_Recall_optthr=0.6795, macro_Sensitivity_optthr=0.6795, macro_Specificity_optthr=0.8025\n",
      "\n",
      "Outer fold 4/5\n",
      "Outer fold macro (optthr): macro_AUC_optthr=0.8348, macro_AUPRC_optthr=0.8740, macro_Brier_optthr=0.1750, macro_ACC_optthr=0.7378, macro_F1_optthr=0.7650, macro_Precision_optthr=0.7692, macro_Recall_optthr=0.7609, macro_Sensitivity_optthr=0.7609, macro_Specificity_optthr=0.7083\n",
      "\n",
      "Outer fold 5/5\n",
      "Outer fold macro (optthr): macro_AUC_optthr=0.8240, macro_AUPRC_optthr=0.8743, macro_Brier_optthr=0.1685, macro_ACC_optthr=0.7647, macro_F1_optthr=0.8165, macro_Precision_optthr=0.7672, macro_Recall_optthr=0.8725, macro_Sensitivity_optthr=0.8725, macro_Specificity_optthr=0.6029\n",
      "\n",
      "Best params (by outer macro_F1 at opt thresholds):\n",
      "[ARCH]:\n",
      "  fixed_rep_dim: 128\n",
      "  random_rep_dim: 128\n",
      "  combine_mode: add\n",
      "  grl_lambda: 1.0\n",
      "[TRAIN]:\n",
      "  lr: 0.001\n",
      "  weight_decay: 0.0\n",
      "  batch_size: 256\n",
      "  max_epochs: 100\n",
      "  patience: 20\n",
      "  loss_weights: ARMEDLossWeights(lambda_adv=1.0, lambda_recon=0.0)\n",
      "  pca_var_ratio: 0.95\n",
      "  threshold_selection_source: train\n",
      "  monitor_source: test\n",
      "  early_stop_metric: loss\n",
      "  early_stop_on: val\n",
      "Epoch 001 | train 6.253730 | val_loss(monitor) 6.220345\n",
      "Epoch 002 | train 6.230203 | val_loss(monitor) 6.182607\n",
      "Epoch 003 | train 6.198466 | val_loss(monitor) 6.149177\n",
      "Epoch 004 | train 6.161873 | val_loss(monitor) 6.106242\n",
      "Epoch 005 | train 6.121008 | val_loss(monitor) 6.069122\n",
      "Epoch 006 | train 6.083585 | val_loss(monitor) 6.051857\n",
      "Epoch 007 | train 6.047042 | val_loss(monitor) 6.047001\n",
      "Epoch 008 | train 6.014025 | val_loss(monitor) 6.043869\n",
      "Epoch 009 | train 5.978612 | val_loss(monitor) 6.026231\n",
      "Epoch 010 | train 5.942643 | val_loss(monitor) 6.035023\n",
      "Epoch 011 | train 5.902059 | val_loss(monitor) 6.028292\n",
      "Epoch 012 | train 5.852280 | val_loss(monitor) 6.008207\n",
      "Epoch 013 | train 5.802206 | val_loss(monitor) 6.035028\n",
      "Epoch 014 | train 5.757422 | val_loss(monitor) 6.031123\n",
      "Epoch 015 | train 5.712692 | val_loss(monitor) 6.081243\n",
      "Epoch 016 | train 5.676661 | val_loss(monitor) 6.093290\n",
      "Epoch 017 | train 5.638202 | val_loss(monitor) 6.119686\n",
      "Epoch 018 | train 5.606047 | val_loss(monitor) 6.185676\n",
      "Epoch 019 | train 5.583378 | val_loss(monitor) 6.185892\n",
      "Epoch 020 | train 5.569923 | val_loss(monitor) 6.275309\n",
      "Epoch 021 | train 5.559903 | val_loss(monitor) 6.260241\n",
      "Epoch 022 | train 5.546978 | val_loss(monitor) 6.345809\n",
      "Epoch 023 | train 5.541508 | val_loss(monitor) 6.329443\n",
      "Epoch 024 | train 5.549193 | val_loss(monitor) 6.381171\n",
      "Early stopping at epoch 024 (best loss@val 6.217977)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    # arch params\n",
    "    \"fixed_rep_dim\": [64, 128, 256],\n",
    "    \"random_rep_dim\": [64, 128],\n",
    "    \"combine_mode\": [\"add\", \"film\"],\n",
    "    \"grl_lambda\": [0.5, 1.0],\n",
    "    # train params\n",
    "    \"lr\": [1e-3, 3e-4, 1e-4],\n",
    "    \"weight_decay\": [0.0, 1e-4],\n",
    "    \"batch_size\": [128, 256],\n",
    "    \"max_epochs\": [100],\n",
    "    \"patience\": [20],\n",
    "}\n",
    "\n",
    "res_nested = run_training_and_eval_armed(\n",
    "    X_only_fixed=GHQ_cat_only_fixed.values,\n",
    "    X_fixed_and_random=GHQ_cat_fixed_and_random.values,\n",
    "    y=GHQ_cat_y.values,\n",
    "    pid_idx=pid_np,\n",
    "    time_index=time_ix_np,\n",
    "    build_model_fn=build_model_fn,\n",
    "    wrapper_cls=wrapper_cls,\n",
    "    mode=\"nested_cv\",\n",
    "    scenario=\"both\",\n",
    "    outer_folds=5,\n",
    "    inner_folds=3,\n",
    "    param_grid=param_grid,\n",
    "    arch_defaults=arch_defaults,\n",
    "    train_defaults=train_defaults,\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc4ca57",
   "metadata": {},
   "source": [
    "### CV without parameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d60b7d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: macro_AUC_optthr=0.6701, macro_AUPRC_optthr=0.6703, macro_Brier_optthr=0.2709, macro_ACC_optthr=0.5872, macro_F1_optthr=0.5535, macro_Precision_optthr=0.6567, macro_Recall_optthr=0.4783, macro_Sensitivity_optthr=0.4783, macro_Specificity_optthr=0.7125\n",
      "Fold 2: macro_AUC_optthr=0.7695, macro_AUPRC_optthr=0.7929, macro_Brier_optthr=0.2187, macro_ACC_optthr=0.6744, macro_F1_optthr=0.6686, macro_Precision_optthr=0.7687, macro_Recall_optthr=0.5916, macro_Sensitivity_optthr=0.5916, macro_Specificity_optthr=0.7778\n",
      "Fold 3: macro_AUC_optthr=0.7899, macro_AUPRC_optthr=0.7908, macro_Brier_optthr=0.2020, macro_ACC_optthr=0.6851, macro_F1_optthr=0.7545, macro_Precision_optthr=0.6409, macro_Recall_optthr=0.9171, macro_Sensitivity_optthr=0.9171, macro_Specificity_optthr=0.4259\n",
      "\n",
      "CV averages (±95% CI) for 0.50 treshold:\n",
      "           macro_ACC: 0.6480  (95% CI 0.5205, 0.7754)\n",
      "           macro_AUC: 0.7432  (95% CI 0.5840, 0.9023)\n",
      "         macro_AUPRC: 0.7513  (95% CI 0.5770, 0.9257)\n",
      "         macro_Brier: 0.2306  (95% CI 0.1412, 0.3199)\n",
      "            macro_F1: 0.6445  (95% CI 0.3992, 0.8899)\n",
      "     macro_Precision: 0.7110  (95% CI 0.4715, 0.9504)\n",
      "        macro_Recall: 0.6252  (95% CI 0.0554, 1.1950)\n",
      "   macro_Sensitivity: 0.6252  (95% CI 0.0554, 1.1950)\n",
      "   macro_Specificity: 0.6815  (95% CI 0.1785, 1.1845)\n",
      "          task_1_ACC: 0.6480  (95% CI 0.5205, 0.7754)\n",
      "          task_1_AUC: 0.7432  (95% CI 0.5840, 0.9023)\n",
      "        task_1_AUPRC: 0.7513  (95% CI 0.5770, 0.9257)\n",
      "        task_1_Brier: 0.2306  (95% CI 0.1412, 0.3199)\n",
      "           task_1_F1: 0.6445  (95% CI 0.3992, 0.8899)\n",
      "    task_1_Precision: 0.7110  (95% CI 0.4715, 0.9504)\n",
      "       task_1_Recall: 0.6252  (95% CI 0.0554, 1.1950)\n",
      "  task_1_Sensitivity: 0.6252  (95% CI 0.0554, 1.1950)\n",
      "  task_1_Specificity: 0.6815  (95% CI 0.1785, 1.1845)\n",
      "\n",
      "CV averages (±95% CI) for optimal threshold:\n",
      "    macro_ACC_optthr: 0.6489  (95% CI 0.5155, 0.7823)\n",
      "    macro_AUC_optthr: 0.7432  (95% CI 0.5840, 0.9023)\n",
      "  macro_AUPRC_optthr: 0.7513  (95% CI 0.5770, 0.9257)\n",
      "  macro_Brier_optthr: 0.2306  (95% CI 0.1412, 0.3199)\n",
      "     macro_F1_optthr: 0.6589  (95% CI 0.4082, 0.9095)\n",
      "macro_Precision_optthr: 0.6888  (95% CI 0.5157, 0.8618)\n",
      " macro_Recall_optthr: 0.6623  (95% CI 0.0964, 1.2283)\n",
      "macro_Sensitivity_optthr: 0.6623  (95% CI 0.0964, 1.2283)\n",
      "macro_Specificity_optthr: 0.6387  (95% CI 0.1738, 1.1037)\n",
      "   task_1_ACC_optthr: 0.6489  (95% CI 0.5155, 0.7823)\n",
      "   task_1_AUC_optthr: 0.7432  (95% CI 0.5840, 0.9023)\n",
      " task_1_AUPRC_optthr: 0.7513  (95% CI 0.5770, 0.9257)\n",
      " task_1_Brier_optthr: 0.2306  (95% CI 0.1412, 0.3199)\n",
      "    task_1_F1_optthr: 0.6589  (95% CI 0.4082, 0.9095)\n",
      "task_1_Precision_optthr: 0.6888  (95% CI 0.5157, 0.8618)\n",
      "task_1_Recall_optthr: 0.6623  (95% CI 0.0964, 1.2283)\n",
      "task_1_Sensitivity_optthr: 0.6623  (95% CI 0.0964, 1.2283)\n",
      "task_1_Specificity_optthr: 0.6387  (95% CI 0.1738, 1.1037)\n",
      "Fold 1: macro_AUC_optthr=0.8002, macro_AUPRC_optthr=0.7651, macro_Brier_optthr=0.1865, macro_ACC_optthr=0.7511, macro_F1_optthr=0.7500, macro_Precision_optthr=0.7190, macro_Recall_optthr=0.7838, macro_Sensitivity_optthr=0.7838, macro_Specificity_optthr=0.7213\n",
      "Fold 2: macro_AUC_optthr=0.5811, macro_AUPRC_optthr=0.5701, macro_Brier_optthr=0.2454, macro_ACC_optthr=0.5165, macro_F1_optthr=0.6686, macro_Precision_optthr=0.5043, macro_Recall_optthr=0.9916, macro_Sensitivity_optthr=0.9916, macro_Specificity_optthr=0.0569\n",
      "Fold 3: macro_AUC_optthr=0.8435, macro_AUPRC_optthr=0.8973, macro_Brier_optthr=0.1656, macro_ACC_optthr=0.7460, macro_F1_optthr=0.7823, macro_Precision_optthr=0.8156, macro_Recall_optthr=0.7516, macro_Sensitivity_optthr=0.7516, macro_Specificity_optthr=0.7374\n",
      "\n",
      "CV averages (±95% CI) for 0.50 treshold:\n",
      "           macro_ACC: 0.6807  (95% CI 0.4074, 0.9541)\n",
      "           macro_AUC: 0.7416  (95% CI 0.3922, 1.0910)\n",
      "         macro_AUPRC: 0.7442  (95% CI 0.3353, 1.1530)\n",
      "         macro_Brier: 0.1992  (95% CI 0.0964, 0.3020)\n",
      "            macro_F1: 0.6615  (95% CI 0.2471, 1.0759)\n",
      "     macro_Precision: 0.7038  (95% CI 0.3784, 1.0291)\n",
      "        macro_Recall: 0.6299  (95% CI 0.1424, 1.1174)\n",
      "   macro_Sensitivity: 0.6299  (95% CI 0.1424, 1.1174)\n",
      "   macro_Specificity: 0.7315  (95% CI 0.6577, 0.8052)\n",
      "          task_1_ACC: 0.6807  (95% CI 0.4074, 0.9541)\n",
      "          task_1_AUC: 0.7416  (95% CI 0.3922, 1.0910)\n",
      "        task_1_AUPRC: 0.7442  (95% CI 0.3353, 1.1530)\n",
      "        task_1_Brier: 0.1992  (95% CI 0.0964, 0.3020)\n",
      "           task_1_F1: 0.6615  (95% CI 0.2471, 1.0759)\n",
      "    task_1_Precision: 0.7038  (95% CI 0.3784, 1.0291)\n",
      "       task_1_Recall: 0.6299  (95% CI 0.1424, 1.1174)\n",
      "  task_1_Sensitivity: 0.6299  (95% CI 0.1424, 1.1174)\n",
      "  task_1_Specificity: 0.7315  (95% CI 0.6577, 0.8052)\n",
      "\n",
      "CV averages (±95% CI) for optimal threshold:\n",
      "    macro_ACC_optthr: 0.6712  (95% CI 0.3384, 1.0040)\n",
      "    macro_AUC_optthr: 0.7416  (95% CI 0.3922, 1.0910)\n",
      "  macro_AUPRC_optthr: 0.7442  (95% CI 0.3353, 1.1530)\n",
      "  macro_Brier_optthr: 0.1992  (95% CI 0.0964, 0.3020)\n",
      "     macro_F1_optthr: 0.7336  (95% CI 0.5880, 0.8792)\n",
      "macro_Precision_optthr: 0.6796  (95% CI 0.2838, 1.0755)\n",
      " macro_Recall_optthr: 0.8423  (95% CI 0.5188, 1.1659)\n",
      "macro_Sensitivity_optthr: 0.8423  (95% CI 0.5188, 1.1659)\n",
      "macro_Specificity_optthr: 0.5052  (95% CI -0.4594, 1.4698)\n",
      "   task_1_ACC_optthr: 0.6712  (95% CI 0.3384, 1.0040)\n",
      "   task_1_AUC_optthr: 0.7416  (95% CI 0.3922, 1.0910)\n",
      " task_1_AUPRC_optthr: 0.7442  (95% CI 0.3353, 1.1530)\n",
      " task_1_Brier_optthr: 0.1992  (95% CI 0.0964, 0.3020)\n",
      "    task_1_F1_optthr: 0.7336  (95% CI 0.5880, 0.8792)\n",
      "task_1_Precision_optthr: 0.6796  (95% CI 0.2838, 1.0755)\n",
      "task_1_Recall_optthr: 0.8423  (95% CI 0.5188, 1.1659)\n",
      "task_1_Sensitivity_optthr: 0.8423  (95% CI 0.5188, 1.1659)\n",
      "task_1_Specificity_optthr: 0.5052  (95% CI -0.4594, 1.4698)\n"
     ]
    }
   ],
   "source": [
    "res_cv_only = run_training_and_eval_armed(\n",
    "    X_only_fixed=GHQ_cat_only_fixed.values,\n",
    "    X_fixed_and_random=GHQ_cat_fixed_and_random.values,\n",
    "    y=y_np,\n",
    "    pid_idx=pid_np,\n",
    "    time_index=time_ix_np,\n",
    "    build_model_fn=build_model_fn,\n",
    "    wrapper_cls=wrapper_cls,\n",
    "    mode=\"cv_only\",\n",
    "    scenario=\"both\",\n",
    "    outer_folds=3,\n",
    "    arch_defaults=arch_defaults,      # used as-is; no grid\n",
    "    train_defaults=train_defaults,    # used as-is; no grid\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebcdc69",
   "metadata": {},
   "source": [
    "## New outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7b51b16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "group",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "day",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "beep",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Body_check",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Restr",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Comp",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "BE",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EE",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "NA_1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "NA_2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "NA_3",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "NA_4",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "NA_5",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "NA_6",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "BS_1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "BS_2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "SE_1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "SE_2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "SS",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "day_beep",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "day_beep_copy",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "critical_event",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDEQ_1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDEQ_2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDEQ_3",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDEQ_4",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDEQ_5",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDEQ_6",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDEQ_7",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDEQ_8",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDEQ_9",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDEQ_10",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDEQ_11",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDEQ_12",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDEQ_19",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDEQ_20",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDEQ_21",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDEQ_22",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDEQ_23",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDEQ_24",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDEQ_25",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDEQ_26",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDEQ_27",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDEQ_28",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDDS1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDDS2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDDS3",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDDS4",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDDS5",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDDS6",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDDS7",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDDS8",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDDS9",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDDS10",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDDS11",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDDS12",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDDS13",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDDS14",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDDS15",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDDS16",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDDS17",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDDS18",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "education2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "education3",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "education4",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "critical_event_next",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "day_beep_diff",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "day_beep_diff_copy",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "c5206ecf-8d77-4187-9664-28104c02b0b2",
       "rows": [
        [
         "0",
         "1",
         "29",
         "1",
         "0",
         "4",
         "3",
         "3",
         "1",
         "2",
         "1",
         "2",
         "3",
         "2",
         "3",
         "2",
         "2",
         "3",
         "1",
         "2",
         "1",
         "3",
         "4",
         "4",
         "1",
         "6",
         "1",
         "3",
         "3",
         "0",
         "6",
         "1",
         "2",
         "3",
         "6",
         "6",
         "5",
         "1",
         "1",
         "1",
         "5",
         "5",
         "1",
         "5",
         "5",
         "6",
         "6",
         "4",
         "5",
         "4",
         "0",
         "1",
         "10",
         "0",
         "0",
         "1",
         "1",
         "1",
         "1",
         "0",
         "0",
         "0",
         "2",
         "12",
         "5",
         "0",
         "1",
         "0",
         "1",
         "2",
         "2"
        ],
        [
         "1",
         "1",
         "29",
         "1",
         "1",
         "1",
         "3",
         "4",
         "1",
         "2",
         "1",
         "2",
         "3",
         "3",
         "3",
         "3",
         "2",
         "3",
         "3",
         "2",
         "2",
         "4",
         "6",
         "6",
         "1",
         "6",
         "1",
         "3",
         "3",
         "0",
         "6",
         "1",
         "2",
         "3",
         "6",
         "6",
         "5",
         "1",
         "1",
         "1",
         "5",
         "5",
         "1",
         "5",
         "5",
         "6",
         "6",
         "4",
         "5",
         "4",
         "0",
         "1",
         "10",
         "0",
         "0",
         "1",
         "1",
         "1",
         "1",
         "0",
         "0",
         "0",
         "2",
         "12",
         "5",
         "0",
         "1",
         "0",
         "0",
         "1",
         "1"
        ],
        [
         "2",
         "1",
         "29",
         "1",
         "1",
         "2",
         "1",
         "5",
         "1",
         "1",
         "1",
         "2",
         "2",
         "2",
         "2",
         "1",
         "1",
         "2",
         "1",
         "2",
         "1",
         "4",
         "7",
         "7",
         "0",
         "6",
         "1",
         "3",
         "3",
         "0",
         "6",
         "1",
         "2",
         "3",
         "6",
         "6",
         "5",
         "1",
         "1",
         "1",
         "5",
         "5",
         "1",
         "5",
         "5",
         "6",
         "6",
         "4",
         "5",
         "4",
         "0",
         "1",
         "10",
         "0",
         "0",
         "1",
         "1",
         "1",
         "1",
         "0",
         "0",
         "0",
         "2",
         "12",
         "5",
         "0",
         "1",
         "0",
         "1",
         "1",
         "1"
        ],
        [
         "3",
         "1",
         "29",
         "1",
         "1",
         "3",
         "4",
         "3",
         "1",
         "2",
         "1",
         "3",
         "4",
         "2",
         "4",
         "1",
         "2",
         "3",
         "2",
         "2",
         "1",
         "4",
         "8",
         "8",
         "1",
         "6",
         "1",
         "3",
         "3",
         "0",
         "6",
         "1",
         "2",
         "3",
         "6",
         "6",
         "5",
         "1",
         "1",
         "1",
         "5",
         "5",
         "1",
         "5",
         "5",
         "6",
         "6",
         "4",
         "5",
         "4",
         "0",
         "1",
         "10",
         "0",
         "0",
         "1",
         "1",
         "1",
         "1",
         "0",
         "0",
         "0",
         "2",
         "12",
         "5",
         "0",
         "1",
         "0",
         "0",
         "1",
         "1"
        ],
        [
         "4",
         "1",
         "29",
         "1",
         "1",
         "4",
         "4",
         "2",
         "1",
         "2",
         "1",
         "2",
         "4",
         "2",
         "3",
         "1",
         "1",
         "2",
         "2",
         "2",
         "1",
         "3",
         "9",
         "9",
         "0",
         "6",
         "1",
         "3",
         "3",
         "0",
         "6",
         "1",
         "2",
         "3",
         "6",
         "6",
         "5",
         "1",
         "1",
         "1",
         "5",
         "5",
         "1",
         "5",
         "5",
         "6",
         "6",
         "4",
         "5",
         "4",
         "0",
         "1",
         "10",
         "0",
         "0",
         "1",
         "1",
         "1",
         "1",
         "0",
         "0",
         "0",
         "2",
         "12",
         "5",
         "0",
         "1",
         "0",
         "0",
         "2",
         "2"
        ]
       ],
       "shape": {
        "columns": 70,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>group</th>\n",
       "      <th>day</th>\n",
       "      <th>beep</th>\n",
       "      <th>Body_check</th>\n",
       "      <th>Restr</th>\n",
       "      <th>Comp</th>\n",
       "      <th>BE</th>\n",
       "      <th>EE</th>\n",
       "      <th>...</th>\n",
       "      <th>EDDS15</th>\n",
       "      <th>EDDS16</th>\n",
       "      <th>EDDS17</th>\n",
       "      <th>EDDS18</th>\n",
       "      <th>education2</th>\n",
       "      <th>education3</th>\n",
       "      <th>education4</th>\n",
       "      <th>critical_event_next</th>\n",
       "      <th>day_beep_diff</th>\n",
       "      <th>day_beep_diff_copy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  age  group  day  beep  Body_check  Restr  Comp  BE  EE  ...  EDDS15  \\\n",
       "0   1   29      1    0     4           3      3     1   2   1  ...       0   \n",
       "1   1   29      1    1     1           3      4     1   2   1  ...       0   \n",
       "2   1   29      1    1     2           1      5     1   1   1  ...       0   \n",
       "3   1   29      1    1     3           4      3     1   2   1  ...       0   \n",
       "4   1   29      1    1     4           4      2     1   2   1  ...       0   \n",
       "\n",
       "   EDDS16  EDDS17  EDDS18  education2  education3  education4  \\\n",
       "0       2      12       5           0           1           0   \n",
       "1       2      12       5           0           1           0   \n",
       "2       2      12       5           0           1           0   \n",
       "3       2      12       5           0           1           0   \n",
       "4       2      12       5           0           1           0   \n",
       "\n",
       "   critical_event_next  day_beep_diff  day_beep_diff_copy  \n",
       "0                    1              2                   2  \n",
       "1                    0              1                   1  \n",
       "2                    1              1                   1  \n",
       "3                    0              1                   1  \n",
       "4                    0              2                   2  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Body_cat_df = pd.read_csv(os.path.join(data_dir, \"Body_data_for_categorical_forecast.csv\"))\n",
    "columns_Body_cat_df = pd.read_csv(os.path.join(data_dir, \"columns_Body_data_for_categorical_forecast.csv\"))\n",
    "\n",
    "Body_cat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "077adb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the outcome column(s) marked with 1 in the \"outcomes\" column of columns_Body_cat_df\n",
    "Body_cat_df_outcome_cols = columns_Body_cat_df.loc[columns_Body_cat_df['outcomes'] == 1, 'column_name'].tolist()\n",
    "Body_cat_y = Body_cat_df[Body_cat_df_outcome_cols]\n",
    "Body_cat_y.head()\n",
    "\n",
    "# Same for outcomes lags column(s)\n",
    "Body_cat_outcomes_lags_cols = columns_Body_cat_df.loc[columns_Body_cat_df['outcomes_lags'] == 1, 'column_name'].tolist()\n",
    "Body_cat_outcomes_lags = Body_cat_df[Body_cat_outcomes_lags_cols]\n",
    "\n",
    "# Same for participant column(s)\n",
    "Body_cat_participant_cols = columns_Body_cat_df.loc[columns_Body_cat_df['participant_id'] == 1, 'column_name'].tolist()\n",
    "Body_cat_participant_id = Body_cat_df[Body_cat_participant_cols]\n",
    "\n",
    "# Same for time column(s)\n",
    "Body_cat_time_cols = columns_Body_cat_df.loc[columns_Body_cat_df['time'] == 1, 'column_name'].tolist()\n",
    "Body_cat_time = Body_cat_df[Body_cat_time_cols]\n",
    "\n",
    "# Same for forecast horizons column(s)\n",
    "Body_cat_forecast_horizons_cols = columns_Body_cat_df.loc[columns_Body_cat_df['forecast_horizons'] == 1, 'column_name'].tolist()\n",
    "Body_cat_forecast_horizons = Body_cat_df[Body_cat_forecast_horizons_cols]\n",
    "\n",
    "# Same for fixed effects column(s)\n",
    "Body_cat_only_fixed_cols = columns_Body_cat_df.loc[columns_Body_cat_df['only_fixed'] == 1, 'column_name'].tolist()\n",
    "Body_cat_only_fixed = Body_cat_df[Body_cat_only_fixed_cols]\n",
    "\n",
    "# Same for random effects column(s)\n",
    "Body_cat_fixed_and_random_cols = columns_Body_cat_df.loc[columns_Body_cat_df['fixed_and_random'] == 1, 'column_name'].tolist()\n",
    "Body_cat_fixed_and_random = Body_cat_df[Body_cat_fixed_and_random_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "00b99e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_raw      = Body_cat_y.to_numpy(np.float32)\n",
    "y_np       = y_raw if y_raw.ndim == 2 else y_raw.reshape(-1, 1)\n",
    "\n",
    "pid_raw    = Body_cat_participant_id.to_numpy().ravel()\n",
    "pid_uniqs, pid_encoded = np.unique(pid_raw, return_inverse=True)\n",
    "pid_np     = pid_encoded.astype(np.int64)       \n",
    "n_ids      = int(len(pid_uniqs))                \n",
    "\n",
    "time_ix_np = Body_cat_time.to_numpy().ravel()\n",
    "\n",
    "\n",
    "\n",
    "def build_model_fn(d_fixed, d_random, y_dim, n_participants, **arch):\n",
    "    return ARMEDTabular(\n",
    "        d_fixed=d_fixed,\n",
    "        d_random=d_random,\n",
    "        y_dim=y_dim,\n",
    "        n_participants=n_participants,\n",
    "        **arch\n",
    "    )\n",
    "\n",
    "wrapper_cls = ARMEDWrapper\n",
    "\n",
    "arch_defaults = dict(\n",
    "    fixed_rep_dim=256,\n",
    "    random_rep_dim=256,\n",
    "    combine_mode=\"add\",\n",
    "    grl_lambda=1.0,\n",
    ")\n",
    "\n",
    "train_defaults = dict(\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-4,\n",
    "    batch_size=256,\n",
    "    max_epochs=100,\n",
    "    patience=20,\n",
    "    loss_weights=ARMEDLossWeights(lambda_adv=1.0, lambda_recon=0.0),\n",
    "\n",
    "    # NEW knobs:\n",
    "    pca_var_ratio=0.95,                   # 95% variance PCA\n",
    "    threshold_selection_source=\"train\",   # pick per-task F1 thresholds on TRAIN\n",
    "    monitor_source=\"test\",                # print “val_loss” on the test loader\n",
    "    early_stop_metric=\"loss\",             # default (BCE + λ_adv CE + λ_recon MSE)\n",
    "    early_stop_on=\"val\",                  # stop on validation loss\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "46574408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | train 4.028074 | val_loss(monitor) 0.699170\n",
      "Epoch 002 | train 4.006329 | val_loss(monitor) 0.703826\n",
      "Epoch 003 | train 3.987052 | val_loss(monitor) 0.709048\n",
      "Epoch 004 | train 3.969835 | val_loss(monitor) 0.714651\n",
      "Epoch 005 | train 3.954430 | val_loss(monitor) 0.720502\n",
      "Epoch 006 | train 3.941038 | val_loss(monitor) 0.726300\n",
      "Epoch 007 | train 3.928426 | val_loss(monitor) 0.731854\n",
      "Epoch 008 | train 3.917093 | val_loss(monitor) 0.737196\n",
      "Epoch 009 | train 3.906043 | val_loss(monitor) 0.742041\n",
      "Epoch 010 | train 3.896091 | val_loss(monitor) 0.746426\n",
      "Epoch 011 | train 3.886171 | val_loss(monitor) 0.750105\n",
      "Epoch 012 | train 3.877179 | val_loss(monitor) 0.753221\n",
      "Epoch 013 | train 3.868231 | val_loss(monitor) 0.755465\n",
      "Epoch 014 | train 3.859213 | val_loss(monitor) 0.757318\n",
      "Epoch 015 | train 3.851116 | val_loss(monitor) 0.758610\n",
      "Epoch 016 | train 3.842240 | val_loss(monitor) 0.759756\n",
      "Epoch 017 | train 3.834473 | val_loss(monitor) 0.761044\n",
      "Epoch 018 | train 3.826720 | val_loss(monitor) 0.762361\n",
      "Epoch 019 | train 3.819029 | val_loss(monitor) 0.764008\n",
      "Epoch 020 | train 3.811740 | val_loss(monitor) 0.766408\n",
      "Epoch 021 | train 3.804373 | val_loss(monitor) 0.769328\n",
      "Epoch 022 | train 3.797680 | val_loss(monitor) 0.772425\n",
      "Epoch 023 | train 3.791311 | val_loss(monitor) 0.775549\n",
      "Epoch 024 | train 3.784533 | val_loss(monitor) 0.778478\n",
      "Epoch 025 | train 3.778805 | val_loss(monitor) 0.781260\n",
      "Epoch 026 | train 3.773344 | val_loss(monitor) 0.783754\n",
      "Epoch 027 | train 3.767888 | val_loss(monitor) 0.786139\n",
      "Epoch 028 | train 3.763035 | val_loss(monitor) 0.788759\n",
      "Epoch 029 | train 3.758501 | val_loss(monitor) 0.791083\n",
      "Epoch 030 | train 3.754734 | val_loss(monitor) 0.793443\n",
      "Epoch 031 | train 3.750686 | val_loss(monitor) 0.796451\n",
      "Epoch 032 | train 3.747029 | val_loss(monitor) 0.799451\n",
      "Epoch 033 | train 3.743685 | val_loss(monitor) 0.802744\n",
      "Epoch 034 | train 3.740549 | val_loss(monitor) 0.805895\n",
      "Epoch 035 | train 3.737497 | val_loss(monitor) 0.808924\n",
      "Epoch 036 | train 3.734634 | val_loss(monitor) 0.811589\n",
      "Epoch 037 | train 3.732310 | val_loss(monitor) 0.813617\n",
      "Epoch 038 | train 3.729629 | val_loss(monitor) 0.814696\n",
      "Epoch 039 | train 3.727063 | val_loss(monitor) 0.815477\n",
      "Epoch 040 | train 3.724527 | val_loss(monitor) 0.815973\n",
      "Epoch 041 | train 3.722364 | val_loss(monitor) 0.816580\n",
      "Epoch 042 | train 3.720031 | val_loss(monitor) 0.816581\n",
      "Epoch 043 | train 3.717669 | val_loss(monitor) 0.817256\n",
      "Epoch 044 | train 3.715649 | val_loss(monitor) 0.818217\n",
      "Epoch 045 | train 3.713586 | val_loss(monitor) 0.819313\n",
      "Epoch 046 | train 3.711334 | val_loss(monitor) 0.819448\n",
      "Epoch 047 | train 3.709194 | val_loss(monitor) 0.820127\n",
      "Epoch 048 | train 3.706935 | val_loss(monitor) 0.821033\n",
      "Epoch 049 | train 3.704663 | val_loss(monitor) 0.821896\n",
      "Epoch 050 | train 3.702600 | val_loss(monitor) 0.821982\n",
      "Early stopping at epoch 050 (best loss@val 3.894992)\n",
      "\n",
      "Single-fit test metrics @0.5:\n",
      "        task_1_AUC: 0.3889\n",
      "      task_1_AUPRC: 0.5946\n",
      "      task_1_Brier: 0.2964\n",
      "        task_1_ACC: 0.4556\n",
      "         task_1_F1: 0.6080\n",
      "  task_1_Precision: 0.4935\n",
      "     task_1_Recall: 0.7917\n",
      "task_1_Sensitivity: 0.7917\n",
      "task_1_Specificity: 0.0714\n",
      "         macro_AUC: 0.3889\n",
      "       macro_AUPRC: 0.5946\n",
      "       macro_Brier: 0.2964\n",
      "         macro_ACC: 0.4556\n",
      "          macro_F1: 0.6080\n",
      "   macro_Precision: 0.4935\n",
      "      macro_Recall: 0.7917\n",
      " macro_Sensitivity: 0.7917\n",
      " macro_Specificity: 0.0714\n",
      "\n",
      "Single-fit test metrics @F1-opt per task:\n",
      " task_1_AUC_optthr: 0.3889\n",
      "task_1_AUPRC_optthr: 0.5946\n",
      "task_1_Brier_optthr: 0.2964\n",
      " task_1_ACC_optthr: 0.4556\n",
      "  task_1_F1_optthr: 0.6080\n",
      "task_1_Precision_optthr: 0.4935\n",
      "task_1_Recall_optthr: 0.7917\n",
      "task_1_Sensitivity_optthr: 0.7917\n",
      "task_1_Specificity_optthr: 0.0714\n",
      "  macro_AUC_optthr: 0.3889\n",
      "macro_AUPRC_optthr: 0.5946\n",
      "macro_Brier_optthr: 0.2964\n",
      "  macro_ACC_optthr: 0.4556\n",
      "   macro_F1_optthr: 0.6080\n",
      "macro_Precision_optthr: 0.4935\n",
      "macro_Recall_optthr: 0.7917\n",
      "macro_Sensitivity_optthr: 0.7917\n",
      "macro_Specificity_optthr: 0.0714\n",
      "Epoch 001 | train 4.223377 | val_loss(monitor) 4.233030\n",
      "Epoch 002 | train 4.205903 | val_loss(monitor) 4.224300\n",
      "Epoch 003 | train 4.190288 | val_loss(monitor) 4.215978\n",
      "Epoch 004 | train 4.176594 | val_loss(monitor) 4.208589\n",
      "Epoch 005 | train 4.164215 | val_loss(monitor) 4.201733\n",
      "Epoch 006 | train 4.152219 | val_loss(monitor) 4.194947\n",
      "Epoch 007 | train 4.141729 | val_loss(monitor) 4.188143\n",
      "Epoch 008 | train 4.131624 | val_loss(monitor) 4.181557\n",
      "Epoch 009 | train 4.122224 | val_loss(monitor) 4.174633\n",
      "Epoch 010 | train 4.113175 | val_loss(monitor) 4.168178\n",
      "Epoch 011 | train 4.104516 | val_loss(monitor) 4.161676\n",
      "Epoch 012 | train 4.096292 | val_loss(monitor) 4.155047\n",
      "Epoch 013 | train 4.088026 | val_loss(monitor) 4.148051\n",
      "Epoch 014 | train 4.080238 | val_loss(monitor) 4.141079\n",
      "Epoch 015 | train 4.072767 | val_loss(monitor) 4.134857\n",
      "Epoch 016 | train 4.065572 | val_loss(monitor) 4.128862\n",
      "Epoch 017 | train 4.058588 | val_loss(monitor) 4.123049\n",
      "Epoch 018 | train 4.052373 | val_loss(monitor) 4.117650\n",
      "Epoch 019 | train 4.046227 | val_loss(monitor) 4.112571\n",
      "Epoch 020 | train 4.040185 | val_loss(monitor) 4.107887\n",
      "Epoch 021 | train 4.034487 | val_loss(monitor) 4.103475\n",
      "Epoch 022 | train 4.028995 | val_loss(monitor) 4.098983\n",
      "Epoch 023 | train 4.024115 | val_loss(monitor) 4.094288\n",
      "Epoch 024 | train 4.019055 | val_loss(monitor) 4.089901\n",
      "Epoch 025 | train 4.014651 | val_loss(monitor) 4.085952\n",
      "Epoch 026 | train 4.010203 | val_loss(monitor) 4.082427\n",
      "Epoch 027 | train 4.006089 | val_loss(monitor) 4.079024\n",
      "Epoch 028 | train 4.002106 | val_loss(monitor) 4.075967\n",
      "Epoch 029 | train 3.998207 | val_loss(monitor) 4.073123\n",
      "Epoch 030 | train 3.994374 | val_loss(monitor) 4.070195\n",
      "Epoch 031 | train 3.991132 | val_loss(monitor) 4.067735\n",
      "Epoch 032 | train 3.987549 | val_loss(monitor) 4.065501\n",
      "Epoch 033 | train 3.983672 | val_loss(monitor) 4.063311\n",
      "Epoch 034 | train 3.980221 | val_loss(monitor) 4.061072\n",
      "Epoch 035 | train 3.977301 | val_loss(monitor) 4.059053\n",
      "Epoch 036 | train 3.973949 | val_loss(monitor) 4.056638\n",
      "Epoch 037 | train 3.971335 | val_loss(monitor) 4.054267\n",
      "Epoch 038 | train 3.968408 | val_loss(monitor) 4.051809\n",
      "Epoch 039 | train 3.965968 | val_loss(monitor) 4.048620\n",
      "Epoch 040 | train 3.963034 | val_loss(monitor) 4.045135\n",
      "Epoch 041 | train 3.960378 | val_loss(monitor) 4.041481\n",
      "Epoch 042 | train 3.957666 | val_loss(monitor) 4.038010\n",
      "Epoch 043 | train 3.955134 | val_loss(monitor) 4.034717\n",
      "Epoch 044 | train 3.952538 | val_loss(monitor) 4.031274\n",
      "Epoch 045 | train 3.950227 | val_loss(monitor) 4.027848\n",
      "Epoch 046 | train 3.947406 | val_loss(monitor) 4.024598\n",
      "Epoch 047 | train 3.944922 | val_loss(monitor) 4.021492\n",
      "Epoch 048 | train 3.942094 | val_loss(monitor) 4.018806\n",
      "Epoch 049 | train 3.939626 | val_loss(monitor) 4.016555\n",
      "Epoch 050 | train 3.936754 | val_loss(monitor) 4.014234\n",
      "Epoch 051 | train 3.934023 | val_loss(monitor) 4.011791\n",
      "Epoch 052 | train 3.931296 | val_loss(monitor) 4.008864\n",
      "Epoch 053 | train 3.928203 | val_loss(monitor) 4.005568\n",
      "Epoch 054 | train 3.925366 | val_loss(monitor) 4.001934\n",
      "Epoch 055 | train 3.922698 | val_loss(monitor) 3.998329\n",
      "Epoch 056 | train 3.919644 | val_loss(monitor) 3.995087\n",
      "Epoch 057 | train 3.916554 | val_loss(monitor) 3.991611\n",
      "Epoch 058 | train 3.913028 | val_loss(monitor) 3.988889\n",
      "Epoch 059 | train 3.909740 | val_loss(monitor) 3.986179\n",
      "Epoch 060 | train 3.906983 | val_loss(monitor) 3.983287\n",
      "Epoch 061 | train 3.903435 | val_loss(monitor) 3.980885\n",
      "Epoch 062 | train 3.900464 | val_loss(monitor) 3.978247\n",
      "Epoch 063 | train 3.897701 | val_loss(monitor) 3.976024\n",
      "Epoch 064 | train 3.895004 | val_loss(monitor) 3.973944\n",
      "Epoch 065 | train 3.892411 | val_loss(monitor) 3.972000\n",
      "Epoch 066 | train 3.889512 | val_loss(monitor) 3.969587\n",
      "Epoch 067 | train 3.886707 | val_loss(monitor) 3.966549\n",
      "Epoch 068 | train 3.883803 | val_loss(monitor) 3.963345\n",
      "Epoch 069 | train 3.880752 | val_loss(monitor) 3.959764\n",
      "Epoch 070 | train 3.877635 | val_loss(monitor) 3.956256\n",
      "Epoch 071 | train 3.874658 | val_loss(monitor) 3.952399\n",
      "Epoch 072 | train 3.871517 | val_loss(monitor) 3.949120\n",
      "Epoch 073 | train 3.867882 | val_loss(monitor) 3.946321\n",
      "Epoch 074 | train 3.864171 | val_loss(monitor) 3.943524\n",
      "Early stopping at epoch 074 (best loss@val 3.965520)\n",
      "\n",
      "Single-fit test metrics @0.5:\n",
      "        task_1_AUC: 0.8235\n",
      "      task_1_AUPRC: 0.8619\n",
      "      task_1_Brier: 0.1630\n",
      "        task_1_ACC: 0.7549\n",
      "         task_1_F1: 0.7573\n",
      "  task_1_Precision: 0.7647\n",
      "     task_1_Recall: 0.7500\n",
      "task_1_Sensitivity: 0.7500\n",
      "task_1_Specificity: 0.7600\n",
      "         macro_AUC: 0.8235\n",
      "       macro_AUPRC: 0.8619\n",
      "       macro_Brier: 0.1630\n",
      "         macro_ACC: 0.7549\n",
      "          macro_F1: 0.7573\n",
      "   macro_Precision: 0.7647\n",
      "      macro_Recall: 0.7500\n",
      " macro_Sensitivity: 0.7500\n",
      " macro_Specificity: 0.7600\n",
      "\n",
      "Single-fit test metrics @F1-opt per task:\n",
      " task_1_AUC_optthr: 0.8235\n",
      "task_1_AUPRC_optthr: 0.8619\n",
      "task_1_Brier_optthr: 0.1630\n",
      " task_1_ACC_optthr: 0.7647\n",
      "  task_1_F1_optthr: 0.7647\n",
      "task_1_Precision_optthr: 0.7800\n",
      "task_1_Recall_optthr: 0.7500\n",
      "task_1_Sensitivity_optthr: 0.7500\n",
      "task_1_Specificity_optthr: 0.7800\n",
      "  macro_AUC_optthr: 0.8235\n",
      "macro_AUPRC_optthr: 0.8619\n",
      "macro_Brier_optthr: 0.1630\n",
      "  macro_ACC_optthr: 0.7647\n",
      "   macro_F1_optthr: 0.7647\n",
      "macro_Precision_optthr: 0.7800\n",
      "macro_Recall_optthr: 0.7500\n",
      "macro_Sensitivity_optthr: 0.7500\n",
      "macro_Specificity_optthr: 0.7800\n"
     ]
    }
   ],
   "source": [
    "res_simple = run_training_and_eval_armed(\n",
    "    X_only_fixed=Body_cat_only_fixed.values,\n",
    "    X_fixed_and_random=Body_cat_fixed_and_random.values,\n",
    "    y=y_np,\n",
    "    pid_idx=pid_np,\n",
    "    time_index=time_ix_np,\n",
    "    build_model_fn=build_model_fn,\n",
    "    wrapper_cls=wrapper_cls,\n",
    "    mode=\"single\",\n",
    "    scenario=\"both\",          # <- runs cases and time in one go\n",
    "    arch_defaults=arch_defaults,\n",
    "    train_defaults=train_defaults,\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "edb57b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: macro_AUC_optthr=0.8036, macro_AUPRC_optthr=0.8602, macro_Brier_optthr=0.1651, macro_ACC_optthr=0.7529, macro_F1_optthr=0.8158, macro_Precision_optthr=0.7949, macro_Recall_optthr=0.8378, macro_Sensitivity_optthr=0.8378, macro_Specificity_optthr=0.5932\n",
      "Fold 2: macro_AUC_optthr=0.6982, macro_AUPRC_optthr=0.6902, macro_Brier_optthr=0.3161, macro_ACC_optthr=0.5176, macro_F1_optthr=0.6822, macro_Precision_optthr=0.5176, macro_Recall_optthr=1.0000, macro_Sensitivity_optthr=1.0000, macro_Specificity_optthr=0.0000\n",
      "Fold 3: macro_AUC_optthr=0.6884, macro_AUPRC_optthr=0.8076, macro_Brier_optthr=0.2141, macro_ACC_optthr=0.5976, macro_F1_optthr=0.6495, macro_Precision_optthr=0.7079, macro_Recall_optthr=0.6000, macro_Sensitivity_optthr=0.6000, macro_Specificity_optthr=0.5938\n",
      "\n",
      "CV averages (±95% CI) for 0.50 treshold:\n",
      "           macro_ACC: 0.6326  (95% CI 0.3235, 0.9417)\n",
      "           macro_AUC: 0.7301  (95% CI 0.5713, 0.8888)\n",
      "         macro_AUPRC: 0.7860  (95% CI 0.5698, 1.0022)\n",
      "         macro_Brier: 0.2318  (95% CI 0.0403, 0.4232)\n",
      "            macro_F1: 0.7282  (95% CI 0.5382, 0.9182)\n",
      "     macro_Precision: 0.6818  (95% CI 0.2905, 1.0732)\n",
      "        macro_Recall: 0.8260  (95% CI 0.4204, 1.2315)\n",
      "   macro_Sensitivity: 0.8260  (95% CI 0.4204, 1.2315)\n",
      "   macro_Specificity: 0.4035  (95% CI -0.4927, 1.2997)\n",
      "          task_1_ACC: 0.6326  (95% CI 0.3235, 0.9417)\n",
      "          task_1_AUC: 0.7301  (95% CI 0.5713, 0.8888)\n",
      "        task_1_AUPRC: 0.7860  (95% CI 0.5698, 1.0022)\n",
      "        task_1_Brier: 0.2318  (95% CI 0.0403, 0.4232)\n",
      "           task_1_F1: 0.7282  (95% CI 0.5382, 0.9182)\n",
      "    task_1_Precision: 0.6818  (95% CI 0.2905, 1.0732)\n",
      "       task_1_Recall: 0.8260  (95% CI 0.4204, 1.2315)\n",
      "  task_1_Sensitivity: 0.8260  (95% CI 0.4204, 1.2315)\n",
      "  task_1_Specificity: 0.4035  (95% CI -0.4927, 1.2997)\n",
      "\n",
      "CV averages (±95% CI) for optimal threshold:\n",
      "    macro_ACC_optthr: 0.6227  (95% CI 0.3255, 0.9199)\n",
      "    macro_AUC_optthr: 0.7301  (95% CI 0.5713, 0.8888)\n",
      "  macro_AUPRC_optthr: 0.7860  (95% CI 0.5698, 1.0022)\n",
      "  macro_Brier_optthr: 0.2318  (95% CI 0.0403, 0.4232)\n",
      "     macro_F1_optthr: 0.7158  (95% CI 0.4969, 0.9347)\n",
      "macro_Precision_optthr: 0.6735  (95% CI 0.3213, 1.0257)\n",
      " macro_Recall_optthr: 0.8126  (95% CI 0.3128, 1.3124)\n",
      "macro_Sensitivity_optthr: 0.8126  (95% CI 0.3128, 1.3124)\n",
      "macro_Specificity_optthr: 0.3957  (95% CI -0.4555, 1.2468)\n",
      "   task_1_ACC_optthr: 0.6227  (95% CI 0.3255, 0.9199)\n",
      "   task_1_AUC_optthr: 0.7301  (95% CI 0.5713, 0.8888)\n",
      " task_1_AUPRC_optthr: 0.7860  (95% CI 0.5698, 1.0022)\n",
      " task_1_Brier_optthr: 0.2318  (95% CI 0.0403, 0.4232)\n",
      "    task_1_F1_optthr: 0.7158  (95% CI 0.4969, 0.9347)\n",
      "task_1_Precision_optthr: 0.6735  (95% CI 0.3213, 1.0257)\n",
      "task_1_Recall_optthr: 0.8126  (95% CI 0.3128, 1.3124)\n",
      "task_1_Sensitivity_optthr: 0.8126  (95% CI 0.3128, 1.3124)\n",
      "task_1_Specificity_optthr: 0.3957  (95% CI -0.4555, 1.2468)\n",
      "Fold 1: macro_AUC_optthr=0.8611, macro_AUPRC_optthr=0.8937, macro_Brier_optthr=0.1581, macro_ACC_optthr=0.7419, macro_F1_optthr=0.8118, macro_Precision_optthr=0.7188, macro_Recall_optthr=0.9324, macro_Sensitivity_optthr=0.9324, macro_Specificity_optthr=0.4600\n",
      "Fold 2: macro_AUC_optthr=0.8546, macro_AUPRC_optthr=0.8877, macro_Brier_optthr=0.1708, macro_ACC_optthr=0.7874, macro_F1_optthr=0.8258, macro_Precision_optthr=0.7619, macro_Recall_optthr=0.9014, macro_Sensitivity_optthr=0.9014, macro_Specificity_optthr=0.6429\n",
      "Fold 3: macro_AUC_optthr=0.8366, macro_AUPRC_optthr=0.8683, macro_Brier_optthr=0.1631, macro_ACC_optthr=0.7323, macro_F1_optthr=0.7213, macro_Precision_optthr=0.7586, macro_Recall_optthr=0.6875, macro_Sensitivity_optthr=0.6875, macro_Specificity_optthr=0.7778\n",
      "\n",
      "CV averages (±95% CI) for 0.50 treshold:\n",
      "           macro_ACC: 0.7595  (95% CI 0.6870, 0.8320)\n",
      "           macro_AUC: 0.8508  (95% CI 0.8192, 0.8823)\n",
      "         macro_AUPRC: 0.8832  (95% CI 0.8503, 0.9162)\n",
      "         macro_Brier: 0.1640  (95% CI 0.1482, 0.1798)\n",
      "            macro_F1: 0.7931  (95% CI 0.6438, 0.9425)\n",
      "     macro_Precision: 0.7431  (95% CI 0.6746, 0.8117)\n",
      "        macro_Recall: 0.8597  (95% CI 0.5225, 1.1970)\n",
      "   macro_Sensitivity: 0.8597  (95% CI 0.5225, 1.1970)\n",
      "   macro_Specificity: 0.6199  (95% CI 0.3049, 0.9350)\n",
      "          task_1_ACC: 0.7595  (95% CI 0.6870, 0.8320)\n",
      "          task_1_AUC: 0.8508  (95% CI 0.8192, 0.8823)\n",
      "        task_1_AUPRC: 0.8832  (95% CI 0.8503, 0.9162)\n",
      "        task_1_Brier: 0.1640  (95% CI 0.1482, 0.1798)\n",
      "           task_1_F1: 0.7931  (95% CI 0.6438, 0.9425)\n",
      "    task_1_Precision: 0.7431  (95% CI 0.6746, 0.8117)\n",
      "       task_1_Recall: 0.8597  (95% CI 0.5225, 1.1970)\n",
      "  task_1_Sensitivity: 0.8597  (95% CI 0.5225, 1.1970)\n",
      "  task_1_Specificity: 0.6199  (95% CI 0.3049, 0.9350)\n",
      "\n",
      "CV averages (±95% CI) for optimal threshold:\n",
      "    macro_ACC_optthr: 0.7539  (95% CI 0.6808, 0.8270)\n",
      "    macro_AUC_optthr: 0.8508  (95% CI 0.8192, 0.8823)\n",
      "  macro_AUPRC_optthr: 0.8832  (95% CI 0.8503, 0.9162)\n",
      "  macro_Brier_optthr: 0.1640  (95% CI 0.1482, 0.1798)\n",
      "     macro_F1_optthr: 0.7863  (95% CI 0.6454, 0.9272)\n",
      "macro_Precision_optthr: 0.7464  (95% CI 0.6867, 0.8061)\n",
      " macro_Recall_optthr: 0.8404  (95% CI 0.5092, 1.1717)\n",
      "macro_Sensitivity_optthr: 0.8404  (95% CI 0.5092, 1.1717)\n",
      "macro_Specificity_optthr: 0.6269  (95% CI 0.2307, 1.0231)\n",
      "   task_1_ACC_optthr: 0.7539  (95% CI 0.6808, 0.8270)\n",
      "   task_1_AUC_optthr: 0.8508  (95% CI 0.8192, 0.8823)\n",
      " task_1_AUPRC_optthr: 0.8832  (95% CI 0.8503, 0.9162)\n",
      " task_1_Brier_optthr: 0.1640  (95% CI 0.1482, 0.1798)\n",
      "    task_1_F1_optthr: 0.7863  (95% CI 0.6454, 0.9272)\n",
      "task_1_Precision_optthr: 0.7464  (95% CI 0.6867, 0.8061)\n",
      "task_1_Recall_optthr: 0.8404  (95% CI 0.5092, 1.1717)\n",
      "task_1_Sensitivity_optthr: 0.8404  (95% CI 0.5092, 1.1717)\n",
      "task_1_Specificity_optthr: 0.6269  (95% CI 0.2307, 1.0231)\n"
     ]
    }
   ],
   "source": [
    "res_cv_only = run_training_and_eval_armed(\n",
    "    X_only_fixed=Body_cat_only_fixed.values,\n",
    "    X_fixed_and_random=Body_cat_fixed_and_random.values,\n",
    "    y=y_np,\n",
    "    pid_idx=pid_np,\n",
    "    time_index=time_ix_np,\n",
    "    build_model_fn=build_model_fn,\n",
    "    wrapper_cls=wrapper_cls,\n",
    "    mode=\"cv_only\",\n",
    "    scenario=\"both\",\n",
    "    outer_folds=3,\n",
    "    arch_defaults=arch_defaults,      # used as-is; no grid\n",
    "    train_defaults=train_defaults,    # used as-is; no grid\n",
    "    verbose=True,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
