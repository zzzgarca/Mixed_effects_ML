{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f278667b",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a1069b",
   "metadata": {},
   "source": [
    "## Root and data folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "068e5c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "root_dir = \"/Users/silviumatu/Desktop/Code/Python/Disertatie/Disertatie_Matu_Silviu_v1\"\n",
    "os.makedirs(root_dir, exist_ok=True)\n",
    "\n",
    "data_dir = os.path.join(root_dir, \"Data\")\n",
    "os.makedirs(data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1166a5e",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d6a9787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_participant_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_gender",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_BDI_TOTAL_pre",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_YSQ_D1_pre",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_YSQ_D2_pre",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_LSAS_ANX_pre",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_LSAS_AVOID_pre",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_day_participant",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_response_within_day_participant",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_time_intervals",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_duration",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x_q3",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_q4",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_q5",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_q6",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_q7",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_q8",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_q9",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_q10",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_q11",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_q12",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_q13",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_depression",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_q2_value_1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_q2_value_2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_q2_value_3",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_q2_value_4",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_q2_value_5",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_q2_value_6",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_q2_value_7",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_time_intervals_copy",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x_time_difference",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y_dep_score_next",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "d9c38d43-10b6-4416-8521-3054673e54e2",
       "rows": [
        [
         "0",
         "6",
         "22",
         "1.0",
         "20",
         "133",
         "61",
         "51",
         "47",
         "0",
         "0",
         "0",
         "67.71",
         "5",
         "2",
         "1",
         "1",
         "1",
         "3",
         "3",
         "3",
         "2",
         "1",
         "1",
         "12",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1.0",
         "10.0"
        ],
        [
         "1",
         "6",
         "22",
         "1.0",
         "20",
         "133",
         "61",
         "51",
         "47",
         "0",
         "1",
         "1",
         "59.23",
         "4",
         "2",
         "1",
         "2",
         "1",
         "5",
         "2",
         "5",
         "2",
         "1",
         "1",
         "10",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1.0",
         "2.0"
        ],
        [
         "2",
         "6",
         "22",
         "1.0",
         "20",
         "133",
         "61",
         "51",
         "47",
         "0",
         "2",
         "2",
         "41.122",
         "0",
         "5",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "2",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "2",
         "5.0",
         "4.0"
        ],
        [
         "3",
         "6",
         "22",
         "1.0",
         "20",
         "133",
         "61",
         "51",
         "47",
         "1",
         "0",
         "7",
         "46.619",
         "2",
         "3",
         "1",
         "1",
         "1",
         "1",
         "2",
         "3",
         "1",
         "1",
         "1",
         "4",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "7",
         "3.0",
         "3.0"
        ],
        [
         "4",
         "6",
         "22",
         "1.0",
         "20",
         "133",
         "61",
         "51",
         "47",
         "1",
         "1",
         "10",
         "40.567",
         "0",
         "5",
         "0",
         "0",
         "0",
         "3",
         "0",
         "3",
         "1",
         "1",
         "2",
         "3",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "10",
         "5.0",
         "15.0"
        ]
       ],
       "shape": {
        "columns": 34,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_participant_id</th>\n",
       "      <th>x_age</th>\n",
       "      <th>x_gender</th>\n",
       "      <th>x_BDI_TOTAL_pre</th>\n",
       "      <th>x_YSQ_D1_pre</th>\n",
       "      <th>x_YSQ_D2_pre</th>\n",
       "      <th>x_LSAS_ANX_pre</th>\n",
       "      <th>x_LSAS_AVOID_pre</th>\n",
       "      <th>x_day_participant</th>\n",
       "      <th>x_response_within_day_participant</th>\n",
       "      <th>...</th>\n",
       "      <th>x_q2_value_1</th>\n",
       "      <th>x_q2_value_2</th>\n",
       "      <th>x_q2_value_3</th>\n",
       "      <th>x_q2_value_4</th>\n",
       "      <th>x_q2_value_5</th>\n",
       "      <th>x_q2_value_6</th>\n",
       "      <th>x_q2_value_7</th>\n",
       "      <th>x_time_intervals_copy</th>\n",
       "      <th>x_time_difference</th>\n",
       "      <th>y_dep_score_next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>133</td>\n",
       "      <td>61</td>\n",
       "      <td>51</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>133</td>\n",
       "      <td>61</td>\n",
       "      <td>51</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>133</td>\n",
       "      <td>61</td>\n",
       "      <td>51</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>133</td>\n",
       "      <td>61</td>\n",
       "      <td>51</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>133</td>\n",
       "      <td>61</td>\n",
       "      <td>51</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   x_participant_id  x_age  x_gender  x_BDI_TOTAL_pre  x_YSQ_D1_pre  \\\n",
       "0                 6     22       1.0               20           133   \n",
       "1                 6     22       1.0               20           133   \n",
       "2                 6     22       1.0               20           133   \n",
       "3                 6     22       1.0               20           133   \n",
       "4                 6     22       1.0               20           133   \n",
       "\n",
       "   x_YSQ_D2_pre  x_LSAS_ANX_pre  x_LSAS_AVOID_pre  x_day_participant  \\\n",
       "0            61              51                47                  0   \n",
       "1            61              51                47                  0   \n",
       "2            61              51                47                  0   \n",
       "3            61              51                47                  1   \n",
       "4            61              51                47                  1   \n",
       "\n",
       "   x_response_within_day_participant  ...  x_q2_value_1  x_q2_value_2  \\\n",
       "0                                  0  ...             0             0   \n",
       "1                                  1  ...             0             1   \n",
       "2                                  2  ...             1             0   \n",
       "3                                  0  ...             0             0   \n",
       "4                                  1  ...             1             0   \n",
       "\n",
       "   x_q2_value_3  x_q2_value_4  x_q2_value_5  x_q2_value_6  x_q2_value_7  \\\n",
       "0             1             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             1             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   x_time_intervals_copy  x_time_difference  y_dep_score_next  \n",
       "0                      0                1.0              10.0  \n",
       "1                      1                1.0               2.0  \n",
       "2                      2                5.0               4.0  \n",
       "3                      7                3.0               3.0  \n",
       "4                     10                5.0              15.0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXP_reg_df = pd.read_csv(os.path.join(data_dir, \"EXP_regression_data_forecast.csv\"))\n",
    "columns_EXP_reg_df = pd.read_csv(os.path.join(data_dir, \"columns_EXP_regression_data_forecast.csv\"))\n",
    "\n",
    "EXP_reg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c174fcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the outcome column(s) marked with 1 in the \"outcomes\" column of columns_EXP_reg_df\n",
    "EXP_reg_outcome_cols = columns_EXP_reg_df.loc[columns_EXP_reg_df['outcomes'] == 1, 'column_name'].tolist()\n",
    "EXP_reg_y = EXP_reg_df[EXP_reg_outcome_cols]\n",
    "EXP_reg_y.head()\n",
    "\n",
    "# Same for outcomes lags column(s)\n",
    "EXP_reg_outcomes_lags_cols = columns_EXP_reg_df.loc[columns_EXP_reg_df['outcomes_lags'] == 1, 'column_name'].tolist()\n",
    "EXP_reg_outcomes_lags = EXP_reg_df[EXP_reg_outcomes_lags_cols]\n",
    "\n",
    "# Same for participant column(s)\n",
    "EXP_reg_participant_cols = columns_EXP_reg_df.loc[columns_EXP_reg_df['participant_id'] == 1, 'column_name'].tolist()\n",
    "EXP_reg_participant_id = EXP_reg_df[EXP_reg_participant_cols]\n",
    "\n",
    "# Same for time column(s)\n",
    "EXP_reg_time_cols = columns_EXP_reg_df.loc[columns_EXP_reg_df['time'] == 1, 'column_name'].tolist()\n",
    "EXP_reg_time = EXP_reg_df[EXP_reg_time_cols]\n",
    "\n",
    "# Same for forecast horizons column(s)\n",
    "EXP_reg_forecast_horizons_cols = columns_EXP_reg_df.loc[columns_EXP_reg_df['forecast_horizons'] == 1, 'column_name'].tolist()\n",
    "EXP_reg_forecast_horizons = EXP_reg_df[EXP_reg_forecast_horizons_cols]\n",
    "\n",
    "# Same for fixed effects column(s)\n",
    "EXP_reg_only_fixed_cols = columns_EXP_reg_df.loc[columns_EXP_reg_df['only_fixed'] == 1, 'column_name'].tolist()\n",
    "EXP_reg_only_fixed = EXP_reg_df[EXP_reg_only_fixed_cols]\n",
    "\n",
    "# Same for random effects column(s)\n",
    "EXP_reg_fixed_and_random_cols = columns_EXP_reg_df.loc[columns_EXP_reg_df['fixed_and_random'] == 1, 'column_name'].tolist()\n",
    "EXP_reg_fixed_and_random = EXP_reg_df[EXP_reg_fixed_and_random_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de618133",
   "metadata": {},
   "source": [
    "# ARMED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916c36bf",
   "metadata": {},
   "source": [
    "## Architecutre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ce60db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple, Dict, Any, Iterable\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GradientReversalFn(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, lambd: float):\n",
    "        ctx.lambd = float(lambd)\n",
    "        return x\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return -ctx.lambd * grad_output, None\n",
    "\n",
    "class GradientReversal(nn.Module):\n",
    "    def __init__(self, lambd: float = 1.0):\n",
    "        super().__init__()\n",
    "        self.lambd = float(lambd)\n",
    "    def set_lambda(self, lambd: float):\n",
    "        self.lambd = float(lambd)\n",
    "    def forward(self, x):\n",
    "        return GradientReversalFn.apply(x, self.lambd)\n",
    "\n",
    "def mlp(in_dim: int, hidden: Iterable[int], out_dim: int, dropout: float = 0.0, last_activation: Optional[nn.Module] = None):\n",
    "    layers: list[nn.Module] = []\n",
    "    dims = [in_dim] + list(hidden)\n",
    "    for d0, d1 in zip(dims[:-1], dims[1:]):\n",
    "        layers.append(nn.Linear(d0, d1))\n",
    "        layers.append(nn.ReLU())\n",
    "        if dropout > 0:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "    layers.append(nn.Linear(dims[-1], out_dim))\n",
    "    if last_activation is not None:\n",
    "        layers.append(last_activation)\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class FixedAE(nn.Module):\n",
    "    def __init__(self, in_dim: int, enc_hidden=(128, 64), rep_dim=32, dropout=0.0,\n",
    "                 use_decoder: bool = False, dec_hidden: Optional[Iterable[int]] = None):\n",
    "        super().__init__()\n",
    "        self.encoder = mlp(in_dim, enc_hidden, rep_dim, dropout)\n",
    "        self.use_decoder = bool(use_decoder)\n",
    "        if self.use_decoder:\n",
    "            dec_hidden = list(dec_hidden) if dec_hidden is not None else list(enc_hidden)[::-1]\n",
    "            self.decoder = mlp(rep_dim, dec_hidden, in_dim, dropout)\n",
    "        else:\n",
    "            self.decoder = None\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n",
    "        z = self.encoder(x)\n",
    "        xhat = self.decoder(z) if self.decoder is not None else None\n",
    "        return z, xhat\n",
    "\n",
    "class RandomEnc(nn.Module):\n",
    "    def __init__(self, in_dim: int, hidden=(128, 64), rep_dim=32, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.net = mlp(in_dim, hidden, rep_dim, dropout)\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "\n",
    "class ParticipantEmbedding(nn.Module):\n",
    "    def __init__(self, n_participants: int, rep_dim: int):\n",
    "        super().__init__()\n",
    "        self.n_seen = int(n_participants)\n",
    "        self.unk_index = self.n_seen\n",
    "        self.emb = nn.Embedding(self.n_seen + 1, rep_dim, padding_idx=None)\n",
    "    def forward(self, pid_idx: torch.Tensor) -> torch.Tensor:\n",
    "        idx = pid_idx.clone()\n",
    "        idx = torch.where(idx >= 0, idx, torch.full_like(idx, self.unk_index))\n",
    "        return self.emb(idx)\n",
    "\n",
    "class FiLM(nn.Module):\n",
    "    def __init__(self, rep_dim: int, hidden=(64,), dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.gamma = mlp(rep_dim, hidden, rep_dim, dropout)\n",
    "        self.beta  = mlp(rep_dim, hidden, rep_dim, dropout)\n",
    "    def forward(self, z_id: torch.Tensor, z_obs: torch.Tensor) -> torch.Tensor:\n",
    "        g = 1.0 + 0.1 * torch.tanh(self.gamma(z_id))\n",
    "        b = 0.1 * self.beta(z_id)\n",
    "        return g * z_obs + b\n",
    "\n",
    "class Adversary(nn.Module):\n",
    "    def __init__(self, in_dim: int, hidden=(64,), n_participants: int = 1,\n",
    "                 dropout: float = 0.0, grl_lambda: float = 1.0):\n",
    "        super().__init__()\n",
    "        self.grl = GradientReversal(grl_lambda)\n",
    "        self.net = mlp(in_dim, hidden, n_participants, dropout)\n",
    "    def set_lambda(self, lambd: float):\n",
    "        self.grl.set_lambda(lambd)\n",
    "    def forward(self, z_fixed: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(self.grl(z_fixed))\n",
    "\n",
    "class ARMEDTabular(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_fixed: int,\n",
    "        d_random: int = 0,\n",
    "        y_dim: int = 1,\n",
    "        n_participants: int = 1,\n",
    "        include_random_data: bool = True,\n",
    "        fixed_enc_hidden=(128, 64),\n",
    "        fixed_rep_dim: int = 32,\n",
    "        fixed_dropout: float = 0.0,\n",
    "        use_fixed_decoder: bool = False,\n",
    "        fixed_dec_hidden: Optional[Iterable[int]] = None,\n",
    "        random_hidden=(128, 64),\n",
    "        random_rep_dim: int = 32,\n",
    "        random_dropout: float = 0.0,\n",
    "        combine_mode: str = \"add\",   # \"add\" or \"film\"\n",
    "        film_hidden=(64,),\n",
    "        film_dropout: float = 0.0,\n",
    "        adv_hidden=(64,),\n",
    "        adv_dropout: float = 0.0,\n",
    "        grl_lambda: float = 1.0,\n",
    "        head_hidden=(64,),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.include_random_data = bool(include_random_data and d_random > 0)\n",
    "\n",
    "        self.fixed = FixedAE(\n",
    "            in_dim=d_fixed,\n",
    "            enc_hidden=fixed_enc_hidden,\n",
    "            rep_dim=fixed_rep_dim,\n",
    "            dropout=fixed_dropout,\n",
    "            use_decoder=use_fixed_decoder,\n",
    "            dec_hidden=fixed_dec_hidden,\n",
    "        )\n",
    "\n",
    "        self.id_emb = ParticipantEmbedding(n_participants, rep_dim=random_rep_dim)\n",
    "\n",
    "        self.random = RandomEnc(\n",
    "            in_dim=d_random,\n",
    "            hidden=random_hidden,\n",
    "            rep_dim=random_rep_dim,\n",
    "            dropout=random_dropout,\n",
    "        ) if self.include_random_data else None\n",
    "\n",
    "        if combine_mode not in {\"add\", \"film\"}:\n",
    "            raise ValueError(\"combine_mode must be 'add' or 'film'\")\n",
    "        self.combine_mode = combine_mode\n",
    "        self.film = FiLM(rep_dim=random_rep_dim, hidden=film_hidden, dropout=film_dropout) if combine_mode == \"film\" else None\n",
    "\n",
    "        self.head = mlp(fixed_rep_dim + random_rep_dim, head_hidden, y_dim, dropout=0.0)\n",
    "        self.adv  = Adversary(fixed_rep_dim, adv_hidden, n_participants, adv_dropout, grl_lambda)\n",
    "\n",
    "        self.norm_f = nn.LayerNorm(fixed_rep_dim)\n",
    "        self.norm_r = nn.LayerNorm(random_rep_dim)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x_fixed: torch.Tensor,\n",
    "        pid_idx: torch.Tensor,\n",
    "        x_random: Optional[torch.Tensor] = None\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, Optional[torch.Tensor], torch.Tensor, torch.Tensor]:\n",
    "\n",
    "        z_f, xhat = self.fixed(x_fixed)\n",
    "        z_f = self.norm_f(z_f)\n",
    "\n",
    "        z_id = self.id_emb(pid_idx)\n",
    "        if self.include_random_data and (x_random is not None):\n",
    "            z_r_obs = self.random(x_random)\n",
    "            z_r = z_r_obs + z_id if self.combine_mode == \"add\" else self.film(z_id, z_r_obs)\n",
    "        else:\n",
    "            z_r = z_id\n",
    "        z_r = self.norm_r(z_r)\n",
    "\n",
    "        y_hat  = self.head(torch.cat([z_f, z_r], dim=1))   # continuous outputs\n",
    "        adv_logits = self.adv(z_f)                         # adversary still classification\n",
    "\n",
    "        return y_hat, adv_logits, xhat, z_f, z_r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e898a0",
   "metadata": {},
   "source": [
    "## Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "788fdf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple, Dict, Any, Iterable, Sequence\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ARMEDLossWeights:\n",
    "    lambda_adv: float = 1.0\n",
    "    lambda_recon: float = 0.0\n",
    "\n",
    "\n",
    "class ARMEDWrapper:\n",
    "    \"\"\"\n",
    "    Regression wrapper around ARMEDTabular:\n",
    "      - device management\n",
    "      - regression loss (MSE) for predictions\n",
    "      - adversary and reconstruction losses unchanged\n",
    "      - validation/prediction helpers returning continuous outputs\n",
    "    \"\"\"\n",
    "    def __init__(self, model: nn.Module, loss_weights: Optional[ARMEDLossWeights] = None, device: Optional[torch.device] = None):\n",
    "        self.model = model\n",
    "        self.loss_w = loss_weights or ARMEDLossWeights()\n",
    "        self.device = (device\n",
    "                       or (torch.device(\"mps\") if torch.backends.mps.is_available() else None)\n",
    "                       or (torch.device(\"cuda\") if torch.cuda.is_available() else None)\n",
    "                       or torch.device(\"cpu\"))\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def forward(self, x_fixed: torch.Tensor, pid_idx: torch.Tensor, x_random: Optional[torch.Tensor] = None):\n",
    "        return self.model(x_fixed, pid_idx, x_random)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Loss components (regression)\n",
    "    # -----------------------------\n",
    "    def _pred_loss(self, y_hat: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "        return F.mse_loss(y_hat, y_true)\n",
    "\n",
    "    def _adv_loss(self, adv_logits: torch.Tensor, pid_idx: torch.Tensor) -> torch.Tensor:\n",
    "        seen_mask = (pid_idx >= 0)\n",
    "        if seen_mask.any():\n",
    "            return F.cross_entropy(adv_logits[seen_mask], pid_idx[seen_mask])\n",
    "        else:\n",
    "            return torch.tensor(0.0, device=adv_logits.device)\n",
    "\n",
    "    def _recon_loss(self, xhat: Optional[torch.Tensor], x: torch.Tensor) -> torch.Tensor:\n",
    "        if (xhat is None) or (self.loss_w.lambda_recon <= 0.0):\n",
    "            return torch.tensor(0.0, device=x.device)\n",
    "        return F.mse_loss(xhat, x)\n",
    "\n",
    "    def compute_losses(\n",
    "        self,\n",
    "        y_true: torch.Tensor,\n",
    "        y_hat: torch.Tensor,\n",
    "        adv_logits: torch.Tensor,\n",
    "        xhat: Optional[torch.Tensor],\n",
    "        x_fixed: torch.Tensor,\n",
    "        pid_idx: torch.Tensor,\n",
    "    ) -> Tuple[torch.Tensor, Dict[str, float]]:\n",
    "        lp = self._pred_loss(y_hat, y_true)\n",
    "        la = self._adv_loss(adv_logits, pid_idx)\n",
    "        lr = self._recon_loss(xhat, x_fixed)\n",
    "\n",
    "        total = lp + self.loss_w.lambda_adv * la + self.loss_w.lambda_recon * lr\n",
    "\n",
    "        parts = {\n",
    "            \"loss_total\": float(total.detach().cpu()),\n",
    "            \"loss_pred\":  float(lp.detach().cpu()),\n",
    "            \"loss_adv\":   float(la.detach().cpu()),\n",
    "            \"loss_recon\": float(lr.detach().cpu()),\n",
    "        }\n",
    "        return total, parts\n",
    "\n",
    "    # -----------------------------\n",
    "    # Eval / predict helpers\n",
    "    # -----------------------------\n",
    "    @torch.no_grad()\n",
    "    def validation_step(\n",
    "        self,\n",
    "        x_fixed: torch.Tensor,\n",
    "        pid_idx: torch.Tensor,\n",
    "        y_true: torch.Tensor,\n",
    "        x_random: Optional[torch.Tensor] = None,\n",
    "        prefix: str = \"val\"\n",
    "    ) -> Tuple[torch.Tensor, Dict[str, float]]:\n",
    "        self.model.eval()\n",
    "        x_fixed = x_fixed.to(self.device)\n",
    "        pid_idx = pid_idx.to(self.device)\n",
    "        y_true  = y_true.to(self.device)\n",
    "        x_random = x_random.to(self.device) if x_random is not None else None\n",
    "\n",
    "        y_hat, adv_logits, xhat, _, _ = self.forward(x_fixed, pid_idx, x_random)\n",
    "        loss, parts = self.compute_losses(y_true, y_hat, adv_logits, xhat, x_fixed, pid_idx)\n",
    "\n",
    "        print(\n",
    "            f\"{prefix}_loss: {parts['loss_total']:.6f} | \"\n",
    "            f\"pred: {parts['loss_pred']:.6f} | \"\n",
    "            f\"adv: {parts['loss_adv']:.6f} | \"\n",
    "            f\"recon: {parts['loss_recon']:.6f}\"\n",
    "        )\n",
    "        return loss, parts\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict_logits(   # now returns continuous predictions (y_hat)\n",
    "        self,\n",
    "        x_fixed: torch.Tensor,\n",
    "        pid_idx: torch.Tensor,\n",
    "        x_random: Optional[torch.Tensor] = None\n",
    "    ) -> torch.Tensor:\n",
    "        self.model.eval()\n",
    "        x_fixed = x_fixed.to(self.device)\n",
    "        pid_idx = pid_idx.to(self.device)\n",
    "        x_random = x_random.to(self.device) if x_random is not None else None\n",
    "        y_hat, _, _, _, _ = self.forward(x_fixed, pid_idx, x_random)\n",
    "        return y_hat\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict_values(\n",
    "        self,\n",
    "        x_fixed: torch.Tensor,\n",
    "        pid_idx: torch.Tensor,\n",
    "        x_random: Optional[torch.Tensor] = None\n",
    "    ) -> torch.Tensor:\n",
    "        return self.predict_logits(x_fixed, pid_idx, x_random)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea48953",
   "metadata": {},
   "source": [
    "## Evaluation procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b982099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, Optional, Tuple, Iterable, List\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, TimeSeriesSplit, ParameterGrid\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import t as student_t\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Dataset / loaders (unchanged)\n",
    "# -------------------------------------------------------------------\n",
    "class _ARMEDDataset(Dataset):\n",
    "    def __init__(self, Xf, pid_idx, y, Xr=None, device=None):\n",
    "        device = device or torch.device(\"cpu\")\n",
    "        Xf  = np.asarray(Xf, dtype=np.float32)\n",
    "        y   = np.asarray(y,  dtype=np.float32)\n",
    "        pid = np.asarray(pid_idx)\n",
    "\n",
    "        if y.ndim == 1:\n",
    "            y = y[:, None]\n",
    "\n",
    "        self.Xf  = torch.as_tensor(Xf, dtype=torch.float32, device=device)\n",
    "        self.pid = torch.as_tensor(pid, dtype=torch.long,    device=device)\n",
    "        self.y   = torch.as_tensor(y,  dtype=torch.float32,  device=device)\n",
    "\n",
    "        if Xr is None:\n",
    "            self.Xr = torch.zeros((len(self.Xf), 0), dtype=torch.float32, device=device)\n",
    "        else:\n",
    "            Xr = np.asarray(Xr, dtype=np.float32)\n",
    "            self.Xr = torch.as_tensor(Xr, dtype=torch.float32, device=device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.Xf.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.Xf[idx], self.pid[idx], self.Xr[idx], self.y[idx]\n",
    "\n",
    "def _make_loader(Xf, pid_idx, y, Xr=None, batch_size=256, shuffle=False, device=None):\n",
    "    ds = _ARMEDDataset(Xf, pid_idx, y, Xr=Xr, device=device)\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=shuffle, num_workers=0, drop_last=False)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Regression metrics — IDENTICAL to the KAN routine\n",
    "# -------------------------------------------------------------------\n",
    "def regression_metrics(y_true: np.ndarray, y_pred: np.ndarray) -> dict:\n",
    "    y_true = np.asarray(y_true); y_pred = np.asarray(y_pred)\n",
    "    if y_true.ndim == 1: y_true = y_true[:, None]\n",
    "    if y_pred.ndim == 1: y_pred = y_pred[:, None]\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    out = {}\n",
    "    for j in range(y_true.shape[1]):\n",
    "        t = y_true[:, j]; p = y_pred[:, j]\n",
    "        mse = float(np.mean((p - t) ** 2))\n",
    "        rmse = float(np.sqrt(mse))\n",
    "        mae = float(np.mean(np.abs(p - t)))\n",
    "        var = float(np.var(t))\n",
    "        r2 = float(1.0 - (mse / var)) if var > 0 else np.nan\n",
    "        if np.std(t) > 0 and np.std(p) > 0:\n",
    "            r = float(np.corrcoef(t, p)[0, 1])\n",
    "        else:\n",
    "            r = np.nan\n",
    "        out[f\"task_{j+1}_MSE\"] = mse\n",
    "        out[f\"task_{j+1}_RMSE\"] = rmse\n",
    "        out[f\"task_{j+1}_MAE\"] = mae\n",
    "        out[f\"task_{j+1}_R2\"] = r2\n",
    "        out[f\"task_{j+1}_PearsonR\"] = r\n",
    "    for k in (\"MSE\",\"RMSE\",\"MAE\",\"R2\",\"PearsonR\"):\n",
    "        vals = [out[f\"task_{j+1}_{k}\"] for j in range(y_true.shape[1])]\n",
    "        out[f\"macro_{k}\"] = float(np.nanmean(vals))\n",
    "    return out\n",
    "\n",
    "def _print_regression_metrics(metrics: dict, title: str = \"Test metrics\"):\n",
    "    print(f\"\\n{title}:\")\n",
    "    macro_keys = [k for k in metrics.keys() if k.startswith(\"macro_\")]\n",
    "    for k in sorted(macro_keys):\n",
    "        print(f\"{k:>16}: {metrics[k]:.6f}\")\n",
    "    task_indices = sorted({int(k.split('_')[1]) for k in metrics.keys() if k.startswith(\"task_\")})\n",
    "    for j in task_indices:\n",
    "        print(f\"task_{j}: \" +\n",
    "              \", \".join(f\"{m}={metrics.get(f'task_{j}_{m}', np.nan):.6f}\"\n",
    "                        for m in (\"MSE\",\"RMSE\",\"MAE\",\"R2\",\"PearsonR\")))\n",
    "\n",
    "def _summarize_cv_folds(results_folds: List[dict]) -> dict:\n",
    "    if not results_folds:\n",
    "        return {}\n",
    "\n",
    "    all_keys = set().union(*results_folds)\n",
    "    summary = {}\n",
    "\n",
    "    for k in sorted(all_keys):\n",
    "        vals = np.array([fold.get(k, np.nan) for fold in results_folds], dtype=float)\n",
    "        mask = np.isfinite(vals)\n",
    "        n = int(mask.sum())\n",
    "\n",
    "        if n == 0:\n",
    "            m = np.nan; low = np.nan; high = np.nan\n",
    "        elif n == 1:\n",
    "            m = float(vals[mask][0]); low = np.nan; high = np.nan\n",
    "        else:\n",
    "            m = float(np.nanmean(vals))\n",
    "            s = float(np.nanstd(vals, ddof=1))\n",
    "            se = s / np.sqrt(n)\n",
    "            tcrit = float(student_t.ppf(0.975, df=n - 1))\n",
    "            low = m - tcrit * se\n",
    "            high = m + tcrit * se\n",
    "\n",
    "        summary[f\"{k}_mean\"] = m\n",
    "        summary[f\"{k}_95ci_low\"] = low\n",
    "        summary[f\"{k}_95ci_high\"] = high\n",
    "\n",
    "    return summary\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# PCA pipelines and helpers (unchanged)\n",
    "# -------------------------------------------------------------------\n",
    "_VAR_EPS = 1e-8\n",
    "_STD_EPS = 1e-6\n",
    "_CLIP_Z  = 8.0\n",
    "\n",
    "@dataclass\n",
    "class PCAPipeline:\n",
    "    keep_mask: np.ndarray\n",
    "    mean_: np.ndarray\n",
    "    scale_: np.ndarray\n",
    "    pca: PCA\n",
    "\n",
    "def _fit_pca_pipeline(X_train: np.ndarray, var_ratio: float = 0.95, random_state: int | None = None) -> PCAPipeline:\n",
    "    X = np.asarray(X_train, dtype=np.float64)\n",
    "    X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    var = X.var(axis=0)\n",
    "    keep = var > _VAR_EPS\n",
    "    if not np.any(keep):\n",
    "        pca = PCA(n_components=0, svd_solver='full', random_state=random_state)\n",
    "        return PCAPipeline(keep_mask=keep, mean_=np.array([], dtype=np.float64),\n",
    "                           scale_=np.array([], dtype=np.float64), pca=pca)\n",
    "\n",
    "    Xk = X[:, keep]\n",
    "\n",
    "    mean = Xk.mean(axis=0)\n",
    "    std  = Xk.std(axis=0)\n",
    "    std  = np.maximum(std, _STD_EPS)\n",
    "\n",
    "    Z = (Xk - mean) / std\n",
    "    Z = np.nan_to_num(Z, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    np.clip(Z, -_CLIP_Z, _CLIP_Z, out=Z)\n",
    "\n",
    "    pca = PCA(n_components=var_ratio, svd_solver='full', random_state=random_state)\n",
    "    pca.fit(Z)\n",
    "    if not np.isfinite(pca.components_).all():\n",
    "        raise RuntimeError(\"PCA components contain non-finite values after fit.\")\n",
    "\n",
    "    return PCAPipeline(keep_mask=keep, mean_=mean, scale_=std, pca=pca)\n",
    "\n",
    "def _transform_pca_pipeline(pipe: PCAPipeline | None, X: np.ndarray | None) -> np.ndarray | None:\n",
    "    if pipe is None or X is None:\n",
    "        return None\n",
    "\n",
    "    X = np.asarray(X, dtype=np.float64)\n",
    "    X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    if pipe.keep_mask.size == 0 or not np.any(pipe.keep_mask):\n",
    "        return np.zeros((X.shape[0], 0), dtype=np.float32)\n",
    "    Xk = X[:, pipe.keep_mask]\n",
    "\n",
    "    Z = (Xk - pipe.mean_) / pipe.scale_\n",
    "    Z = np.nan_to_num(Z, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    np.clip(Z, -_CLIP_Z, _CLIP_Z, out=Z)\n",
    "\n",
    "    if not np.isfinite(Z).all():\n",
    "        bad = np.argwhere(~np.isfinite(Z))[0]\n",
    "        raise RuntimeError(f\"[our PCA] Z non-finite at {tuple(bad)}: {Z[tuple(bad)]}\")\n",
    "    if np.abs(Z).max() > 1e6:\n",
    "        raise RuntimeError(f\"[our PCA] Z max |z| too large: {np.abs(Z).max()}\")\n",
    "    if not np.isfinite(pipe.pca.components_).all():\n",
    "        raise RuntimeError(\"[our PCA] components_ non-finite\")\n",
    "    if hasattr(pipe.pca, \"mean_\") and not np.isfinite(pipe.pca.mean_).all():\n",
    "        raise RuntimeError(\"[our PCA] mean_ non-finite\")\n",
    "\n",
    "    Z64 = np.ascontiguousarray(Z, dtype=np.float64)\n",
    "    CT  = np.ascontiguousarray(pipe.pca.components_.T, dtype=np.float64)\n",
    "\n",
    "    with np.errstate(over='ignore', invalid='ignore', divide='ignore'):\n",
    "        Xt = Z64 @ CT\n",
    "\n",
    "    Xt = np.nan_to_num(Xt, nan=0.0, posinf=0.0, neginf=0.0).astype(np.float32)\n",
    "    return Xt\n",
    "\n",
    "def _concat_safe(*arrays: Optional[np.ndarray]) -> np.ndarray:\n",
    "    parts = [a for a in arrays if a is not None and a.size > 0]\n",
    "    if not parts:\n",
    "        return np.zeros((0, 0), dtype=np.float32)\n",
    "    return np.concatenate(parts, axis=1).astype(np.float32)\n",
    "\n",
    "def _filter_time_test_min_measurements(pid_idx: np.ndarray, test_idx: np.ndarray, min_meas: int = 3):\n",
    "    \"\"\"Keep only rows in test_idx belonging to pids with >= min_meas measurements overall.\"\"\"\n",
    "    pid = np.asarray(pid_idx)\n",
    "    counts = {pid_val: np.sum(pid == pid_val) for pid_val in np.unique(pid)}\n",
    "    keep = [i for i in test_idx if counts.get(pid[i], 0) >= min_meas]\n",
    "    return np.array(keep, dtype=int)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Splitting helpers (unchanged)\n",
    "# -------------------------------------------------------------------\n",
    "def _split_cases(pid_array, test_fraction=0.2, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    unique_ids = np.unique(pid_array)\n",
    "    te_ids = rng.choice(unique_ids, size=max(1, int(len(unique_ids) * test_fraction)), replace=False)\n",
    "    te_mask = np.isin(pid_array, te_ids)\n",
    "    return np.where(~te_mask)[0], np.where(te_mask)[0]\n",
    "\n",
    "def _split_time_basic(time_index, test_fraction=0.2):\n",
    "    order = np.argsort(time_index)\n",
    "    n = len(order)\n",
    "    split = int(np.floor(n * (1.0 - test_fraction)))\n",
    "    return order[:split], order[split:]\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Early-stop helper on loaders (regression)\n",
    "# -------------------------------------------------------------------\n",
    "def _eval_macro_metric_on_loader(wrapper, loader: DataLoader, which: str = \"macro_R2\") -> float:\n",
    "    if loader is None:\n",
    "        return np.nan\n",
    "    wrapper.model.eval()\n",
    "    preds_all, y_all = [], []\n",
    "    with torch.no_grad():\n",
    "        for Xf_b, pid_b, Xr_b, y_b in loader:\n",
    "            y_hat = wrapper.predict_logits(Xf_b, pid_b, Xr_b if Xr_b.size(1) > 0 else None)\n",
    "            preds_all.append(y_hat.cpu().numpy())\n",
    "            y_all.append(y_b.cpu().numpy())\n",
    "    y_pred = np.vstack(preds_all); y_true = np.vstack(y_all)\n",
    "    m = regression_metrics(y_true, y_pred)\n",
    "    return float(m.get(which, np.nan))\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Train loop (prints train & monitor; early stop by loss or macro metric)\n",
    "# -------------------------------------------------------------------\n",
    "def _fit_once(\n",
    "    wrapper, optimizer,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: Optional[DataLoader],          # used for early stopping (default)\n",
    "    monitor_loader: Optional[DataLoader],      # printed each epoch; often the test set\n",
    "    max_epochs: int = 100,\n",
    "    patience: int = 10,\n",
    "    early_stop_metric: str = \"loss\",           # \"loss\" | \"macro_R2\" | \"macro_MAE\"\n",
    "    early_stop_on: str = \"val\",                # \"val\" | \"train\" | \"monitor\"\n",
    "    verbose: bool = True,\n",
    "):\n",
    "    if early_stop_on == \"val\" and val_loader is None:\n",
    "        early_stop_on = \"train\"\n",
    "\n",
    "    higher_is_better = (early_stop_metric == \"macro_R2\")\n",
    "    best_val = -np.inf if higher_is_better else np.inf\n",
    "    best_state, no_improve = None, 0\n",
    "\n",
    "    def _avg_loss(loader) -> Optional[float]:\n",
    "        if loader is None:\n",
    "            return None\n",
    "        wrapper.model.eval()\n",
    "        total, n = 0.0, 0\n",
    "        with torch.no_grad():\n",
    "            for Xf_b, pid_b, Xr_b, y_b in loader:\n",
    "                y_hat, adv_logits, xhat, _, _ = wrapper.forward(Xf_b, pid_b, Xr_b if Xr_b.size(1) > 0 else None)\n",
    "                l, _ = wrapper.compute_losses(y_b, y_hat, adv_logits, xhat, Xf_b, pid_b)\n",
    "                bs = Xf_b.size(0)\n",
    "                total += float(l.detach().cpu()) * bs\n",
    "                n += bs\n",
    "        return total / max(1, n)\n",
    "\n",
    "    def _current_metric():\n",
    "        if early_stop_metric == \"loss\":\n",
    "            if early_stop_on == \"val\":\n",
    "                return _avg_loss(val_loader)\n",
    "            elif early_stop_on == \"train\":\n",
    "                return _avg_loss(train_loader)\n",
    "            else:\n",
    "                return _avg_loss(monitor_loader)\n",
    "        else:\n",
    "            which = early_stop_metric\n",
    "            if early_stop_on == \"val\":\n",
    "                return _eval_macro_metric_on_loader(wrapper, val_loader, which=which)\n",
    "            elif early_stop_on == \"train\":\n",
    "                return _eval_macro_metric_on_loader(wrapper, train_loader, which=which)\n",
    "            else:\n",
    "                return _eval_macro_metric_on_loader(wrapper, monitor_loader, which=which)\n",
    "\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        wrapper.model.train()\n",
    "        total_tr, n_tr = 0.0, 0\n",
    "        for Xf_b, pid_b, Xr_b, y_b in train_loader:\n",
    "            y_hat, adv_logits, xhat, _, _ = wrapper.forward(\n",
    "                Xf_b, pid_b, Xr_b if Xr_b.size(1) > 0 else None\n",
    "            )\n",
    "            loss, _ = wrapper.compute_losses(y_b, y_hat, adv_logits, xhat, Xf_b, pid_b)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            bs = Xf_b.size(0)\n",
    "            total_tr += float(loss.detach().cpu()) * bs\n",
    "            n_tr += bs\n",
    "        train_loss = total_tr / max(1, n_tr)\n",
    "\n",
    "        monitor_loss = _avg_loss(monitor_loader)\n",
    "        if verbose:\n",
    "            if monitor_loss is not None:\n",
    "                print(f\"Epoch {epoch:03d} | train {train_loss:.6f} | monitor_loss {monitor_loss:.6f}\")\n",
    "            else:\n",
    "                print(f\"Epoch {epoch:03d} | train {train_loss:.6f}\")\n",
    "\n",
    "        current = _current_metric()\n",
    "        if higher_is_better:\n",
    "            is_better = (current is not None) and (current > best_val + 1e-6)\n",
    "        else:\n",
    "            is_better = (current is not None) and (current < best_val - 1e-6)\n",
    "\n",
    "        if is_better:\n",
    "            best_val = current\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in wrapper.model.state_dict().items()}\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience:\n",
    "                if verbose:\n",
    "                    tag = f\"{early_stop_metric}@{early_stop_on}\"\n",
    "                    print(f\"Early stopping at epoch {epoch:03d} (best {tag} {best_val:.6f})\")\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        wrapper.model.load_state_dict(best_state)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# PCA + loaders + per-split PID remap\n",
    "# -------------------------------------------------------------------\n",
    "def _prepare_split_and_loaders(\n",
    "    X_only_fixed: np.ndarray,\n",
    "    X_fixed_and_random: Optional[np.ndarray],\n",
    "    y: np.ndarray,\n",
    "    pid_idx_full: np.ndarray,\n",
    "    indices_train: np.ndarray,\n",
    "    indices_val: Optional[np.ndarray],\n",
    "    indices_test: np.ndarray,\n",
    "    batch_size: int,\n",
    "    device: torch.device,\n",
    "    random_state: int = 42,\n",
    "    pca_var_ratio: float = 0.95,\n",
    "):\n",
    "    of_pipe = _fit_pca_pipeline(X_only_fixed[indices_train], var_ratio=pca_var_ratio, random_state=random_state)\n",
    "    fr_pipe = None\n",
    "    if X_fixed_and_random is not None and X_fixed_and_random.shape[1] > 0:\n",
    "        fr_pipe = _fit_pca_pipeline(X_fixed_and_random[indices_train], var_ratio=pca_var_ratio, random_state=random_state)\n",
    "\n",
    "    def transform_block(idxs):\n",
    "        of = _transform_pca_pipeline(of_pipe, X_only_fixed[idxs])\n",
    "        fr = _transform_pca_pipeline(fr_pipe, None if X_fixed_and_random is None else X_fixed_and_random[idxs])\n",
    "        Xf = _concat_safe(of, fr)\n",
    "        Xr = fr\n",
    "        return Xf, Xr\n",
    "\n",
    "    Xf_tr, Xr_tr = transform_block(indices_train)\n",
    "    Xf_te, Xr_te = transform_block(indices_test)\n",
    "    if indices_val is not None:\n",
    "        Xf_va, Xr_va = transform_block(indices_val)\n",
    "    else:\n",
    "        Xf_va, Xr_va = None, None\n",
    "\n",
    "    seen = np.unique(pid_idx_full[indices_train])\n",
    "    pid_to_seen = {p: i for i, p in enumerate(seen)}\n",
    "\n",
    "    def map_pids(idxs):\n",
    "        vals = pid_idx_full[idxs]\n",
    "        mapped = np.array([pid_to_seen.get(p, -1) for p in vals], dtype=np.int64)\n",
    "        return mapped\n",
    "\n",
    "    pid_tr = map_pids(indices_train)\n",
    "    pid_te = map_pids(indices_test)\n",
    "    pid_va = map_pids(indices_val) if indices_val is not None else None\n",
    "\n",
    "    tr_loader = _make_loader(Xf_tr, pid_tr, y[indices_train], Xr=Xr_tr, batch_size=batch_size, shuffle=True,  device=device)\n",
    "    va_loader = _make_loader(Xf_va, pid_va, y[indices_val], Xr=Xr_va, batch_size=batch_size, shuffle=False, device=device) if Xf_va is not None else None\n",
    "    te_loader = _make_loader(Xf_te, pid_te, y[indices_test],  Xr=Xr_te, batch_size=batch_size, shuffle=False, device=device)\n",
    "\n",
    "    d_fixed  = Xf_tr.shape[1]\n",
    "    d_random = 0 if Xr_tr is None else Xr_tr.shape[1]\n",
    "\n",
    "    preprocessors = {\n",
    "        \"only_fixed\": of_pipe,\n",
    "        \"fixed_and_random\": fr_pipe,\n",
    "        \"d_fixed\": d_fixed,\n",
    "        \"d_random\": d_random,\n",
    "        \"n_seen\": int(len(seen)),\n",
    "    }\n",
    "    loaders = {\"train\": tr_loader, \"val\": va_loader, \"test\": te_loader}\n",
    "    return preprocessors, loaders\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# One split fit/eval (regression)\n",
    "# -------------------------------------------------------------------\n",
    "def _fit_eval_once(\n",
    "    build_model_fn, wrapper_cls,\n",
    "    arch_params: Dict[str, Any],\n",
    "    train_params: Dict[str, Any],\n",
    "    X_of: np.ndarray,\n",
    "    X_fr: Optional[np.ndarray],\n",
    "    y: np.ndarray,\n",
    "    pid_idx_full: np.ndarray,\n",
    "    tr_idx: np.ndarray,\n",
    "    va_idx: Optional[np.ndarray],\n",
    "    te_idx: np.ndarray,\n",
    "    device: torch.device,\n",
    "    monitor_source: str = \"test\",\n",
    "    verbose: bool = True,\n",
    "):\n",
    "    preprocessors, loaders = _prepare_split_and_loaders(\n",
    "        X_of, X_fr, y, pid_idx_full,\n",
    "        tr_idx, va_idx, te_idx,\n",
    "        batch_size=train_params.get(\"batch_size\", 256),\n",
    "        device=device,\n",
    "        random_state=train_params.get(\"random_state\", 42),\n",
    "        pca_var_ratio=train_params.get(\"pca_var_ratio\", 0.95),\n",
    "    )\n",
    "\n",
    "    d_fixed  = preprocessors[\"d_fixed\"]\n",
    "    d_random = preprocessors[\"d_random\"]\n",
    "    n_seen   = preprocessors[\"n_seen\"]\n",
    "\n",
    "    y_dim = y.shape[1] if y.ndim == 2 else 1\n",
    "    model = build_model_fn(\n",
    "        d_fixed=d_fixed,\n",
    "        d_random=d_random,\n",
    "        y_dim=y_dim,\n",
    "        n_participants=n_seen,\n",
    "        **arch_params\n",
    "    ).to(device)\n",
    "\n",
    "    wrapper = wrapper_cls(model, loss_weights=train_params.get(\"loss_weights\", None), device=device)\n",
    "    opt = torch.optim.Adam(wrapper.model.parameters(),\n",
    "                           lr=train_params.get(\"lr\", 1e-3),\n",
    "                           weight_decay=train_params.get(\"weight_decay\", 0.0))\n",
    "\n",
    "    monitor_loader = loaders[\"test\"] if monitor_source == \"test\" else loaders[\"val\"]\n",
    "\n",
    "    _fit_once(\n",
    "        wrapper, opt,\n",
    "        loaders[\"train\"], loaders[\"val\"], monitor_loader,\n",
    "        max_epochs=train_params.get(\"max_epochs\", 100),\n",
    "        patience=train_params.get(\"patience\", 10),\n",
    "        early_stop_metric=train_params.get(\"early_stop_metric\", \"loss\"),\n",
    "        early_stop_on=train_params.get(\"early_stop_on\", \"val\"),\n",
    "        verbose=verbose\n",
    "    )\n",
    "\n",
    "    wrapper.model.eval()\n",
    "    preds_all, y_all = [], []\n",
    "    with torch.no_grad():\n",
    "        for Xf_b, pid_b, Xr_b, y_b in loaders[\"test\"]:\n",
    "            y_hat = wrapper.predict_logits(Xf_b, pid_b, Xr_b if Xr_b.size(1) > 0 else None)\n",
    "            preds_all.append(y_hat.cpu().numpy())\n",
    "            y_all.append(y_b.cpu().numpy())\n",
    "    y_pred_te = np.vstack(preds_all); y_true_te = np.vstack(y_all)\n",
    "\n",
    "    metrics = regression_metrics(y_true_te, y_pred_te)\n",
    "\n",
    "    return {\n",
    "        \"metrics\": metrics,\n",
    "        \"preprocessors\": preprocessors,\n",
    "        \"wrapper\": wrapper,\n",
    "        \"model\": wrapper.model,\n",
    "        \"y_true_test\": y_true_te,\n",
    "        \"y_pred_test\": y_pred_te,\n",
    "    }\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Main entry: single / cv_only / nested_cv, scenarios cases/time/both\n",
    "# -------------------------------------------------------------------\n",
    "def run_training_and_eval_armed(\n",
    "    X_only_fixed: np.ndarray,\n",
    "    X_fixed_and_random: Optional[np.ndarray],\n",
    "    y: np.ndarray,\n",
    "    pid_idx: np.ndarray,\n",
    "    time_index: np.ndarray,\n",
    "    build_model_fn,\n",
    "    wrapper_cls,\n",
    "    *,\n",
    "    mode: str = \"single\",\n",
    "    scenario: str = \"cases\",\n",
    "    outer_folds: int = 5,\n",
    "    inner_folds: int = 3,\n",
    "    param_grid: Optional[Dict[str, List]] = None,\n",
    "    arch_defaults: Optional[Dict[str, Any]] = None,\n",
    "    train_defaults: Optional[Dict[str, Any]] = None,\n",
    "    device: Optional[torch.device] = None,\n",
    "    verbose: bool = True,\n",
    ") -> Dict[str, Any]:\n",
    "    device = device or (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "    X_of = np.asarray(X_only_fixed, dtype=np.float32)\n",
    "    X_fr = None if X_fixed_and_random is None else np.asarray(X_fixed_and_random, dtype=np.float32)\n",
    "    y    = np.asarray(y, dtype=np.float32)\n",
    "    pid_idx = np.asarray(pid_idx, dtype=np.int64)\n",
    "    time_ix = np.asarray(time_index)\n",
    "\n",
    "    arch_defaults = arch_defaults or {}\n",
    "    train_defaults = train_defaults or {}\n",
    "\n",
    "    rnd = int(train_defaults.get(\"random_state\", 42))\n",
    "    val_frac = float(train_defaults.get(\"val_fraction\", 0.10))\n",
    "    monitor_source = train_defaults.get(\"monitor_source\", \"test\")\n",
    "\n",
    "    def _make_train_val_split(idx_array: np.ndarray, seed: int) -> Tuple[np.ndarray, Optional[np.ndarray]]:\n",
    "        idx_array = np.asarray(idx_array)\n",
    "        if len(idx_array) <= 10 or val_frac <= 0.0:\n",
    "            return idx_array, None\n",
    "        rng = np.random.default_rng(seed)\n",
    "        perm = rng.permutation(len(idx_array))\n",
    "        cut = max(1, int(val_frac * len(idx_array)))\n",
    "        va_sel, tr_sel = perm[:cut], perm[cut:]\n",
    "        return idx_array[tr_sel], idx_array[va_sel]\n",
    "\n",
    "    if scenario == \"both\":\n",
    "        out_cases = run_training_and_eval_armed(\n",
    "            X_of, X_fr, y, pid_idx, time_ix,\n",
    "            build_model_fn, wrapper_cls,\n",
    "            mode=mode, scenario=\"cases\",\n",
    "            outer_folds=outer_folds, inner_folds=inner_folds,\n",
    "            param_grid=param_grid, arch_defaults=arch_defaults, train_defaults=train_defaults,\n",
    "            device=device, verbose=verbose\n",
    "        )\n",
    "        out_time = run_training_and_eval_armed(\n",
    "            X_of, X_fr, y, pid_idx, time_ix,\n",
    "            build_model_fn, wrapper_cls,\n",
    "            mode=mode, scenario=\"time\",\n",
    "            outer_folds=outer_folds, inner_folds=inner_folds,\n",
    "            param_grid=param_grid, arch_defaults=arch_defaults, train_defaults=train_defaults,\n",
    "            device=device, verbose=verbose\n",
    "        )\n",
    "        return {\"cases\": out_cases, \"time\": out_time}\n",
    "\n",
    "    # -------------------- MODE: SINGLE --------------------\n",
    "    if mode == \"single\":\n",
    "        if scenario == \"cases\":\n",
    "            tr_idx_all, te_idx = _split_cases(pid_idx, test_fraction=0.2, seed=rnd)\n",
    "            te_idx_use = te_idx\n",
    "        elif scenario == \"time\":\n",
    "            tr_idx_all, te_idx_raw = _split_time_basic(time_ix, test_fraction=0.2)\n",
    "            te_idx = _filter_time_test_min_measurements(pid_idx, te_idx_raw, min_meas=3)\n",
    "            if len(te_idx) == 0:\n",
    "                raise RuntimeError(\"Time split produced empty test after >=3 measurements filter.\")\n",
    "            te_idx_use = te_idx\n",
    "        else:\n",
    "            raise ValueError(\"scenario must be 'cases' or 'time'\")\n",
    "\n",
    "        tr_idx, va_idx = _make_train_val_split(np.asarray(tr_idx_all), seed=rnd)\n",
    "\n",
    "        res = _fit_eval_once(\n",
    "            build_model_fn, wrapper_cls,\n",
    "            arch_defaults, train_defaults,\n",
    "            X_of, X_fr, y,\n",
    "            pid_idx,\n",
    "            tr_idx, va_idx, te_idx_use,\n",
    "            device=device,\n",
    "            monitor_source=monitor_source,\n",
    "            verbose=verbose\n",
    "        )\n",
    "\n",
    "        if verbose:\n",
    "            _print_regression_metrics(res[\"metrics\"], title=\"Single-fit test metrics\")\n",
    "        return res\n",
    "\n",
    "    # -------------------- MODE: CV-ONLY --------------------\n",
    "    if mode == \"cv_only\":\n",
    "        fold_metrics: List[Dict[str, float]] = []\n",
    "\n",
    "        if scenario == \"cases\":\n",
    "            outer = GroupKFold(n_splits=outer_folds)\n",
    "            outer_iter = outer.split(X_of, y[:, 0] if y.ndim > 1 else y, groups=pid_idx)\n",
    "        elif scenario == \"time\":\n",
    "            tss = TimeSeriesSplit(n_splits=outer_folds)\n",
    "            order = np.argsort(time_ix)\n",
    "            X_order = X_of[order]; y_order = y[order]\n",
    "            outer_iter = ((order[tr], order[te]) for tr, te in tss.split(X_order, y_order[:, 0] if y.ndim > 1 else y_order))\n",
    "        else:\n",
    "            raise ValueError(\"scenario must be 'cases' or 'time'\")\n",
    "\n",
    "        for fold_id, (tr_idx_all, te_idx_raw) in enumerate(outer_iter, start=1):\n",
    "            if scenario == \"time\":\n",
    "                te_idx = _filter_time_test_min_measurements(pid_idx, te_idx_raw, min_meas=3)\n",
    "                if len(te_idx) == 0:\n",
    "                    if verbose: print(f\"Fold {fold_id}: skipped (empty train/test).\")\n",
    "                    continue\n",
    "                te_idx_use = te_idx\n",
    "            else:\n",
    "                te_idx_use = te_idx_raw\n",
    "\n",
    "            tr_idx, va_idx = _make_train_val_split(np.asarray(tr_idx_all), seed=rnd + fold_id)\n",
    "\n",
    "            res = _fit_eval_once(\n",
    "                build_model_fn, wrapper_cls,\n",
    "                arch_defaults, train_defaults,\n",
    "                X_of, X_fr, y,\n",
    "                pid_idx,\n",
    "                tr_idx, va_idx, te_idx_use,\n",
    "                device=device,\n",
    "                monitor_source=monitor_source,\n",
    "                verbose=False\n",
    "            )\n",
    "            fold_metrics.append(res[\"metrics\"])\n",
    "            if verbose:\n",
    "                print(f\"\\nFold {fold_id}:\")\n",
    "                _print_regression_metrics(res[\"metrics\"], title=\"Per-fold test metrics\")\n",
    "\n",
    "        cv_summary = _summarize_cv_folds(fold_metrics)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"\\nCV averages (±95% CI):\")\n",
    "            for key in sorted(cv_summary.keys()):\n",
    "                if key.endswith(\"_mean\"):\n",
    "                    base = key[:-5]\n",
    "                    low = cv_summary.get(f\"{base}_95ci_low\", np.nan)\n",
    "                    high = cv_summary.get(f\"{base}_95ci_high\", np.nan)\n",
    "                    print(f\"{base:>20}: {cv_summary[key]:.6f}  (95% CI {low:.6f}, {high:.6f})\")\n",
    "\n",
    "        return {\n",
    "            \"cv_folds_metrics\": fold_metrics,\n",
    "            \"cv_summary\": cv_summary,\n",
    "        }\n",
    "\n",
    "    # -------------------- MODE: NESTED CV --------------------\n",
    "    if mode == \"nested_cv\":\n",
    "        if not param_grid:\n",
    "            param_grid = {\n",
    "                \"fixed_rep_dim\": [32, 64, 128],\n",
    "                \"random_rep_dim\": [32],\n",
    "                \"combine_mode\": [\"add\"],\n",
    "                \"grl_lambda\": [1.0],\n",
    "                \"lr\": [1e-3, 3e-4],\n",
    "                \"weight_decay\": [0.0, 1e-4],\n",
    "                \"batch_size\": [256],\n",
    "                \"max_epochs\": [100],\n",
    "                \"patience\": [10],\n",
    "            }\n",
    "\n",
    "        results_folds = []\n",
    "        best_score_global, best_params_global = -np.inf, None\n",
    "\n",
    "        if scenario == \"cases\":\n",
    "            outer = GroupKFold(n_splits=outer_folds)\n",
    "            outer_iter = outer.split(X_of, y[:, 0] if y.ndim > 1 else y, groups=pid_idx)\n",
    "        elif scenario == \"time\":\n",
    "            tss = TimeSeriesSplit(n_splits=outer_folds)\n",
    "            order = np.argsort(time_ix)\n",
    "            X_order = X_of[order]; y_order = y[order]\n",
    "            outer_iter = ((order[tr], order[te]) for tr, te in tss.split(X_order, y_order[:, 0] if y.ndim > 1 else y_order))\n",
    "        else:\n",
    "            raise ValueError(\"scenario must be 'cases' or 'time'\")\n",
    "\n",
    "        for fold_id, (tr_idx_all, te_idx_raw) in enumerate(outer_iter, start=1):\n",
    "            if verbose:\n",
    "                print(f\"\\nOuter fold {fold_id}/{outer_folds}\")\n",
    "\n",
    "            if scenario == \"time\":\n",
    "                te_idx = _filter_time_test_min_measurements(pid_idx, te_idx_raw, min_meas=3)\n",
    "                if len(te_idx) == 0:\n",
    "                    if verbose: print(f\"Skipping outer time fold {fold_id} (empty test after filter).\")\n",
    "                    continue\n",
    "                te_idx_use = te_idx\n",
    "            else:\n",
    "                te_idx_use = te_idx_raw\n",
    "\n",
    "            def inner_iter():\n",
    "                if scenario == \"cases\":\n",
    "                    inner = GroupKFold(n_splits=inner_folds)\n",
    "                    return inner.split(X_of[tr_idx_all], (y[tr_idx_all, 0] if y.ndim > 1 else y[tr_idx_all]), groups=pid_idx[tr_idx_all])\n",
    "                else:\n",
    "                    tr_order = np.argsort(time_ix[tr_idx_all])\n",
    "                    X_tr_order = X_of[tr_idx_all][tr_order]\n",
    "                    y_tr_order = y[tr_idx_all][tr_order]\n",
    "                    inner_tss = TimeSeriesSplit(n_splits=inner_folds)\n",
    "                    return ((tr_idx_all[tr_order][itr], tr_idx_all[tr_order][iva])\n",
    "                            for itr, iva in inner_tss.split(X_tr_order, y_tr_order[:, 0] if y.ndim > 1 else y_tr_order))\n",
    "\n",
    "            best_inner_score, best_inner_params = -np.inf, None\n",
    "\n",
    "            for params in ParameterGrid(param_grid):\n",
    "                arch_params = dict(arch_defaults)\n",
    "                train_params = dict(train_defaults)\n",
    "                for k, v in params.items():\n",
    "                    if k in (\"fixed_rep_dim\", \"random_rep_dim\", \"combine_mode\", \"grl_lambda\"):\n",
    "                        arch_params[k] = v\n",
    "                    else:\n",
    "                        train_params[k] = v\n",
    "\n",
    "                inner_scores = []\n",
    "                for in_tr, in_va in inner_iter():\n",
    "                    if scenario == \"time\":\n",
    "                        in_va_f = _filter_time_test_min_measurements(pid_idx, in_va, min_meas=3)\n",
    "                        if len(in_va_f) == 0:\n",
    "                            continue\n",
    "                        in_va = in_va_f\n",
    "\n",
    "                    rng_seed = rnd + fold_id\n",
    "                    tr_idx_inner, va_idx_inner = _make_train_val_split(np.asarray(in_tr), seed=rng_seed)\n",
    "\n",
    "                    res_inner = _fit_eval_once(\n",
    "                        build_model_fn, wrapper_cls,\n",
    "                        arch_params, train_params,\n",
    "                        X_of, X_fr, y,\n",
    "                        pid_idx,\n",
    "                        tr_idx_inner, va_idx_inner, in_va,\n",
    "                        device=device,\n",
    "                        monitor_source=\"val\",\n",
    "                        verbose=False\n",
    "                    )\n",
    "                    score = res_inner[\"metrics\"].get(\"macro_R2\", np.nan)\n",
    "                    inner_scores.append(score)\n",
    "\n",
    "                avg_score = float(np.nanmean(inner_scores)) if len(inner_scores) else -np.inf\n",
    "                if avg_score > best_inner_score:\n",
    "                    best_inner_score = avg_score\n",
    "                    best_inner_params = (arch_params, train_params)\n",
    "\n",
    "            if best_inner_params is None:\n",
    "                if verbose: print(\"No viable inner config; skipping outer fold.\")\n",
    "                continue\n",
    "\n",
    "            arch_params, train_params = best_inner_params\n",
    "            tr_idx_outer, va_idx_outer = _make_train_val_split(np.asarray(tr_idx_all), seed=rnd + fold_id * 17)\n",
    "\n",
    "            res_outer = _fit_eval_once(\n",
    "                build_model_fn, wrapper_cls,\n",
    "                arch_params, train_params,\n",
    "                X_of, X_fr, y,\n",
    "                pid_idx,\n",
    "                tr_idx_outer, va_idx_outer, te_idx_use,\n",
    "                device=device,\n",
    "                monitor_source=monitor_source,\n",
    "                verbose=False\n",
    "            )\n",
    "            results_folds.append(res_outer)\n",
    "\n",
    "            score_outer = res_outer[\"metrics\"].get(\"macro_R2\", -np.inf)\n",
    "            if score_outer > best_score_global:\n",
    "                best_score_global = score_outer\n",
    "                best_params_global = (arch_params, train_params)\n",
    "\n",
    "            if verbose:\n",
    "                _print_regression_metrics(res_outer[\"metrics\"], title=\"Outer fold test metrics\")\n",
    "\n",
    "        def summarize(results_list: List[Dict[str, Any]]) -> Dict[str, float]:\n",
    "            keys = list(results_list[0][\"metrics\"].keys())\n",
    "            out = {}\n",
    "            for k in keys:\n",
    "                arr = np.array([res[\"metrics\"][k] for res in results_list], dtype=float)\n",
    "                m = float(np.nanmean(arr)); s = float(np.nanstd(arr, ddof=1)); n = len(arr)\n",
    "                se = s / np.sqrt(n) if n > 1 else np.nan\n",
    "                if n > 1:\n",
    "                    tcrit = float(student_t.ppf(0.975, df=n-1))\n",
    "                    ci = (m - tcrit * se, m + tcrit * se)\n",
    "                else:\n",
    "                    ci = (np.nan, np.nan)\n",
    "                out[k + \"_mean\"] = m\n",
    "                out[k + \"_95ci_low\"] = ci[0]\n",
    "                out[k + \"_95ci_high\"] = ci[1]\n",
    "            return out\n",
    "\n",
    "        cv_summary = summarize(results_folds)\n",
    "\n",
    "        if verbose and best_params_global is not None:\n",
    "            print(\"\\nBest params (by outer macro_R2):\")\n",
    "            arch_p, train_p = best_params_global\n",
    "            print(\"[ARCH]:\");   [print(f\"  {k}: {v}\") for k, v in arch_p.items()]\n",
    "            print(\"[TRAIN]:\");  [print(f\"  {k}: {v}\") for k, v in train_p.items()]\n",
    "\n",
    "        print(\"\\nCross-validation results:\")\n",
    "        print(\"CV Summary:\")\n",
    "        print(cv_summary)\n",
    "\n",
    "        # Optional final refit (kept silent to match print moments)\n",
    "        if scenario == \"cases\":\n",
    "            tr_idx_all, te_idx = _split_cases(pid_idx, test_fraction=0.2, seed=rnd)\n",
    "            te_idx_use = te_idx\n",
    "        else:\n",
    "            tr_idx_all, te_idx_raw = _split_time_basic(time_ix, test_fraction=0.2)\n",
    "            te_idx = _filter_time_test_min_measurements(pid_idx, te_idx_raw, min_meas=3)\n",
    "            if len(te_idx) == 0:\n",
    "                raise RuntimeError(\"Final refit: time split produced empty test after filter.\")\n",
    "            te_idx_use = te_idx\n",
    "\n",
    "        tr_idx_final, va_idx_final = _make_train_val_split(np.asarray(tr_idx_all), seed=rnd + 999)\n",
    "\n",
    "        final_res = _fit_eval_once(\n",
    "            build_model_fn, wrapper_cls,\n",
    "            best_params_global[0], best_params_global[1],\n",
    "            X_of, X_fr, y,\n",
    "            pid_idx,\n",
    "            tr_idx_final, va_idx_final, te_idx_use,\n",
    "            device=device,\n",
    "            monitor_source=monitor_source,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"outer_folds\": results_folds,\n",
    "            \"cv_summary\": cv_summary,\n",
    "            \"best_params\": {\"arch\": best_params_global[0], \"train\": best_params_global[1]},\n",
    "            \"final_refit\": final_res,\n",
    "        }\n",
    "\n",
    "    raise ValueError(\"mode must be one of {'single','cv_only','nested_cv'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e421e889",
   "metadata": {},
   "source": [
    "## Model test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8fdc27",
   "metadata": {},
   "source": [
    "### Define variables and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ade285cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_raw      = EXP_reg_y.to_numpy(np.float32)\n",
    "y_np       = y_raw if y_raw.ndim == 2 else y_raw.reshape(-1, 1)\n",
    "\n",
    "pid_raw    = EXP_reg_participant_id.to_numpy().ravel()\n",
    "pid_uniqs, pid_encoded = np.unique(pid_raw, return_inverse=True)\n",
    "pid_np     = pid_encoded.astype(np.int64)\n",
    "n_ids      = int(len(pid_uniqs))\n",
    "\n",
    "time_ix_np = EXP_reg_time.to_numpy().ravel()\n",
    "\n",
    "\n",
    "def build_model_fn(d_fixed, d_random, y_dim, n_participants, **arch):\n",
    "    return ARMEDTabular(\n",
    "        d_fixed=d_fixed,\n",
    "        d_random=d_random,\n",
    "        y_dim=y_dim,\n",
    "        n_participants=n_participants,\n",
    "        **arch\n",
    "    )\n",
    "\n",
    "wrapper_cls = ARMEDWrapper\n",
    "\n",
    "\n",
    "arch_defaults = dict(\n",
    "    fixed_rep_dim=256,\n",
    "    random_rep_dim=256,\n",
    "    combine_mode=\"add\",\n",
    "    grl_lambda=1.0,\n",
    ")\n",
    "\n",
    "train_defaults = dict(\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-4,\n",
    "    batch_size=256,\n",
    "    max_epochs=100,\n",
    "    patience=20,\n",
    "    loss_weights=ARMEDLossWeights(lambda_adv=1.0, lambda_recon=0.0),\n",
    "\n",
    "    # PCA on each block (fit on TRAIN within split)\n",
    "    pca_var_ratio=0.95,\n",
    "\n",
    "    # Console monitoring each epoch (uses this loader for the printed “monitor_loss”)\n",
    "    monitor_source=\"test\",          # or \"val\"\n",
    "\n",
    "    # Early stopping target (pick ONE)\n",
    "    early_stop_metric=\"macro_R2\",   # \"loss\" (prediction MSE) | \"macro_R2\" (↑ better) | \"macro_MAE\" (↓ better)\n",
    "    early_stop_on=\"val\",            # \"val\" | \"train\" | \"monitor\"\n",
    "\n",
    "    # Split controls\n",
    "    random_state=42,\n",
    "    val_fraction=0.10,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312c501e",
   "metadata": {},
   "source": [
    "### Simple split test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58fff929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | train 28.668227 | monitor_loss 13.754825\n",
      "Epoch 002 | train 24.318638 | monitor_loss 12.064663\n",
      "Epoch 003 | train 21.372946 | monitor_loss 11.418877\n",
      "Epoch 004 | train 19.531485 | monitor_loss 10.973756\n",
      "Epoch 005 | train 18.108686 | monitor_loss 10.185671\n",
      "Epoch 006 | train 16.918664 | monitor_loss 9.735870\n",
      "Epoch 007 | train 16.016300 | monitor_loss 9.569500\n",
      "Epoch 008 | train 15.430674 | monitor_loss 9.600272\n",
      "Epoch 009 | train 15.014173 | monitor_loss 9.658867\n",
      "Epoch 010 | train 14.685780 | monitor_loss 9.745872\n",
      "Epoch 011 | train 14.407295 | monitor_loss 9.735779\n",
      "Epoch 012 | train 14.179964 | monitor_loss 9.800245\n",
      "Epoch 013 | train 13.988724 | monitor_loss 9.709022\n",
      "Epoch 014 | train 13.817087 | monitor_loss 9.869119\n",
      "Epoch 015 | train 13.687785 | monitor_loss 9.851102\n",
      "Epoch 016 | train 13.539674 | monitor_loss 9.905873\n",
      "Epoch 017 | train 13.416805 | monitor_loss 9.845573\n",
      "Epoch 018 | train 13.289579 | monitor_loss 9.850217\n",
      "Epoch 019 | train 13.225102 | monitor_loss 9.771808\n",
      "Epoch 020 | train 13.108118 | monitor_loss 9.846527\n",
      "Epoch 021 | train 13.124280 | monitor_loss 9.880655\n",
      "Epoch 022 | train 12.956974 | monitor_loss 9.702843\n",
      "Epoch 023 | train 12.892627 | monitor_loss 9.767147\n",
      "Epoch 024 | train 12.808092 | monitor_loss 9.825921\n",
      "Epoch 025 | train 12.722291 | monitor_loss 9.829342\n",
      "Epoch 026 | train 12.696909 | monitor_loss 9.810249\n",
      "Epoch 027 | train 12.632828 | monitor_loss 9.965818\n",
      "Epoch 028 | train 12.561842 | monitor_loss 9.799561\n",
      "Epoch 029 | train 12.504051 | monitor_loss 9.876104\n",
      "Epoch 030 | train 12.533107 | monitor_loss 9.862265\n",
      "Epoch 031 | train 12.473298 | monitor_loss 9.900791\n",
      "Epoch 032 | train 12.366846 | monitor_loss 9.801183\n",
      "Epoch 033 | train 12.334096 | monitor_loss 9.884281\n",
      "Epoch 034 | train 12.303565 | monitor_loss 9.714426\n",
      "Epoch 035 | train 12.249884 | monitor_loss 9.812025\n",
      "Epoch 036 | train 12.205271 | monitor_loss 9.855485\n",
      "Epoch 037 | train 12.143832 | monitor_loss 9.802575\n",
      "Epoch 038 | train 12.110142 | monitor_loss 9.904557\n",
      "Epoch 039 | train 12.065512 | monitor_loss 9.844885\n",
      "Epoch 040 | train 12.027277 | monitor_loss 9.905887\n",
      "Epoch 041 | train 12.010008 | monitor_loss 9.925872\n",
      "Epoch 042 | train 11.977282 | monitor_loss 9.979226\n",
      "Epoch 043 | train 11.957532 | monitor_loss 9.970436\n",
      "Epoch 044 | train 11.934431 | monitor_loss 9.877586\n",
      "Epoch 045 | train 11.943049 | monitor_loss 9.957533\n",
      "Epoch 046 | train 11.848084 | monitor_loss 9.982934\n",
      "Epoch 047 | train 11.807054 | monitor_loss 9.964805\n",
      "Epoch 048 | train 11.788968 | monitor_loss 9.991936\n",
      "Epoch 049 | train 11.755329 | monitor_loss 10.069402\n",
      "Epoch 050 | train 11.723271 | monitor_loss 10.032544\n",
      "Epoch 051 | train 11.704655 | monitor_loss 10.011448\n",
      "Epoch 052 | train 11.679094 | monitor_loss 10.050572\n",
      "Epoch 053 | train 11.681865 | monitor_loss 10.082882\n",
      "Epoch 054 | train 11.604112 | monitor_loss 10.031896\n",
      "Early stopping at epoch 054 (best macro_R2@val 0.396951)\n",
      "\n",
      "Single-fit test metrics:\n",
      "       macro_MAE: 2.281933\n",
      "       macro_MSE: 9.714425\n",
      "  macro_PearsonR: 0.455856\n",
      "        macro_R2: 0.199451\n",
      "      macro_RMSE: 3.116797\n",
      "task_1: MSE=9.714425, RMSE=3.116797, MAE=2.281933, R2=0.199451, PearsonR=0.455856\n",
      "Epoch 001 | train 28.969722 | monitor_loss 25.424145\n",
      "Epoch 002 | train 25.607718 | monitor_loss 22.892710\n",
      "Epoch 003 | train 22.989703 | monitor_loss 21.018617\n",
      "Epoch 004 | train 20.908851 | monitor_loss 19.787846\n",
      "Epoch 005 | train 19.348446 | monitor_loss 18.779374\n",
      "Epoch 006 | train 17.960128 | monitor_loss 17.688595\n",
      "Epoch 007 | train 16.866942 | monitor_loss 16.853250\n",
      "Epoch 008 | train 16.150265 | monitor_loss 16.312631\n",
      "Epoch 009 | train 15.687683 | monitor_loss 15.889649\n",
      "Epoch 010 | train 15.331469 | monitor_loss 15.561971\n",
      "Epoch 011 | train 15.021740 | monitor_loss 15.352348\n",
      "Epoch 012 | train 14.748583 | monitor_loss 15.165033\n",
      "Epoch 013 | train 14.491484 | monitor_loss 14.976898\n",
      "Epoch 014 | train 14.253557 | monitor_loss 14.838247\n",
      "Epoch 015 | train 14.063598 | monitor_loss 14.713979\n",
      "Epoch 016 | train 13.877196 | monitor_loss 14.572278\n",
      "Epoch 017 | train 13.719094 | monitor_loss 14.412530\n",
      "Epoch 018 | train 13.581197 | monitor_loss 14.326110\n",
      "Epoch 019 | train 13.446973 | monitor_loss 14.212384\n",
      "Epoch 020 | train 13.346106 | monitor_loss 14.141050\n",
      "Epoch 021 | train 13.224395 | monitor_loss 14.007838\n",
      "Epoch 022 | train 13.125644 | monitor_loss 13.931735\n",
      "Epoch 023 | train 13.029656 | monitor_loss 13.873089\n",
      "Epoch 024 | train 12.955461 | monitor_loss 13.816313\n",
      "Epoch 025 | train 12.857878 | monitor_loss 13.739965\n",
      "Epoch 026 | train 12.779718 | monitor_loss 13.679986\n",
      "Epoch 027 | train 12.704142 | monitor_loss 13.657899\n",
      "Epoch 028 | train 12.632053 | monitor_loss 13.603258\n",
      "Epoch 029 | train 12.562097 | monitor_loss 13.566092\n",
      "Epoch 030 | train 12.483371 | monitor_loss 13.539365\n",
      "Epoch 031 | train 12.427420 | monitor_loss 13.503862\n",
      "Epoch 032 | train 12.380699 | monitor_loss 13.518365\n",
      "Epoch 033 | train 12.346313 | monitor_loss 13.517688\n",
      "Epoch 034 | train 12.232661 | monitor_loss 13.420513\n",
      "Epoch 035 | train 12.175532 | monitor_loss 13.466634\n",
      "Epoch 036 | train 12.121628 | monitor_loss 13.468017\n",
      "Epoch 037 | train 12.070244 | monitor_loss 13.444903\n",
      "Epoch 038 | train 12.024461 | monitor_loss 13.497048\n",
      "Epoch 039 | train 11.992904 | monitor_loss 13.505628\n",
      "Epoch 040 | train 11.935956 | monitor_loss 13.480571\n",
      "Epoch 041 | train 11.859728 | monitor_loss 13.517363\n",
      "Epoch 042 | train 11.790844 | monitor_loss 13.498940\n",
      "Epoch 043 | train 11.744199 | monitor_loss 13.497570\n",
      "Epoch 044 | train 11.706813 | monitor_loss 13.551105\n",
      "Epoch 045 | train 11.624065 | monitor_loss 13.627305\n",
      "Epoch 046 | train 11.568302 | monitor_loss 13.526608\n",
      "Epoch 047 | train 11.497866 | monitor_loss 13.538556\n",
      "Epoch 048 | train 11.466468 | monitor_loss 13.588615\n",
      "Epoch 049 | train 11.400279 | monitor_loss 13.577641\n",
      "Epoch 050 | train 11.354231 | monitor_loss 13.733948\n",
      "Epoch 051 | train 11.278621 | monitor_loss 13.617920\n",
      "Epoch 052 | train 11.254979 | monitor_loss 13.730983\n",
      "Epoch 053 | train 11.184367 | monitor_loss 13.904525\n",
      "Epoch 054 | train 11.115097 | monitor_loss 13.693375\n",
      "Epoch 055 | train 11.012406 | monitor_loss 13.728495\n",
      "Epoch 056 | train 10.972385 | monitor_loss 13.805970\n",
      "Epoch 057 | train 10.889009 | monitor_loss 13.710231\n",
      "Epoch 058 | train 10.786573 | monitor_loss 13.930901\n",
      "Epoch 059 | train 10.769018 | monitor_loss 13.763768\n",
      "Epoch 060 | train 10.732703 | monitor_loss 13.960181\n",
      "Epoch 061 | train 10.679117 | monitor_loss 14.031016\n",
      "Early stopping at epoch 061 (best macro_R2@val 0.352944)\n",
      "\n",
      "Single-fit test metrics:\n",
      "       macro_MAE: 2.122359\n",
      "       macro_MSE: 9.294177\n",
      "  macro_PearsonR: 0.653869\n",
      "        macro_R2: 0.414786\n",
      "      macro_RMSE: 3.048635\n",
      "task_1: MSE=9.294177, RMSE=3.048635, MAE=2.122359, R2=0.414786, PearsonR=0.653869\n"
     ]
    }
   ],
   "source": [
    "res_single = run_training_and_eval_armed(\n",
    "    X_only_fixed=EXP_reg_only_fixed,              # e.g., EXP_reg_X_only_fixed.to_numpy(np.float32)\n",
    "    X_fixed_and_random=EXP_reg_fixed_and_random,  # or None\n",
    "    y=y_np,\n",
    "    pid_idx=pid_np,\n",
    "    time_index=time_ix_np,\n",
    "    build_model_fn=build_model_fn,\n",
    "    wrapper_cls=wrapper_cls,\n",
    "    mode=\"single\",\n",
    "    scenario=\"both\",   # or \"time\"\n",
    "    arch_defaults=arch_defaults,\n",
    "    train_defaults=train_defaults,\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c2fc41",
   "metadata": {},
   "source": [
    "### Nested CV with parameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09927b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outer fold 1/5\n",
      "Outer fold macro: macro_MAE=2.6737, macro_MSE=11.3197, macro_RMSE=3.3645, macro_MedAE=2.0651, macro_R2=0.3200, macro_EVS=0.3535, macro_MAPE=144465515.8408, macro_sMAPE=1.4069\n",
      "\n",
      "Outer fold 2/5\n",
      "Outer fold macro: macro_MAE=2.7981, macro_MSE=12.9290, macro_RMSE=3.5957, macro_MedAE=2.1650, macro_R2=0.4179, macro_EVS=0.4213, macro_MAPE=97661197.6936, macro_sMAPE=1.1188\n",
      "\n",
      "Outer fold 3/5\n",
      "Outer fold macro: macro_MAE=2.2361, macro_MSE=10.3293, macro_RMSE=3.2139, macro_MedAE=1.4546, macro_R2=0.2600, macro_EVS=0.2691, macro_MAPE=62917285.7755, macro_sMAPE=1.1926\n",
      "\n",
      "Outer fold 4/5\n",
      "Outer fold macro: macro_MAE=2.4923, macro_MSE=15.4924, macro_RMSE=3.9360, macro_MedAE=1.0839, macro_R2=0.0088, macro_EVS=0.2327, macro_MAPE=28625357.8250, macro_sMAPE=1.6312\n",
      "\n",
      "Outer fold 5/5\n",
      "Outer fold macro: macro_MAE=2.4270, macro_MSE=9.7935, macro_RMSE=3.1295, macro_MedAE=1.8025, macro_R2=0.1034, macro_EVS=0.1334, macro_MAPE=105777933.2864, macro_sMAPE=1.2509\n",
      "\n",
      "Best params (by outer macro_R2):\n",
      "[ARCH]:\n",
      "  fixed_rep_dim: 256\n",
      "  random_rep_dim: 256\n",
      "  combine_mode: add\n",
      "  grl_lambda: 0.5\n",
      "[TRAIN]:\n",
      "  lr: 0.0003\n",
      "  weight_decay: 0.0\n",
      "  batch_size: 256\n",
      "  max_epochs: 100\n",
      "  patience: 20\n",
      "  loss_weights: ARMEDLossWeights(lambda_adv=1.0, lambda_recon=0.0)\n",
      "  pca_var_ratio: 0.95\n",
      "  monitor_source: test\n",
      "  early_stop_metric: macro_R2\n",
      "  early_stop_on: val\n",
      "  random_state: 42\n",
      "  val_fraction: 0.1\n",
      "Epoch 001 | train 25.813923 | monitor_loss 11.769233\n",
      "Epoch 002 | train 19.337777 | monitor_loss 11.074016\n",
      "Epoch 003 | train 16.392491 | monitor_loss 9.289645\n",
      "Epoch 004 | train 14.974227 | monitor_loss 9.449121\n",
      "Epoch 005 | train 14.283138 | monitor_loss 9.616553\n",
      "Epoch 006 | train 13.724866 | monitor_loss 9.793510\n",
      "Epoch 007 | train 13.348353 | monitor_loss 9.750982\n",
      "Epoch 008 | train 13.078862 | monitor_loss 9.602726\n",
      "Epoch 009 | train 12.937854 | monitor_loss 10.270249\n",
      "Epoch 010 | train 12.672025 | monitor_loss 10.109602\n",
      "Epoch 011 | train 12.487821 | monitor_loss 9.967613\n",
      "Epoch 012 | train 12.327086 | monitor_loss 10.338830\n",
      "Epoch 013 | train 12.237637 | monitor_loss 10.763298\n",
      "Epoch 014 | train 12.176172 | monitor_loss 10.213974\n",
      "Epoch 015 | train 11.949401 | monitor_loss 11.125299\n",
      "Epoch 016 | train 11.858258 | monitor_loss 10.498959\n",
      "Epoch 017 | train 11.814321 | monitor_loss 10.938918\n",
      "Epoch 018 | train 11.636631 | monitor_loss 10.978275\n",
      "Epoch 019 | train 11.540942 | monitor_loss 10.611027\n",
      "Epoch 020 | train 11.503848 | monitor_loss 11.340514\n",
      "Epoch 021 | train 11.580625 | monitor_loss 10.188240\n",
      "Epoch 022 | train 11.437141 | monitor_loss 11.161462\n",
      "Epoch 023 | train 11.254225 | monitor_loss 10.906595\n",
      "Epoch 024 | train 11.259750 | monitor_loss 11.900841\n",
      "Epoch 025 | train 11.222157 | monitor_loss 11.219295\n",
      "Epoch 026 | train 11.207893 | monitor_loss 11.957463\n",
      "Epoch 027 | train 11.308159 | monitor_loss 11.994659\n",
      "Epoch 028 | train 11.174679 | monitor_loss 11.141687\n",
      "Epoch 029 | train 11.056442 | monitor_loss 11.164226\n",
      "Epoch 030 | train 11.028042 | monitor_loss 12.415329\n",
      "Epoch 031 | train 10.949641 | monitor_loss 10.976869\n",
      "Epoch 032 | train 10.933935 | monitor_loss 11.367538\n",
      "Epoch 033 | train 10.788065 | monitor_loss 11.746298\n",
      "Epoch 034 | train 10.714228 | monitor_loss 12.064388\n",
      "Epoch 035 | train 10.657771 | monitor_loss 12.072269\n",
      "Epoch 036 | train 10.478890 | monitor_loss 11.882848\n",
      "Epoch 037 | train 10.502929 | monitor_loss 11.176456\n",
      "Epoch 038 | train 10.637066 | monitor_loss 12.338091\n",
      "Epoch 039 | train 10.187584 | monitor_loss 12.911015\n",
      "Epoch 040 | train 10.033400 | monitor_loss 12.433084\n",
      "Epoch 041 | train 9.876799 | monitor_loss 12.887141\n",
      "Epoch 042 | train 9.757515 | monitor_loss 14.107033\n",
      "Epoch 043 | train 9.721436 | monitor_loss 13.201436\n",
      "Early stopping at epoch 043 (best macro_R2@val 0.437362)\n",
      "\n",
      "Outer fold 1/5\n",
      "Outer fold macro: macro_MAE=3.2266, macro_MSE=15.6384, macro_RMSE=3.9545, macro_MedAE=2.8758, macro_R2=0.1379, macro_EVS=0.2165, macro_MAPE=152611508.7364, macro_sMAPE=1.2090\n",
      "\n",
      "Outer fold 2/5\n",
      "Outer fold macro: macro_MAE=2.2534, macro_MSE=10.7227, macro_RMSE=3.2745, macro_MedAE=1.3929, macro_R2=0.3420, macro_EVS=0.3572, macro_MAPE=63865125.0878, macro_sMAPE=1.2676\n",
      "\n",
      "Outer fold 3/5\n",
      "Outer fold macro: macro_MAE=2.2279, macro_MSE=9.1963, macro_RMSE=3.0325, macro_MedAE=1.5625, macro_R2=0.4121, macro_EVS=0.4131, macro_MAPE=84525197.9356, macro_sMAPE=1.1911\n",
      "\n",
      "Outer fold 4/5\n",
      "Outer fold macro: macro_MAE=2.0763, macro_MSE=8.8603, macro_RMSE=2.9766, macro_MedAE=1.4164, macro_R2=0.3457, macro_EVS=0.3471, macro_MAPE=83591216.3062, macro_sMAPE=1.3064\n",
      "\n",
      "Outer fold 5/5\n",
      "Outer fold macro: macro_MAE=2.1435, macro_MSE=8.7369, macro_RMSE=2.9558, macro_MedAE=1.5171, macro_R2=0.4453, macro_EVS=0.4471, macro_MAPE=87733037.3829, macro_sMAPE=1.2806\n",
      "\n",
      "Best params (by outer macro_R2):\n",
      "[ARCH]:\n",
      "  fixed_rep_dim: 256\n",
      "  random_rep_dim: 256\n",
      "  combine_mode: add\n",
      "  grl_lambda: 0.5\n",
      "[TRAIN]:\n",
      "  lr: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  batch_size: 256\n",
      "  max_epochs: 100\n",
      "  patience: 20\n",
      "  loss_weights: ARMEDLossWeights(lambda_adv=1.0, lambda_recon=0.0)\n",
      "  pca_var_ratio: 0.95\n",
      "  monitor_source: test\n",
      "  early_stop_metric: macro_R2\n",
      "  early_stop_on: val\n",
      "  random_state: 42\n",
      "  val_fraction: 0.1\n",
      "Epoch 001 | train 21.042218 | monitor_loss 15.660305\n",
      "Epoch 002 | train 15.099493 | monitor_loss 14.659025\n",
      "Epoch 003 | train 13.815515 | monitor_loss 14.082537\n",
      "Epoch 004 | train 13.107209 | monitor_loss 13.326016\n",
      "Epoch 005 | train 12.717595 | monitor_loss 13.219555\n",
      "Epoch 006 | train 12.230257 | monitor_loss 13.545293\n",
      "Epoch 007 | train 12.055568 | monitor_loss 13.935990\n",
      "Epoch 008 | train 11.931319 | monitor_loss 13.115806\n",
      "Epoch 009 | train 11.988902 | monitor_loss 13.587680\n",
      "Epoch 010 | train 11.783083 | monitor_loss 14.222254\n",
      "Epoch 011 | train 11.628753 | monitor_loss 13.881009\n",
      "Epoch 012 | train 11.432671 | monitor_loss 15.167662\n",
      "Epoch 013 | train 11.381802 | monitor_loss 13.457717\n",
      "Epoch 014 | train 10.875957 | monitor_loss 14.278934\n",
      "Epoch 015 | train 10.485327 | monitor_loss 14.058552\n",
      "Epoch 016 | train 10.410841 | monitor_loss 15.105682\n",
      "Epoch 017 | train 10.193390 | monitor_loss 14.456611\n",
      "Epoch 018 | train 9.905022 | monitor_loss 14.005683\n",
      "Epoch 019 | train 9.543810 | monitor_loss 15.493832\n",
      "Epoch 020 | train 9.212547 | monitor_loss 14.317410\n",
      "Epoch 021 | train 9.148877 | monitor_loss 14.511382\n",
      "Epoch 022 | train 8.840741 | monitor_loss 14.717742\n",
      "Epoch 023 | train 8.640489 | monitor_loss 15.585523\n",
      "Early stopping at epoch 023 (best macro_R2@val 0.410730)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"fixed_rep_dim\": [64, 128, 256],\n",
    "    \"random_rep_dim\": [64, 128, 256],\n",
    "    \"combine_mode\": [\"add\"],       # \"film\" also supported\n",
    "    \"grl_lambda\": [0.5, 1.0],\n",
    "\n",
    "    \"lr\": [1e-3, 3e-4, 1e-4],\n",
    "    \"weight_decay\": [0.0, 1e-4],\n",
    "    \"batch_size\": [64, 128, 256],\n",
    "    \"max_epochs\": [100],\n",
    "    \"patience\": [20],\n",
    "}\n",
    "\n",
    "res_nested = run_training_and_eval_armed(\n",
    "    X_only_fixed=EXP_reg_only_fixed,              # e.g., EXP_reg_X_only_fixed.to_numpy(np.float32)\n",
    "    X_fixed_and_random=EXP_reg_fixed_and_random,  # or None\n",
    "    y=y_np,\n",
    "    pid_idx=pid_np,\n",
    "    time_index=time_ix_np,\n",
    "    build_model_fn=build_model_fn,\n",
    "    wrapper_cls=wrapper_cls,\n",
    "    mode=\"nested_cv\",\n",
    "    scenario=\"both\",            # or \"time\"\n",
    "    outer_folds=5,\n",
    "    inner_folds=3,\n",
    "    param_grid=param_grid,\n",
    "    arch_defaults=arch_defaults,\n",
    "    train_defaults=train_defaults,\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc4ca57",
   "metadata": {},
   "source": [
    "### CV without parameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d60b7d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1:\n",
      "\n",
      "Per-fold test metrics:\n",
      "       macro_MAE: 2.304174\n",
      "       macro_MSE: 10.692920\n",
      "  macro_PearsonR: 0.602544\n",
      "        macro_R2: 0.357656\n",
      "      macro_RMSE: 3.270003\n",
      "task_1: MSE=10.692920, RMSE=3.270003, MAE=2.304174, R2=0.357656, PearsonR=0.602544\n",
      "\n",
      "Fold 2:\n",
      "\n",
      "Per-fold test metrics:\n",
      "       macro_MAE: 2.876254\n",
      "       macro_MSE: 12.502810\n",
      "  macro_PearsonR: 0.725843\n",
      "        macro_R2: 0.437114\n",
      "      macro_RMSE: 3.535931\n",
      "task_1: MSE=12.502810, RMSE=3.535931, MAE=2.876254, R2=0.437114, PearsonR=0.725843\n",
      "\n",
      "Fold 3:\n",
      "\n",
      "Per-fold test metrics:\n",
      "       macro_MAE: 2.280378\n",
      "       macro_MSE: 10.972196\n",
      "  macro_PearsonR: 0.494338\n",
      "        macro_R2: 0.213945\n",
      "      macro_RMSE: 3.312430\n",
      "task_1: MSE=10.972196, RMSE=3.312430, MAE=2.280378, R2=0.213945, PearsonR=0.494338\n",
      "\n",
      "Fold 4:\n",
      "\n",
      "Per-fold test metrics:\n",
      "       macro_MAE: 2.609625\n",
      "       macro_MSE: 11.495363\n",
      "  macro_PearsonR: 0.522278\n",
      "        macro_R2: 0.264511\n",
      "      macro_RMSE: 3.390481\n",
      "task_1: MSE=11.495363, RMSE=3.390481, MAE=2.609625, R2=0.264511, PearsonR=0.522278\n",
      "\n",
      "Fold 5:\n",
      "\n",
      "Per-fold test metrics:\n",
      "       macro_MAE: 2.597573\n",
      "       macro_MSE: 10.314645\n",
      "  macro_PearsonR: 0.371681\n",
      "        macro_R2: 0.055730\n",
      "      macro_RMSE: 3.211642\n",
      "task_1: MSE=10.314645, RMSE=3.211642, MAE=2.597573, R2=0.055730, PearsonR=0.371681\n",
      "\n",
      "CV averages (±95% CI):\n",
      "           macro_MAE: 2.533601  (95% CI 2.226906, 2.840295)\n",
      "           macro_MSE: 11.195587  (95% CI 10.142487, 12.248686)\n",
      "      macro_PearsonR: 0.543337  (95% CI 0.380111, 0.706562)\n",
      "            macro_R2: 0.265791  (95% CI 0.085209, 0.446374)\n",
      "          macro_RMSE: 3.344098  (95% CI 3.188284, 3.499912)\n",
      "          task_1_MAE: 2.533601  (95% CI 2.226906, 2.840295)\n",
      "          task_1_MSE: 11.195587  (95% CI 10.142487, 12.248686)\n",
      "     task_1_PearsonR: 0.543337  (95% CI 0.380111, 0.706562)\n",
      "           task_1_R2: 0.265791  (95% CI 0.085209, 0.446374)\n",
      "         task_1_RMSE: 3.344098  (95% CI 3.188284, 3.499912)\n",
      "\n",
      "Fold 1:\n",
      "\n",
      "Per-fold test metrics:\n",
      "       macro_MAE: 3.064413\n",
      "       macro_MSE: 13.774432\n",
      "  macro_PearsonR: 0.540214\n",
      "        macro_R2: 0.240646\n",
      "      macro_RMSE: 3.711392\n",
      "task_1: MSE=13.774432, RMSE=3.711392, MAE=3.064413, R2=0.240646, PearsonR=0.540214\n",
      "\n",
      "Fold 2:\n",
      "\n",
      "Per-fold test metrics:\n",
      "       macro_MAE: 2.472296\n",
      "       macro_MSE: 11.110966\n",
      "  macro_PearsonR: 0.571941\n",
      "        macro_R2: 0.318155\n",
      "      macro_RMSE: 3.333312\n",
      "task_1: MSE=11.110966, RMSE=3.333312, MAE=2.472296, R2=0.318155, PearsonR=0.571941\n",
      "\n",
      "Fold 3:\n",
      "\n",
      "Per-fold test metrics:\n",
      "       macro_MAE: 2.175581\n",
      "       macro_MSE: 9.746602\n",
      "  macro_PearsonR: 0.615509\n",
      "        macro_R2: 0.376945\n",
      "      macro_RMSE: 3.121955\n",
      "task_1: MSE=9.746602, RMSE=3.121955, MAE=2.175581, R2=0.376945, PearsonR=0.615509\n",
      "\n",
      "Fold 4:\n",
      "\n",
      "Per-fold test metrics:\n",
      "       macro_MAE: 2.082975\n",
      "       macro_MSE: 9.263656\n",
      "  macro_PearsonR: 0.567373\n",
      "        macro_R2: 0.315882\n",
      "      macro_RMSE: 3.043625\n",
      "task_1: MSE=9.263656, RMSE=3.043625, MAE=2.082975, R2=0.315882, PearsonR=0.567373\n",
      "\n",
      "Fold 5:\n",
      "\n",
      "Per-fold test metrics:\n",
      "       macro_MAE: 2.079491\n",
      "       macro_MSE: 8.969693\n",
      "  macro_PearsonR: 0.659100\n",
      "        macro_R2: 0.430573\n",
      "      macro_RMSE: 2.994945\n",
      "task_1: MSE=8.969693, RMSE=2.994945, MAE=2.079491, R2=0.430573, PearsonR=0.659100\n",
      "\n",
      "CV averages (±95% CI):\n",
      "           macro_MAE: 2.374951  (95% CI 1.856592, 2.893310)\n",
      "           macro_MSE: 10.573070  (95% CI 8.128341, 13.017799)\n",
      "      macro_PearsonR: 0.590828  (95% CI 0.532791, 0.648864)\n",
      "            macro_R2: 0.336441  (95% CI 0.247692, 0.425189)\n",
      "          macro_RMSE: 3.241046  (95% CI 2.877203, 3.604888)\n",
      "          task_1_MAE: 2.374951  (95% CI 1.856592, 2.893310)\n",
      "          task_1_MSE: 10.573070  (95% CI 8.128341, 13.017799)\n",
      "     task_1_PearsonR: 0.590828  (95% CI 0.532791, 0.648864)\n",
      "           task_1_R2: 0.336441  (95% CI 0.247692, 0.425189)\n",
      "         task_1_RMSE: 3.241046  (95% CI 2.877203, 3.604888)\n"
     ]
    }
   ],
   "source": [
    "res_cv = run_training_and_eval_armed(\n",
    "    X_only_fixed=EXP_reg_only_fixed,\n",
    "    X_fixed_and_random=EXP_reg_fixed_and_random,\n",
    "    y=y_np,\n",
    "    pid_idx=pid_np,\n",
    "    time_index=time_ix_np,\n",
    "    build_model_fn=build_model_fn,\n",
    "    wrapper_cls=wrapper_cls,\n",
    "    mode=\"cv_only\",\n",
    "    scenario=\"both\",   # or \"time\"\n",
    "    outer_folds=5,\n",
    "    arch_defaults=arch_defaults,\n",
    "    train_defaults=train_defaults,\n",
    "    verbose=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
